I0722 00:57:08.061532 23230 caffe.cpp:217] Using GPUs 0, 1, 2, 3
I0722 00:57:08.092581 23230 caffe.cpp:222] GPU 0: GeForce GTX 1080 Ti
I0722 00:57:08.093195 23230 caffe.cpp:222] GPU 1: GeForce GTX 1080 Ti
I0722 00:57:08.093818 23230 caffe.cpp:222] GPU 2: GeForce GTX 1080 Ti
I0722 00:57:08.094482 23230 caffe.cpp:222] GPU 3: GeForce GTX 1080 Ti
I0722 00:57:08.703785 23230 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/VOC0712/SSD_1024x1024/train.prototxt"
test_net: "models/VGGNet/VOC0712/SSD_1024x1024/test.prototxt"
test_iter: 19
test_interval: 1000
base_lr: 0.001
display: 10
max_iter: 240000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 8
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0722 00:57:08.704004 23230 solver.cpp:96] Creating training net from train_net file: models/VGGNet/VOC0712/SSD_1024x1024/train.prototxt
I0722 00:57:08.705984 23230 net.cpp:58] Initializing net from parameters: 
name: "VGG_VOC0712_SSD_1024x1024_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 1024
      width: 1024
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "examples/bdc2018/bdc2018_train_name_lmdb"
    batch_size: 2
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/bdc2018/labelmap_bdc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc_bdc2018"
  top: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new"
  top: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 102.4
    max_size: 204.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "fc7_mbox_loc_bdc2018"
  top: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  top: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "fc7_mbox_conf_bdc2018_new"
  top: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 204.8
    max_size: 378.88
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv6_2_mbox_loc_bdc2018"
  top: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv6_2_mbox_conf_bdc2018_new"
  top: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 378.88
    max_size: 552.96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv7_2_mbox_loc_bdc2018"
  top: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv7_2_mbox_conf_bdc2018_new"
  top: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 552.96
    max_size: 727.04
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv8_2_mbox_loc_bdc2018"
  top: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv8_2_mbox_conf_bdc2018_new"
  top: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 727.04
    max_size: 901.12
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv9_2_mbox_loc_bdc2018"
  top: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv9_2_mbox_conf_bdc2018_new"
  top: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 901.12
    max_size: 1075.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 9
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0722 00:57:08.706584 23230 layer_factory.hpp:77] Creating layer data
I0722 00:57:08.706810 23230 net.cpp:100] Creating Layer data
I0722 00:57:08.706841 23230 net.cpp:408] data -> data
I0722 00:57:08.706887 23230 net.cpp:408] data -> label
I0722 00:57:08.709138 23236 db_lmdb.cpp:35] Opened lmdb examples/bdc2018/bdc2018_train_name_lmdb
I0722 00:57:08.758469 23230 annotated_data_layer.cpp:62] output data size: 2,3,1024,1024
I0722 00:57:08.799270 23230 net.cpp:150] Setting up data
I0722 00:57:08.799321 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799329 23230 net.cpp:157] Top shape: 1 1 1 8 (8)
I0722 00:57:08.799331 23230 net.cpp:165] Memory required for data: 25165856
I0722 00:57:08.799345 23230 layer_factory.hpp:77] Creating layer data_data_0_split
I0722 00:57:08.799366 23230 net.cpp:100] Creating Layer data_data_0_split
I0722 00:57:08.799374 23230 net.cpp:434] data_data_0_split <- data
I0722 00:57:08.799392 23230 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0722 00:57:08.799407 23230 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0722 00:57:08.799414 23230 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0722 00:57:08.799422 23230 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0722 00:57:08.799428 23230 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0722 00:57:08.799435 23230 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0722 00:57:08.799441 23230 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0722 00:57:08.799567 23230 net.cpp:150] Setting up data_data_0_split
I0722 00:57:08.799577 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799582 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799587 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799592 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799595 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799599 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799603 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:08.799607 23230 net.cpp:165] Memory required for data: 201326624
I0722 00:57:08.799610 23230 layer_factory.hpp:77] Creating layer conv1_1
I0722 00:57:08.799630 23230 net.cpp:100] Creating Layer conv1_1
I0722 00:57:08.799636 23230 net.cpp:434] conv1_1 <- data_data_0_split_0
I0722 00:57:08.799644 23230 net.cpp:408] conv1_1 -> conv1_1
I0722 00:57:09.124239 23237 blocking_queue.cpp:50] Waiting for data
I0722 00:57:09.232801 23230 net.cpp:150] Setting up conv1_1
I0722 00:57:09.232853 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.232859 23230 net.cpp:165] Memory required for data: 738197536
I0722 00:57:09.232970 23230 layer_factory.hpp:77] Creating layer relu1_1
I0722 00:57:09.233000 23230 net.cpp:100] Creating Layer relu1_1
I0722 00:57:09.233008 23230 net.cpp:434] relu1_1 <- conv1_1
I0722 00:57:09.233017 23230 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0722 00:57:09.233222 23230 net.cpp:150] Setting up relu1_1
I0722 00:57:09.233235 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.233239 23230 net.cpp:165] Memory required for data: 1275068448
I0722 00:57:09.233243 23230 layer_factory.hpp:77] Creating layer conv1_2
I0722 00:57:09.233278 23230 net.cpp:100] Creating Layer conv1_2
I0722 00:57:09.233283 23230 net.cpp:434] conv1_2 <- conv1_1
I0722 00:57:09.233295 23230 net.cpp:408] conv1_2 -> conv1_2
I0722 00:57:09.241616 23230 net.cpp:150] Setting up conv1_2
I0722 00:57:09.241634 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.241638 23230 net.cpp:165] Memory required for data: 1811939360
I0722 00:57:09.241649 23230 layer_factory.hpp:77] Creating layer relu1_2
I0722 00:57:09.241657 23230 net.cpp:100] Creating Layer relu1_2
I0722 00:57:09.241662 23230 net.cpp:434] relu1_2 <- conv1_2
I0722 00:57:09.241667 23230 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0722 00:57:09.241860 23230 net.cpp:150] Setting up relu1_2
I0722 00:57:09.241873 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.241876 23230 net.cpp:165] Memory required for data: 2348810272
I0722 00:57:09.241892 23230 layer_factory.hpp:77] Creating layer pool1
I0722 00:57:09.241917 23230 net.cpp:100] Creating Layer pool1
I0722 00:57:09.241924 23230 net.cpp:434] pool1 <- conv1_2
I0722 00:57:09.241930 23230 net.cpp:408] pool1 -> pool1
I0722 00:57:09.241995 23230 net.cpp:150] Setting up pool1
I0722 00:57:09.242004 23230 net.cpp:157] Top shape: 2 64 512 512 (33554432)
I0722 00:57:09.242007 23230 net.cpp:165] Memory required for data: 2483028000
I0722 00:57:09.242012 23230 layer_factory.hpp:77] Creating layer conv2_1
I0722 00:57:09.242022 23230 net.cpp:100] Creating Layer conv2_1
I0722 00:57:09.242025 23230 net.cpp:434] conv2_1 <- pool1
I0722 00:57:09.242031 23230 net.cpp:408] conv2_1 -> conv2_1
I0722 00:57:09.248375 23230 net.cpp:150] Setting up conv2_1
I0722 00:57:09.248394 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.248399 23230 net.cpp:165] Memory required for data: 2751463456
I0722 00:57:09.248412 23230 layer_factory.hpp:77] Creating layer relu2_1
I0722 00:57:09.248422 23230 net.cpp:100] Creating Layer relu2_1
I0722 00:57:09.248426 23230 net.cpp:434] relu2_1 <- conv2_1
I0722 00:57:09.248432 23230 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0722 00:57:09.250111 23230 net.cpp:150] Setting up relu2_1
I0722 00:57:09.250125 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.250129 23230 net.cpp:165] Memory required for data: 3019898912
I0722 00:57:09.250141 23230 layer_factory.hpp:77] Creating layer conv2_2
I0722 00:57:09.250159 23230 net.cpp:100] Creating Layer conv2_2
I0722 00:57:09.250164 23230 net.cpp:434] conv2_2 <- conv2_1
I0722 00:57:09.250171 23230 net.cpp:408] conv2_2 -> conv2_2
I0722 00:57:09.260203 23230 net.cpp:150] Setting up conv2_2
I0722 00:57:09.260224 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.260229 23230 net.cpp:165] Memory required for data: 3288334368
I0722 00:57:09.260237 23230 layer_factory.hpp:77] Creating layer relu2_2
I0722 00:57:09.260243 23230 net.cpp:100] Creating Layer relu2_2
I0722 00:57:09.260248 23230 net.cpp:434] relu2_2 <- conv2_2
I0722 00:57:09.260265 23230 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0722 00:57:09.260481 23230 net.cpp:150] Setting up relu2_2
I0722 00:57:09.260495 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.260499 23230 net.cpp:165] Memory required for data: 3556769824
I0722 00:57:09.260504 23230 layer_factory.hpp:77] Creating layer pool2
I0722 00:57:09.260510 23230 net.cpp:100] Creating Layer pool2
I0722 00:57:09.260515 23230 net.cpp:434] pool2 <- conv2_2
I0722 00:57:09.260520 23230 net.cpp:408] pool2 -> pool2
I0722 00:57:09.260591 23230 net.cpp:150] Setting up pool2
I0722 00:57:09.260601 23230 net.cpp:157] Top shape: 2 128 256 256 (16777216)
I0722 00:57:09.260604 23230 net.cpp:165] Memory required for data: 3623878688
I0722 00:57:09.260620 23230 layer_factory.hpp:77] Creating layer conv3_1
I0722 00:57:09.260633 23230 net.cpp:100] Creating Layer conv3_1
I0722 00:57:09.260637 23230 net.cpp:434] conv3_1 <- pool2
I0722 00:57:09.260646 23230 net.cpp:408] conv3_1 -> conv3_1
I0722 00:57:09.268270 23230 net.cpp:150] Setting up conv3_1
I0722 00:57:09.268288 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.268293 23230 net.cpp:165] Memory required for data: 3758096416
I0722 00:57:09.268303 23230 layer_factory.hpp:77] Creating layer relu3_1
I0722 00:57:09.268312 23230 net.cpp:100] Creating Layer relu3_1
I0722 00:57:09.268318 23230 net.cpp:434] relu3_1 <- conv3_1
I0722 00:57:09.268324 23230 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0722 00:57:09.270143 23230 net.cpp:150] Setting up relu3_1
I0722 00:57:09.270159 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.270161 23230 net.cpp:165] Memory required for data: 3892314144
I0722 00:57:09.270165 23230 layer_factory.hpp:77] Creating layer conv3_2
I0722 00:57:09.270177 23230 net.cpp:100] Creating Layer conv3_2
I0722 00:57:09.270182 23230 net.cpp:434] conv3_2 <- conv3_1
I0722 00:57:09.270191 23230 net.cpp:408] conv3_2 -> conv3_2
I0722 00:57:09.278285 23230 net.cpp:150] Setting up conv3_2
I0722 00:57:09.278307 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.278311 23230 net.cpp:165] Memory required for data: 4026531872
I0722 00:57:09.278319 23230 layer_factory.hpp:77] Creating layer relu3_2
I0722 00:57:09.278336 23230 net.cpp:100] Creating Layer relu3_2
I0722 00:57:09.278339 23230 net.cpp:434] relu3_2 <- conv3_2
I0722 00:57:09.278345 23230 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0722 00:57:09.278789 23230 net.cpp:150] Setting up relu3_2
I0722 00:57:09.278805 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.278810 23230 net.cpp:165] Memory required for data: 4160749600
I0722 00:57:09.278813 23230 layer_factory.hpp:77] Creating layer conv3_3
I0722 00:57:09.278829 23230 net.cpp:100] Creating Layer conv3_3
I0722 00:57:09.278834 23230 net.cpp:434] conv3_3 <- conv3_2
I0722 00:57:09.278841 23230 net.cpp:408] conv3_3 -> conv3_3
I0722 00:57:09.286573 23230 net.cpp:150] Setting up conv3_3
I0722 00:57:09.286593 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.286599 23230 net.cpp:165] Memory required for data: 4294967328
I0722 00:57:09.286607 23230 layer_factory.hpp:77] Creating layer relu3_3
I0722 00:57:09.286614 23230 net.cpp:100] Creating Layer relu3_3
I0722 00:57:09.286618 23230 net.cpp:434] relu3_3 <- conv3_3
I0722 00:57:09.286624 23230 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0722 00:57:09.286829 23230 net.cpp:150] Setting up relu3_3
I0722 00:57:09.286842 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.286846 23230 net.cpp:165] Memory required for data: 4429185056
I0722 00:57:09.286849 23230 layer_factory.hpp:77] Creating layer pool3
I0722 00:57:09.286859 23230 net.cpp:100] Creating Layer pool3
I0722 00:57:09.286862 23230 net.cpp:434] pool3 <- conv3_3
I0722 00:57:09.286869 23230 net.cpp:408] pool3 -> pool3
I0722 00:57:09.286923 23230 net.cpp:150] Setting up pool3
I0722 00:57:09.286932 23230 net.cpp:157] Top shape: 2 256 128 128 (8388608)
I0722 00:57:09.286936 23230 net.cpp:165] Memory required for data: 4462739488
I0722 00:57:09.286947 23230 layer_factory.hpp:77] Creating layer conv4_1
I0722 00:57:09.286959 23230 net.cpp:100] Creating Layer conv4_1
I0722 00:57:09.286965 23230 net.cpp:434] conv4_1 <- pool3
I0722 00:57:09.286974 23230 net.cpp:408] conv4_1 -> conv4_1
I0722 00:57:09.299978 23230 net.cpp:150] Setting up conv4_1
I0722 00:57:09.299996 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.300000 23230 net.cpp:165] Memory required for data: 4529848352
I0722 00:57:09.300009 23230 layer_factory.hpp:77] Creating layer relu4_1
I0722 00:57:09.300017 23230 net.cpp:100] Creating Layer relu4_1
I0722 00:57:09.300036 23230 net.cpp:434] relu4_1 <- conv4_1
I0722 00:57:09.300042 23230 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0722 00:57:09.300271 23230 net.cpp:150] Setting up relu4_1
I0722 00:57:09.300284 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.300287 23230 net.cpp:165] Memory required for data: 4596957216
I0722 00:57:09.300292 23230 layer_factory.hpp:77] Creating layer conv4_2
I0722 00:57:09.300303 23230 net.cpp:100] Creating Layer conv4_2
I0722 00:57:09.300308 23230 net.cpp:434] conv4_2 <- conv4_1
I0722 00:57:09.300318 23230 net.cpp:408] conv4_2 -> conv4_2
I0722 00:57:09.339054 23230 net.cpp:150] Setting up conv4_2
I0722 00:57:09.339093 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.339102 23230 net.cpp:165] Memory required for data: 4664066080
I0722 00:57:09.339141 23230 layer_factory.hpp:77] Creating layer relu4_2
I0722 00:57:09.339155 23230 net.cpp:100] Creating Layer relu4_2
I0722 00:57:09.339164 23230 net.cpp:434] relu4_2 <- conv4_2
I0722 00:57:09.339174 23230 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0722 00:57:09.341054 23230 net.cpp:150] Setting up relu4_2
I0722 00:57:09.341076 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.341083 23230 net.cpp:165] Memory required for data: 4731174944
I0722 00:57:09.341089 23230 layer_factory.hpp:77] Creating layer conv4_3
I0722 00:57:09.341112 23230 net.cpp:100] Creating Layer conv4_3
I0722 00:57:09.341120 23230 net.cpp:434] conv4_3 <- conv4_2
I0722 00:57:09.341131 23230 net.cpp:408] conv4_3 -> conv4_3
I0722 00:57:09.375401 23230 net.cpp:150] Setting up conv4_3
I0722 00:57:09.375437 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.375442 23230 net.cpp:165] Memory required for data: 4798283808
I0722 00:57:09.375454 23230 layer_factory.hpp:77] Creating layer relu4_3
I0722 00:57:09.375464 23230 net.cpp:100] Creating Layer relu4_3
I0722 00:57:09.375470 23230 net.cpp:434] relu4_3 <- conv4_3
I0722 00:57:09.375478 23230 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0722 00:57:09.377442 23230 net.cpp:150] Setting up relu4_3
I0722 00:57:09.377460 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.377466 23230 net.cpp:165] Memory required for data: 4865392672
I0722 00:57:09.377483 23230 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0722 00:57:09.377506 23230 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0722 00:57:09.377512 23230 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0722 00:57:09.377521 23230 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0722 00:57:09.377537 23230 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0722 00:57:09.377616 23230 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0722 00:57:09.377629 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.377635 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.377640 23230 net.cpp:165] Memory required for data: 4999610400
I0722 00:57:09.377645 23230 layer_factory.hpp:77] Creating layer pool4
I0722 00:57:09.377658 23230 net.cpp:100] Creating Layer pool4
I0722 00:57:09.377663 23230 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0722 00:57:09.377672 23230 net.cpp:408] pool4 -> pool4
I0722 00:57:09.377738 23230 net.cpp:150] Setting up pool4
I0722 00:57:09.377750 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.377754 23230 net.cpp:165] Memory required for data: 5016387616
I0722 00:57:09.377759 23230 layer_factory.hpp:77] Creating layer conv5_1
I0722 00:57:09.377775 23230 net.cpp:100] Creating Layer conv5_1
I0722 00:57:09.377784 23230 net.cpp:434] conv5_1 <- pool4
I0722 00:57:09.377795 23230 net.cpp:408] conv5_1 -> conv5_1
I0722 00:57:09.407939 23230 net.cpp:150] Setting up conv5_1
I0722 00:57:09.407965 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.407970 23230 net.cpp:165] Memory required for data: 5033164832
I0722 00:57:09.407992 23230 layer_factory.hpp:77] Creating layer relu5_1
I0722 00:57:09.408005 23230 net.cpp:100] Creating Layer relu5_1
I0722 00:57:09.408033 23230 net.cpp:434] relu5_1 <- conv5_1
I0722 00:57:09.408042 23230 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0722 00:57:09.408617 23230 net.cpp:150] Setting up relu5_1
I0722 00:57:09.408638 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.408643 23230 net.cpp:165] Memory required for data: 5049942048
I0722 00:57:09.408648 23230 layer_factory.hpp:77] Creating layer conv5_2
I0722 00:57:09.408665 23230 net.cpp:100] Creating Layer conv5_2
I0722 00:57:09.408673 23230 net.cpp:434] conv5_2 <- conv5_1
I0722 00:57:09.408681 23230 net.cpp:408] conv5_2 -> conv5_2
I0722 00:57:09.438285 23230 net.cpp:150] Setting up conv5_2
I0722 00:57:09.438310 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.438315 23230 net.cpp:165] Memory required for data: 5066719264
I0722 00:57:09.438328 23230 layer_factory.hpp:77] Creating layer relu5_2
I0722 00:57:09.438341 23230 net.cpp:100] Creating Layer relu5_2
I0722 00:57:09.438347 23230 net.cpp:434] relu5_2 <- conv5_2
I0722 00:57:09.438354 23230 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0722 00:57:09.440347 23230 net.cpp:150] Setting up relu5_2
I0722 00:57:09.440367 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.440371 23230 net.cpp:165] Memory required for data: 5083496480
I0722 00:57:09.440376 23230 layer_factory.hpp:77] Creating layer conv5_3
I0722 00:57:09.440400 23230 net.cpp:100] Creating Layer conv5_3
I0722 00:57:09.440408 23230 net.cpp:434] conv5_3 <- conv5_2
I0722 00:57:09.440416 23230 net.cpp:408] conv5_3 -> conv5_3
I0722 00:57:09.463030 23230 net.cpp:150] Setting up conv5_3
I0722 00:57:09.463083 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.463096 23230 net.cpp:165] Memory required for data: 5100273696
I0722 00:57:09.463120 23230 layer_factory.hpp:77] Creating layer relu5_3
I0722 00:57:09.463209 23230 net.cpp:100] Creating Layer relu5_3
I0722 00:57:09.463227 23230 net.cpp:434] relu5_3 <- conv5_3
I0722 00:57:09.463241 23230 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0722 00:57:09.464812 23230 net.cpp:150] Setting up relu5_3
I0722 00:57:09.464838 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.464844 23230 net.cpp:165] Memory required for data: 5117050912
I0722 00:57:09.464853 23230 layer_factory.hpp:77] Creating layer pool5
I0722 00:57:09.464869 23230 net.cpp:100] Creating Layer pool5
I0722 00:57:09.464877 23230 net.cpp:434] pool5 <- conv5_3
I0722 00:57:09.464907 23230 net.cpp:408] pool5 -> pool5
I0722 00:57:09.465023 23230 net.cpp:150] Setting up pool5
I0722 00:57:09.465040 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.465047 23230 net.cpp:165] Memory required for data: 5133828128
I0722 00:57:09.465054 23230 layer_factory.hpp:77] Creating layer fc6
I0722 00:57:09.465082 23230 net.cpp:100] Creating Layer fc6
I0722 00:57:09.465091 23230 net.cpp:434] fc6 <- pool5
I0722 00:57:09.465107 23230 net.cpp:408] fc6 -> fc6
I0722 00:57:09.526669 23230 net.cpp:150] Setting up fc6
I0722 00:57:09.526702 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.526708 23230 net.cpp:165] Memory required for data: 5167382560
I0722 00:57:09.526722 23230 layer_factory.hpp:77] Creating layer relu6
I0722 00:57:09.526734 23230 net.cpp:100] Creating Layer relu6
I0722 00:57:09.526742 23230 net.cpp:434] relu6 <- fc6
I0722 00:57:09.526754 23230 net.cpp:395] relu6 -> fc6 (in-place)
I0722 00:57:09.527109 23230 net.cpp:150] Setting up relu6
I0722 00:57:09.527132 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.527137 23230 net.cpp:165] Memory required for data: 5200936992
I0722 00:57:09.527143 23230 layer_factory.hpp:77] Creating layer fc7
I0722 00:57:09.527163 23230 net.cpp:100] Creating Layer fc7
I0722 00:57:09.527170 23230 net.cpp:434] fc7 <- fc6
I0722 00:57:09.527179 23230 net.cpp:408] fc7 -> fc7
I0722 00:57:09.540642 23230 net.cpp:150] Setting up fc7
I0722 00:57:09.540668 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.540674 23230 net.cpp:165] Memory required for data: 5234491424
I0722 00:57:09.540685 23230 layer_factory.hpp:77] Creating layer relu7
I0722 00:57:09.540732 23230 net.cpp:100] Creating Layer relu7
I0722 00:57:09.540740 23230 net.cpp:434] relu7 <- fc7
I0722 00:57:09.540748 23230 net.cpp:395] relu7 -> fc7 (in-place)
I0722 00:57:09.541050 23230 net.cpp:150] Setting up relu7
I0722 00:57:09.541069 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.541074 23230 net.cpp:165] Memory required for data: 5268045856
I0722 00:57:09.541081 23230 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0722 00:57:09.541095 23230 net.cpp:100] Creating Layer fc7_relu7_0_split
I0722 00:57:09.541101 23230 net.cpp:434] fc7_relu7_0_split <- fc7
I0722 00:57:09.541110 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0722 00:57:09.541123 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0722 00:57:09.541159 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0722 00:57:09.541173 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0722 00:57:09.541286 23230 net.cpp:150] Setting up fc7_relu7_0_split
I0722 00:57:09.541298 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.541307 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.541313 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.541319 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.541323 23230 net.cpp:165] Memory required for data: 5402263584
I0722 00:57:09.541332 23230 layer_factory.hpp:77] Creating layer conv6_1
I0722 00:57:09.541347 23230 net.cpp:100] Creating Layer conv6_1
I0722 00:57:09.541352 23230 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0722 00:57:09.541365 23230 net.cpp:408] conv6_1 -> conv6_1
I0722 00:57:09.545420 23230 net.cpp:150] Setting up conv6_1
I0722 00:57:09.545445 23230 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0722 00:57:09.545450 23230 net.cpp:165] Memory required for data: 5410652192
I0722 00:57:09.545461 23230 layer_factory.hpp:77] Creating layer conv6_1_relu
I0722 00:57:09.545470 23230 net.cpp:100] Creating Layer conv6_1_relu
I0722 00:57:09.545477 23230 net.cpp:434] conv6_1_relu <- conv6_1
I0722 00:57:09.545488 23230 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0722 00:57:09.546769 23230 net.cpp:150] Setting up conv6_1_relu
I0722 00:57:09.546797 23230 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0722 00:57:09.546802 23230 net.cpp:165] Memory required for data: 5419040800
I0722 00:57:09.546810 23230 layer_factory.hpp:77] Creating layer conv6_2
I0722 00:57:09.546829 23230 net.cpp:100] Creating Layer conv6_2
I0722 00:57:09.546836 23230 net.cpp:434] conv6_2 <- conv6_1
I0722 00:57:09.546846 23230 net.cpp:408] conv6_2 -> conv6_2
I0722 00:57:09.560880 23230 net.cpp:150] Setting up conv6_2
I0722 00:57:09.560914 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.560920 23230 net.cpp:165] Memory required for data: 5423235104
I0722 00:57:09.560956 23230 layer_factory.hpp:77] Creating layer conv6_2_relu
I0722 00:57:09.560967 23230 net.cpp:100] Creating Layer conv6_2_relu
I0722 00:57:09.560974 23230 net.cpp:434] conv6_2_relu <- conv6_2
I0722 00:57:09.560986 23230 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0722 00:57:09.562551 23230 net.cpp:150] Setting up conv6_2_relu
I0722 00:57:09.562578 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.562584 23230 net.cpp:165] Memory required for data: 5427429408
I0722 00:57:09.562590 23230 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0722 00:57:09.562602 23230 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0722 00:57:09.562608 23230 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0722 00:57:09.562620 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0722 00:57:09.562633 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0722 00:57:09.562641 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0722 00:57:09.562651 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0722 00:57:09.562764 23230 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0722 00:57:09.562799 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.562805 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.562813 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.562817 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:09.562821 23230 net.cpp:165] Memory required for data: 5444206624
I0722 00:57:09.562827 23230 layer_factory.hpp:77] Creating layer conv7_1
I0722 00:57:09.562845 23230 net.cpp:100] Creating Layer conv7_1
I0722 00:57:09.562855 23230 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0722 00:57:09.562865 23230 net.cpp:408] conv7_1 -> conv7_1
I0722 00:57:09.567812 23230 net.cpp:150] Setting up conv7_1
I0722 00:57:09.567836 23230 net.cpp:157] Top shape: 2 128 32 32 (262144)
I0722 00:57:09.567840 23230 net.cpp:165] Memory required for data: 5445255200
I0722 00:57:09.567850 23230 layer_factory.hpp:77] Creating layer conv7_1_relu
I0722 00:57:09.567860 23230 net.cpp:100] Creating Layer conv7_1_relu
I0722 00:57:09.567867 23230 net.cpp:434] conv7_1_relu <- conv7_1
I0722 00:57:09.567876 23230 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0722 00:57:09.569967 23230 net.cpp:150] Setting up conv7_1_relu
I0722 00:57:09.569983 23230 net.cpp:157] Top shape: 2 128 32 32 (262144)
I0722 00:57:09.569988 23230 net.cpp:165] Memory required for data: 5446303776
I0722 00:57:09.569993 23230 layer_factory.hpp:77] Creating layer conv7_2
I0722 00:57:09.570008 23230 net.cpp:100] Creating Layer conv7_2
I0722 00:57:09.570014 23230 net.cpp:434] conv7_2 <- conv7_1
I0722 00:57:09.570026 23230 net.cpp:408] conv7_2 -> conv7_2
I0722 00:57:09.577325 23230 net.cpp:150] Setting up conv7_2
I0722 00:57:09.577349 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.577355 23230 net.cpp:165] Memory required for data: 5446828064
I0722 00:57:09.577368 23230 layer_factory.hpp:77] Creating layer conv7_2_relu
I0722 00:57:09.577378 23230 net.cpp:100] Creating Layer conv7_2_relu
I0722 00:57:09.577384 23230 net.cpp:434] conv7_2_relu <- conv7_2
I0722 00:57:09.577392 23230 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0722 00:57:09.579244 23230 net.cpp:150] Setting up conv7_2_relu
I0722 00:57:09.579262 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.579267 23230 net.cpp:165] Memory required for data: 5447352352
I0722 00:57:09.579272 23230 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0722 00:57:09.579283 23230 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0722 00:57:09.579290 23230 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0722 00:57:09.579299 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0722 00:57:09.579313 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0722 00:57:09.579320 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0722 00:57:09.579329 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0722 00:57:09.579432 23230 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0722 00:57:09.579442 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.579448 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.579453 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.579458 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:09.579463 23230 net.cpp:165] Memory required for data: 5449449504
I0722 00:57:09.579470 23230 layer_factory.hpp:77] Creating layer conv8_1
I0722 00:57:09.579485 23230 net.cpp:100] Creating Layer conv8_1
I0722 00:57:09.579491 23230 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0722 00:57:09.579502 23230 net.cpp:408] conv8_1 -> conv8_1
I0722 00:57:09.586324 23230 net.cpp:150] Setting up conv8_1
I0722 00:57:09.586344 23230 net.cpp:157] Top shape: 2 128 16 16 (65536)
I0722 00:57:09.586350 23230 net.cpp:165] Memory required for data: 5449711648
I0722 00:57:09.586359 23230 layer_factory.hpp:77] Creating layer conv8_1_relu
I0722 00:57:09.586391 23230 net.cpp:100] Creating Layer conv8_1_relu
I0722 00:57:09.586398 23230 net.cpp:434] conv8_1_relu <- conv8_1
I0722 00:57:09.586406 23230 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0722 00:57:09.588407 23230 net.cpp:150] Setting up conv8_1_relu
I0722 00:57:09.588421 23230 net.cpp:157] Top shape: 2 128 16 16 (65536)
I0722 00:57:09.588426 23230 net.cpp:165] Memory required for data: 5449973792
I0722 00:57:09.588431 23230 layer_factory.hpp:77] Creating layer conv8_2
I0722 00:57:09.588448 23230 net.cpp:100] Creating Layer conv8_2
I0722 00:57:09.588455 23230 net.cpp:434] conv8_2 <- conv8_1
I0722 00:57:09.588466 23230 net.cpp:408] conv8_2 -> conv8_2
I0722 00:57:09.598309 23230 net.cpp:150] Setting up conv8_2
I0722 00:57:09.598333 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.598338 23230 net.cpp:165] Memory required for data: 5450375200
I0722 00:57:09.598350 23230 layer_factory.hpp:77] Creating layer conv8_2_relu
I0722 00:57:09.598362 23230 net.cpp:100] Creating Layer conv8_2_relu
I0722 00:57:09.598371 23230 net.cpp:434] conv8_2_relu <- conv8_2
I0722 00:57:09.598377 23230 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0722 00:57:09.600193 23230 net.cpp:150] Setting up conv8_2_relu
I0722 00:57:09.600209 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.600214 23230 net.cpp:165] Memory required for data: 5450776608
I0722 00:57:09.600219 23230 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0722 00:57:09.600232 23230 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0722 00:57:09.600240 23230 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0722 00:57:09.600248 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0722 00:57:09.600263 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0722 00:57:09.600271 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0722 00:57:09.600280 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0722 00:57:09.600411 23230 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0722 00:57:09.600428 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.600436 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.600441 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.600446 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:09.600450 23230 net.cpp:165] Memory required for data: 5452382240
I0722 00:57:09.600455 23230 layer_factory.hpp:77] Creating layer conv9_1
I0722 00:57:09.600471 23230 net.cpp:100] Creating Layer conv9_1
I0722 00:57:09.600477 23230 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0722 00:57:09.600486 23230 net.cpp:408] conv9_1 -> conv9_1
I0722 00:57:09.606981 23230 net.cpp:150] Setting up conv9_1
I0722 00:57:09.607002 23230 net.cpp:157] Top shape: 2 128 14 14 (50176)
I0722 00:57:09.607007 23230 net.cpp:165] Memory required for data: 5452582944
I0722 00:57:09.607017 23230 layer_factory.hpp:77] Creating layer conv9_1_relu
I0722 00:57:09.607024 23230 net.cpp:100] Creating Layer conv9_1_relu
I0722 00:57:09.607030 23230 net.cpp:434] conv9_1_relu <- conv9_1
I0722 00:57:09.607039 23230 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0722 00:57:09.609071 23230 net.cpp:150] Setting up conv9_1_relu
I0722 00:57:09.609092 23230 net.cpp:157] Top shape: 2 128 14 14 (50176)
I0722 00:57:09.609099 23230 net.cpp:165] Memory required for data: 5452783648
I0722 00:57:09.609104 23230 layer_factory.hpp:77] Creating layer conv9_2
I0722 00:57:09.609122 23230 net.cpp:100] Creating Layer conv9_2
I0722 00:57:09.609128 23230 net.cpp:434] conv9_2 <- conv9_1
I0722 00:57:09.609138 23230 net.cpp:408] conv9_2 -> conv9_2
I0722 00:57:09.615970 23230 net.cpp:150] Setting up conv9_2
I0722 00:57:09.615991 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:09.615996 23230 net.cpp:165] Memory required for data: 5453078560
I0722 00:57:09.616005 23230 layer_factory.hpp:77] Creating layer conv9_2_relu
I0722 00:57:09.616016 23230 net.cpp:100] Creating Layer conv9_2_relu
I0722 00:57:09.616040 23230 net.cpp:434] conv9_2_relu <- conv9_2
I0722 00:57:09.616050 23230 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0722 00:57:09.618041 23230 net.cpp:150] Setting up conv9_2_relu
I0722 00:57:09.618070 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:09.618075 23230 net.cpp:165] Memory required for data: 5453373472
I0722 00:57:09.618080 23230 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0722 00:57:09.618089 23230 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0722 00:57:09.618098 23230 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0722 00:57:09.618108 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0722 00:57:09.618129 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0722 00:57:09.618139 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0722 00:57:09.618223 23230 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0722 00:57:09.618233 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:09.618238 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:09.618242 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:09.618247 23230 net.cpp:165] Memory required for data: 5454258208
I0722 00:57:09.618250 23230 layer_factory.hpp:77] Creating layer conv4_3_norm
I0722 00:57:09.618263 23230 net.cpp:100] Creating Layer conv4_3_norm
I0722 00:57:09.618268 23230 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0722 00:57:09.618278 23230 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0722 00:57:09.618567 23230 net.cpp:150] Setting up conv4_3_norm
I0722 00:57:09.618579 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.618583 23230 net.cpp:165] Memory required for data: 5521367072
I0722 00:57:09.618590 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:09.618598 23230 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:09.618602 23230 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0722 00:57:09.618611 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0722 00:57:09.618619 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0722 00:57:09.618628 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0722 00:57:09.618691 23230 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:09.618700 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.618705 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.618710 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.618712 23230 net.cpp:165] Memory required for data: 5722693664
I0722 00:57:09.618716 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:09.618732 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:09.618737 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018 <- conv4_3_norm_conv4_3_norm_0_split_0
I0722 00:57:09.618744 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:09.625977 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:09.625999 23230 net.cpp:157] Top shape: 2 16 128 128 (524288)
I0722 00:57:09.626004 23230 net.cpp:165] Memory required for data: 5724790816
I0722 00:57:09.626015 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.626026 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.626032 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 <- conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:09.626042 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.626219 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.626232 23230 net.cpp:157] Top shape: 2 128 128 16 (524288)
I0722 00:57:09.626253 23230 net.cpp:165] Memory required for data: 5726887968
I0722 00:57:09.626258 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.626271 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.626277 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 <- conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.626287 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.626346 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.626356 23230 net.cpp:157] Top shape: 2 262144 (524288)
I0722 00:57:09.626360 23230 net.cpp:165] Memory required for data: 5728985120
I0722 00:57:09.626364 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:09.626399 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:09.626406 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new <- conv4_3_norm_conv4_3_norm_0_split_1
I0722 00:57:09.626415 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:09.635994 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:09.636030 23230 net.cpp:157] Top shape: 2 36 128 128 (1179648)
I0722 00:57:09.636041 23230 net.cpp:165] Memory required for data: 5733703712
I0722 00:57:09.636067 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.636078 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.636085 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:09.636095 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.636256 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.636266 23230 net.cpp:157] Top shape: 2 128 128 36 (1179648)
I0722 00:57:09.636270 23230 net.cpp:165] Memory required for data: 5738422304
I0722 00:57:09.636274 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.636282 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.636287 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.636296 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.636332 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.636340 23230 net.cpp:157] Top shape: 2 589824 (1179648)
I0722 00:57:09.636344 23230 net.cpp:165] Memory required for data: 5743140896
I0722 00:57:09.636348 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0722 00:57:09.636358 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0722 00:57:09.636361 23230 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0722 00:57:09.636368 23230 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0722 00:57:09.636378 23230 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0722 00:57:09.636420 23230 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0722 00:57:09.636428 23230 net.cpp:157] Top shape: 1 2 262144 (524288)
I0722 00:57:09.636432 23230 net.cpp:165] Memory required for data: 5745238048
I0722 00:57:09.636438 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018
I0722 00:57:09.636453 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018
I0722 00:57:09.636461 23230 net.cpp:434] fc7_mbox_loc_bdc2018 <- fc7_relu7_0_split_1
I0722 00:57:09.636472 23230 net.cpp:408] fc7_mbox_loc_bdc2018 -> fc7_mbox_loc_bdc2018
I0722 00:57:09.642771 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018
I0722 00:57:09.642805 23230 net.cpp:157] Top shape: 2 24 64 64 (196608)
I0722 00:57:09.642810 23230 net.cpp:165] Memory required for data: 5746024480
I0722 00:57:09.642819 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.642828 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.642837 23230 net.cpp:434] fc7_mbox_loc_bdc2018_perm_bdc2018 <- fc7_mbox_loc_bdc2018
I0722 00:57:09.642846 23230 net.cpp:408] fc7_mbox_loc_bdc2018_perm_bdc2018 -> fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.643003 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.643013 23230 net.cpp:157] Top shape: 2 64 64 24 (196608)
I0722 00:57:09.643018 23230 net.cpp:165] Memory required for data: 5746810912
I0722 00:57:09.643021 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.643029 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.643033 23230 net.cpp:434] fc7_mbox_loc_bdc2018_flat_bdc2018 <- fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.643043 23230 net.cpp:408] fc7_mbox_loc_bdc2018_flat_bdc2018 -> fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.643077 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.643086 23230 net.cpp:157] Top shape: 2 98304 (196608)
I0722 00:57:09.643090 23230 net.cpp:165] Memory required for data: 5747597344
I0722 00:57:09.643095 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new
I0722 00:57:09.643110 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new
I0722 00:57:09.643117 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new <- fc7_relu7_0_split_2
I0722 00:57:09.643127 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new -> fc7_mbox_conf_bdc2018_new
I0722 00:57:09.658493 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new
I0722 00:57:09.658514 23230 net.cpp:157] Top shape: 2 54 64 64 (442368)
I0722 00:57:09.658519 23230 net.cpp:165] Memory required for data: 5749366816
I0722 00:57:09.658529 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.658543 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.658551 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new <- fc7_mbox_conf_bdc2018_new
I0722 00:57:09.658560 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new -> fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.658725 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.658735 23230 net.cpp:157] Top shape: 2 64 64 54 (442368)
I0722 00:57:09.658740 23230 net.cpp:165] Memory required for data: 5751136288
I0722 00:57:09.658743 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.658753 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.658758 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new <- fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.658766 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new -> fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.658802 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.658810 23230 net.cpp:157] Top shape: 2 221184 (442368)
I0722 00:57:09.658814 23230 net.cpp:165] Memory required for data: 5752905760
I0722 00:57:09.658820 23230 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0722 00:57:09.658831 23230 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0722 00:57:09.658835 23230 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0722 00:57:09.658841 23230 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0722 00:57:09.658850 23230 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0722 00:57:09.658885 23230 net.cpp:150] Setting up fc7_mbox_priorbox
I0722 00:57:09.658895 23230 net.cpp:157] Top shape: 1 2 98304 (196608)
I0722 00:57:09.658898 23230 net.cpp:165] Memory required for data: 5753692192
I0722 00:57:09.658902 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018
I0722 00:57:09.658937 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018
I0722 00:57:09.658946 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018 <- conv6_2_conv6_2_relu_0_split_1
I0722 00:57:09.658953 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018 -> conv6_2_mbox_loc_bdc2018
I0722 00:57:09.664613 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018
I0722 00:57:09.664634 23230 net.cpp:157] Top shape: 2 24 32 32 (49152)
I0722 00:57:09.664639 23230 net.cpp:165] Memory required for data: 5753888800
I0722 00:57:09.664649 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.664656 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.664662 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018_perm_bdc2018 <- conv6_2_mbox_loc_bdc2018
I0722 00:57:09.664672 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018_perm_bdc2018 -> conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.664834 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.664846 23230 net.cpp:157] Top shape: 2 32 32 24 (49152)
I0722 00:57:09.664850 23230 net.cpp:165] Memory required for data: 5754085408
I0722 00:57:09.664857 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.664865 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.664870 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018_flat_bdc2018 <- conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.664880 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018_flat_bdc2018 -> conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.664913 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.664921 23230 net.cpp:157] Top shape: 2 24576 (49152)
I0722 00:57:09.664925 23230 net.cpp:165] Memory required for data: 5754282016
I0722 00:57:09.664929 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new
I0722 00:57:09.664945 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new
I0722 00:57:09.664952 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new <- conv6_2_conv6_2_relu_0_split_2
I0722 00:57:09.664959 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new
I0722 00:57:09.673449 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new
I0722 00:57:09.673472 23230 net.cpp:157] Top shape: 2 54 32 32 (110592)
I0722 00:57:09.673477 23230 net.cpp:165] Memory required for data: 5754724384
I0722 00:57:09.673486 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.673501 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.673507 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv6_2_mbox_conf_bdc2018_new
I0722 00:57:09.673517 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.673671 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.673681 23230 net.cpp:157] Top shape: 2 32 32 54 (110592)
I0722 00:57:09.673684 23230 net.cpp:165] Memory required for data: 5755166752
I0722 00:57:09.673689 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.673697 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.673702 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.673710 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.673745 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.673754 23230 net.cpp:157] Top shape: 2 55296 (110592)
I0722 00:57:09.673758 23230 net.cpp:165] Memory required for data: 5755609120
I0722 00:57:09.673761 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0722 00:57:09.673769 23230 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0722 00:57:09.673790 23230 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0722 00:57:09.673797 23230 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0722 00:57:09.673806 23230 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0722 00:57:09.673847 23230 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0722 00:57:09.673857 23230 net.cpp:157] Top shape: 1 2 24576 (49152)
I0722 00:57:09.673861 23230 net.cpp:165] Memory required for data: 5755805728
I0722 00:57:09.673864 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018
I0722 00:57:09.673879 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018
I0722 00:57:09.673887 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018 <- conv7_2_conv7_2_relu_0_split_1
I0722 00:57:09.673894 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018 -> conv7_2_mbox_loc_bdc2018
I0722 00:57:09.680235 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018
I0722 00:57:09.680258 23230 net.cpp:157] Top shape: 2 24 16 16 (12288)
I0722 00:57:09.680263 23230 net.cpp:165] Memory required for data: 5755854880
I0722 00:57:09.680274 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.680282 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.680287 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018_perm_bdc2018 <- conv7_2_mbox_loc_bdc2018
I0722 00:57:09.680297 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018_perm_bdc2018 -> conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.680445 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.680455 23230 net.cpp:157] Top shape: 2 16 16 24 (12288)
I0722 00:57:09.680459 23230 net.cpp:165] Memory required for data: 5755904032
I0722 00:57:09.680462 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.680472 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.680476 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018_flat_bdc2018 <- conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.680482 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018_flat_bdc2018 -> conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.680516 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.680523 23230 net.cpp:157] Top shape: 2 6144 (12288)
I0722 00:57:09.680527 23230 net.cpp:165] Memory required for data: 5755953184
I0722 00:57:09.680531 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new
I0722 00:57:09.680543 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new
I0722 00:57:09.680552 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new <- conv7_2_conv7_2_relu_0_split_2
I0722 00:57:09.680559 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new
I0722 00:57:09.683831 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new
I0722 00:57:09.683854 23230 net.cpp:157] Top shape: 2 54 16 16 (27648)
I0722 00:57:09.683859 23230 net.cpp:165] Memory required for data: 5756063776
I0722 00:57:09.683871 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.683881 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.683887 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv7_2_mbox_conf_bdc2018_new
I0722 00:57:09.683895 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.684038 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.684048 23230 net.cpp:157] Top shape: 2 16 16 54 (27648)
I0722 00:57:09.684051 23230 net.cpp:165] Memory required for data: 5756174368
I0722 00:57:09.684056 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.684065 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.684070 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.684095 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.684132 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.684140 23230 net.cpp:157] Top shape: 2 13824 (27648)
I0722 00:57:09.684144 23230 net.cpp:165] Memory required for data: 5756284960
I0722 00:57:09.684147 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0722 00:57:09.684159 23230 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0722 00:57:09.684166 23230 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0722 00:57:09.684172 23230 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0722 00:57:09.684180 23230 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0722 00:57:09.684213 23230 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0722 00:57:09.684222 23230 net.cpp:157] Top shape: 1 2 6144 (12288)
I0722 00:57:09.684226 23230 net.cpp:165] Memory required for data: 5756334112
I0722 00:57:09.684231 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018
I0722 00:57:09.684247 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018
I0722 00:57:09.684254 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018 <- conv8_2_conv8_2_relu_0_split_1
I0722 00:57:09.684262 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018 -> conv8_2_mbox_loc_bdc2018
I0722 00:57:09.686100 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018
I0722 00:57:09.686117 23230 net.cpp:157] Top shape: 2 16 14 14 (6272)
I0722 00:57:09.686122 23230 net.cpp:165] Memory required for data: 5756359200
I0722 00:57:09.686144 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.686156 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.686162 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018_perm_bdc2018 <- conv8_2_mbox_loc_bdc2018
I0722 00:57:09.686169 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018_perm_bdc2018 -> conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.686319 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.686329 23230 net.cpp:157] Top shape: 2 14 14 16 (6272)
I0722 00:57:09.686332 23230 net.cpp:165] Memory required for data: 5756384288
I0722 00:57:09.686336 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.686344 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.686348 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018_flat_bdc2018 <- conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.686357 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018_flat_bdc2018 -> conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.686393 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.686401 23230 net.cpp:157] Top shape: 2 3136 (6272)
I0722 00:57:09.686404 23230 net.cpp:165] Memory required for data: 5756409376
I0722 00:57:09.686409 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new
I0722 00:57:09.686422 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new
I0722 00:57:09.686426 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new <- conv8_2_conv8_2_relu_0_split_2
I0722 00:57:09.686434 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new
I0722 00:57:09.688460 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new
I0722 00:57:09.688478 23230 net.cpp:157] Top shape: 2 36 14 14 (14112)
I0722 00:57:09.688482 23230 net.cpp:165] Memory required for data: 5756465824
I0722 00:57:09.688490 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.688501 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.688506 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv8_2_mbox_conf_bdc2018_new
I0722 00:57:09.688513 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.688684 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.688694 23230 net.cpp:157] Top shape: 2 14 14 36 (14112)
I0722 00:57:09.688697 23230 net.cpp:165] Memory required for data: 5756522272
I0722 00:57:09.688701 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.688711 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.688716 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.688722 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.688757 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.688766 23230 net.cpp:157] Top shape: 2 7056 (14112)
I0722 00:57:09.688769 23230 net.cpp:165] Memory required for data: 5756578720
I0722 00:57:09.688774 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0722 00:57:09.688784 23230 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0722 00:57:09.688788 23230 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0722 00:57:09.688794 23230 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0722 00:57:09.688802 23230 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0722 00:57:09.688836 23230 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0722 00:57:09.688844 23230 net.cpp:157] Top shape: 1 2 3136 (6272)
I0722 00:57:09.688848 23230 net.cpp:165] Memory required for data: 5756603808
I0722 00:57:09.688851 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018
I0722 00:57:09.688868 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018
I0722 00:57:09.688874 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018 <- conv9_2_conv9_2_relu_0_split_0
I0722 00:57:09.688880 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018 -> conv9_2_mbox_loc_bdc2018
I0722 00:57:09.692164 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018
I0722 00:57:09.692185 23230 net.cpp:157] Top shape: 2 16 12 12 (4608)
I0722 00:57:09.692190 23230 net.cpp:165] Memory required for data: 5756622240
I0722 00:57:09.692198 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.692209 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.692215 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018_perm_bdc2018 <- conv9_2_mbox_loc_bdc2018
I0722 00:57:09.692229 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018_perm_bdc2018 -> conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.692378 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.692389 23230 net.cpp:157] Top shape: 2 12 12 16 (4608)
I0722 00:57:09.692392 23230 net.cpp:165] Memory required for data: 5756640672
I0722 00:57:09.692396 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.692404 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.692409 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018_flat_bdc2018 <- conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:09.692417 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018_flat_bdc2018 -> conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.692452 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.692461 23230 net.cpp:157] Top shape: 2 2304 (4608)
I0722 00:57:09.692464 23230 net.cpp:165] Memory required for data: 5756659104
I0722 00:57:09.692469 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new
I0722 00:57:09.692484 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new
I0722 00:57:09.692489 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new <- conv9_2_conv9_2_relu_0_split_1
I0722 00:57:09.692498 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new
I0722 00:57:09.694639 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new
I0722 00:57:09.694660 23230 net.cpp:157] Top shape: 2 36 12 12 (10368)
I0722 00:57:09.694680 23230 net.cpp:165] Memory required for data: 5756700576
I0722 00:57:09.694690 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.694699 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.694705 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv9_2_mbox_conf_bdc2018_new
I0722 00:57:09.694715 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.694866 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.694875 23230 net.cpp:157] Top shape: 2 12 12 36 (10368)
I0722 00:57:09.694880 23230 net.cpp:165] Memory required for data: 5756742048
I0722 00:57:09.694882 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.694890 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.694895 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:09.694903 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.694938 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.694947 23230 net.cpp:157] Top shape: 2 5184 (10368)
I0722 00:57:09.694950 23230 net.cpp:165] Memory required for data: 5756783520
I0722 00:57:09.694953 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0722 00:57:09.694963 23230 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0722 00:57:09.694967 23230 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0722 00:57:09.694972 23230 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0722 00:57:09.694981 23230 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0722 00:57:09.695019 23230 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0722 00:57:09.695026 23230 net.cpp:157] Top shape: 1 2 2304 (4608)
I0722 00:57:09.695029 23230 net.cpp:165] Memory required for data: 5756801952
I0722 00:57:09.695034 23230 layer_factory.hpp:77] Creating layer mbox_loc
I0722 00:57:09.695041 23230 net.cpp:100] Creating Layer mbox_loc
I0722 00:57:09.695045 23230 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695051 23230 net.cpp:434] mbox_loc <- fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695056 23230 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695061 23230 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695065 23230 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695070 23230 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:09.695080 23230 net.cpp:408] mbox_loc -> mbox_loc
I0722 00:57:09.695116 23230 net.cpp:150] Setting up mbox_loc
I0722 00:57:09.695125 23230 net.cpp:157] Top shape: 2 396608 (793216)
I0722 00:57:09.695129 23230 net.cpp:165] Memory required for data: 5759974816
I0722 00:57:09.695132 23230 layer_factory.hpp:77] Creating layer mbox_conf
I0722 00:57:09.695139 23230 net.cpp:100] Creating Layer mbox_conf
I0722 00:57:09.695143 23230 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695149 23230 net.cpp:434] mbox_conf <- fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695154 23230 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695159 23230 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695163 23230 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695168 23230 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:09.695173 23230 net.cpp:408] mbox_conf -> mbox_conf
I0722 00:57:09.695207 23230 net.cpp:150] Setting up mbox_conf
I0722 00:57:09.695215 23230 net.cpp:157] Top shape: 2 892368 (1784736)
I0722 00:57:09.695230 23230 net.cpp:165] Memory required for data: 5767113760
I0722 00:57:09.695235 23230 layer_factory.hpp:77] Creating layer mbox_priorbox
I0722 00:57:09.695245 23230 net.cpp:100] Creating Layer mbox_priorbox
I0722 00:57:09.695250 23230 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0722 00:57:09.695255 23230 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0722 00:57:09.695260 23230 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0722 00:57:09.695264 23230 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0722 00:57:09.695268 23230 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0722 00:57:09.695272 23230 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0722 00:57:09.695278 23230 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0722 00:57:09.695314 23230 net.cpp:150] Setting up mbox_priorbox
I0722 00:57:09.695322 23230 net.cpp:157] Top shape: 1 2 396608 (793216)
I0722 00:57:09.695325 23230 net.cpp:165] Memory required for data: 5770286624
I0722 00:57:09.695329 23230 layer_factory.hpp:77] Creating layer mbox_loss
I0722 00:57:09.695343 23230 net.cpp:100] Creating Layer mbox_loss
I0722 00:57:09.695348 23230 net.cpp:434] mbox_loss <- mbox_loc
I0722 00:57:09.695353 23230 net.cpp:434] mbox_loss <- mbox_conf
I0722 00:57:09.695358 23230 net.cpp:434] mbox_loss <- mbox_priorbox
I0722 00:57:09.695361 23230 net.cpp:434] mbox_loss <- label
I0722 00:57:09.695369 23230 net.cpp:408] mbox_loss -> mbox_loss
I0722 00:57:09.695452 23230 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0722 00:57:09.695580 23230 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0722 00:57:09.695595 23230 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0722 00:57:09.696226 23230 net.cpp:150] Setting up mbox_loss
I0722 00:57:09.696245 23230 net.cpp:157] Top shape: (1)
I0722 00:57:09.696249 23230 net.cpp:160]     with loss weight 1
I0722 00:57:09.696279 23230 net.cpp:165] Memory required for data: 5770286628
I0722 00:57:09.696283 23230 net.cpp:226] mbox_loss needs backward computation.
I0722 00:57:09.696293 23230 net.cpp:228] mbox_priorbox does not need backward computation.
I0722 00:57:09.696301 23230 net.cpp:226] mbox_conf needs backward computation.
I0722 00:57:09.696308 23230 net.cpp:226] mbox_loc needs backward computation.
I0722 00:57:09.696316 23230 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0722 00:57:09.696322 23230 net.cpp:226] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696327 23230 net.cpp:226] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696332 23230 net.cpp:226] conv9_2_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696336 23230 net.cpp:226] conv9_2_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696341 23230 net.cpp:226] conv9_2_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696344 23230 net.cpp:226] conv9_2_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696348 23230 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0722 00:57:09.696358 23230 net.cpp:226] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696362 23230 net.cpp:226] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696367 23230 net.cpp:226] conv8_2_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696370 23230 net.cpp:226] conv8_2_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696374 23230 net.cpp:226] conv8_2_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696378 23230 net.cpp:226] conv8_2_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696382 23230 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0722 00:57:09.696388 23230 net.cpp:226] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696393 23230 net.cpp:226] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696408 23230 net.cpp:226] conv7_2_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696413 23230 net.cpp:226] conv7_2_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696418 23230 net.cpp:226] conv7_2_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696424 23230 net.cpp:226] conv7_2_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696429 23230 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0722 00:57:09.696434 23230 net.cpp:226] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696439 23230 net.cpp:226] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696441 23230 net.cpp:226] conv6_2_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696446 23230 net.cpp:226] conv6_2_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696449 23230 net.cpp:226] conv6_2_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696454 23230 net.cpp:226] conv6_2_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696458 23230 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0722 00:57:09.696465 23230 net.cpp:226] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696470 23230 net.cpp:226] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696473 23230 net.cpp:226] fc7_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696477 23230 net.cpp:226] fc7_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696481 23230 net.cpp:226] fc7_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696486 23230 net.cpp:226] fc7_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696491 23230 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0722 00:57:09.696496 23230 net.cpp:226] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new needs backward computation.
I0722 00:57:09.696501 23230 net.cpp:226] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new needs backward computation.
I0722 00:57:09.696504 23230 net.cpp:226] conv4_3_norm_mbox_conf_bdc2018_new needs backward computation.
I0722 00:57:09.696509 23230 net.cpp:226] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 needs backward computation.
I0722 00:57:09.696513 23230 net.cpp:226] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 needs backward computation.
I0722 00:57:09.696517 23230 net.cpp:226] conv4_3_norm_mbox_loc_bdc2018 needs backward computation.
I0722 00:57:09.696521 23230 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0722 00:57:09.696527 23230 net.cpp:226] conv4_3_norm needs backward computation.
I0722 00:57:09.696532 23230 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0722 00:57:09.696537 23230 net.cpp:226] conv9_2_relu needs backward computation.
I0722 00:57:09.696540 23230 net.cpp:226] conv9_2 needs backward computation.
I0722 00:57:09.696544 23230 net.cpp:226] conv9_1_relu needs backward computation.
I0722 00:57:09.696547 23230 net.cpp:226] conv9_1 needs backward computation.
I0722 00:57:09.696552 23230 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0722 00:57:09.696555 23230 net.cpp:226] conv8_2_relu needs backward computation.
I0722 00:57:09.696559 23230 net.cpp:226] conv8_2 needs backward computation.
I0722 00:57:09.696563 23230 net.cpp:226] conv8_1_relu needs backward computation.
I0722 00:57:09.696566 23230 net.cpp:226] conv8_1 needs backward computation.
I0722 00:57:09.696570 23230 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0722 00:57:09.696574 23230 net.cpp:226] conv7_2_relu needs backward computation.
I0722 00:57:09.696578 23230 net.cpp:226] conv7_2 needs backward computation.
I0722 00:57:09.696583 23230 net.cpp:226] conv7_1_relu needs backward computation.
I0722 00:57:09.696585 23230 net.cpp:226] conv7_1 needs backward computation.
I0722 00:57:09.696596 23230 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0722 00:57:09.696600 23230 net.cpp:226] conv6_2_relu needs backward computation.
I0722 00:57:09.696604 23230 net.cpp:226] conv6_2 needs backward computation.
I0722 00:57:09.696609 23230 net.cpp:226] conv6_1_relu needs backward computation.
I0722 00:57:09.696612 23230 net.cpp:226] conv6_1 needs backward computation.
I0722 00:57:09.696617 23230 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0722 00:57:09.696621 23230 net.cpp:226] relu7 needs backward computation.
I0722 00:57:09.696625 23230 net.cpp:226] fc7 needs backward computation.
I0722 00:57:09.696630 23230 net.cpp:226] relu6 needs backward computation.
I0722 00:57:09.696633 23230 net.cpp:226] fc6 needs backward computation.
I0722 00:57:09.696637 23230 net.cpp:226] pool5 needs backward computation.
I0722 00:57:09.696641 23230 net.cpp:226] relu5_3 needs backward computation.
I0722 00:57:09.696645 23230 net.cpp:226] conv5_3 needs backward computation.
I0722 00:57:09.696650 23230 net.cpp:226] relu5_2 needs backward computation.
I0722 00:57:09.696653 23230 net.cpp:226] conv5_2 needs backward computation.
I0722 00:57:09.696657 23230 net.cpp:226] relu5_1 needs backward computation.
I0722 00:57:09.696661 23230 net.cpp:226] conv5_1 needs backward computation.
I0722 00:57:09.696665 23230 net.cpp:226] pool4 needs backward computation.
I0722 00:57:09.696671 23230 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0722 00:57:09.696676 23230 net.cpp:226] relu4_3 needs backward computation.
I0722 00:57:09.696689 23230 net.cpp:226] conv4_3 needs backward computation.
I0722 00:57:09.696693 23230 net.cpp:226] relu4_2 needs backward computation.
I0722 00:57:09.696697 23230 net.cpp:226] conv4_2 needs backward computation.
I0722 00:57:09.696707 23230 net.cpp:226] relu4_1 needs backward computation.
I0722 00:57:09.696710 23230 net.cpp:226] conv4_1 needs backward computation.
I0722 00:57:09.696718 23230 net.cpp:226] pool3 needs backward computation.
I0722 00:57:09.696723 23230 net.cpp:226] relu3_3 needs backward computation.
I0722 00:57:09.696732 23230 net.cpp:226] conv3_3 needs backward computation.
I0722 00:57:09.696735 23230 net.cpp:226] relu3_2 needs backward computation.
I0722 00:57:09.696739 23230 net.cpp:226] conv3_2 needs backward computation.
I0722 00:57:09.696743 23230 net.cpp:226] relu3_1 needs backward computation.
I0722 00:57:09.696748 23230 net.cpp:226] conv3_1 needs backward computation.
I0722 00:57:09.696755 23230 net.cpp:226] pool2 needs backward computation.
I0722 00:57:09.696760 23230 net.cpp:226] relu2_2 needs backward computation.
I0722 00:57:09.696768 23230 net.cpp:226] conv2_2 needs backward computation.
I0722 00:57:09.696772 23230 net.cpp:226] relu2_1 needs backward computation.
I0722 00:57:09.696776 23230 net.cpp:226] conv2_1 needs backward computation.
I0722 00:57:09.696780 23230 net.cpp:226] pool1 needs backward computation.
I0722 00:57:09.696784 23230 net.cpp:226] relu1_2 needs backward computation.
I0722 00:57:09.696792 23230 net.cpp:226] conv1_2 needs backward computation.
I0722 00:57:09.696801 23230 net.cpp:226] relu1_1 needs backward computation.
I0722 00:57:09.696805 23230 net.cpp:226] conv1_1 needs backward computation.
I0722 00:57:09.696812 23230 net.cpp:228] data_data_0_split does not need backward computation.
I0722 00:57:09.696817 23230 net.cpp:228] data does not need backward computation.
I0722 00:57:09.696820 23230 net.cpp:270] This network produces output mbox_loss
I0722 00:57:09.696931 23230 net.cpp:283] Network initialization done.
I0722 00:57:09.698315 23230 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/VOC0712/SSD_1024x1024/test.prototxt
I0722 00:57:09.699163 23230 net.cpp:58] Initializing net from parameters: 
name: "VGG_VOC0712_SSD_1024x1024_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 1024
      width: 1024
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "examples/bdc2018/bdc2018_val_name_lmdb"
    batch_size: 2
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/bdc2018/labelmap_bdc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc_bdc2018"
  top: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new"
  top: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 102.4
    max_size: 204.8
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "fc7_mbox_loc_bdc2018"
  top: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "fc7_mbox_loc_bdc2018_perm_bdc2018"
  top: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "fc7_mbox_conf_bdc2018_new"
  top: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "fc7_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 204.8
    max_size: 378.88
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv6_2_mbox_loc_bdc2018"
  top: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv6_2_mbox_conf_bdc2018_new"
  top: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 378.88
    max_size: 552.96
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv7_2_mbox_loc_bdc2018"
  top: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 54
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv7_2_mbox_conf_bdc2018_new"
  top: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 552.96
    max_size: 727.04
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv8_2_mbox_loc_bdc2018"
  top: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv8_2_mbox_conf_bdc2018_new"
  top: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 727.04
    max_size: 901.12
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc_bdc2018"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  type: "Permute"
  bottom: "conv9_2_mbox_loc_bdc2018"
  top: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_bdc2018_perm_bdc2018"
  top: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf_bdc2018_new"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  type: "Permute"
  bottom: "conv9_2_mbox_conf_bdc2018_new"
  top: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new"
  top: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 901.12
    max_size: 1075.2
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "fc7_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv6_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv7_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv8_2_mbox_loc_bdc2018_flat_bdc2018"
  bottom: "conv9_2_mbox_loc_bdc2018_flat_bdc2018"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "fc7_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  bottom: "conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 9
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 9
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/user/data/bdc2018/results/SSD_1024x1024/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/bdc2018/labelmap_bdc.prototxt"
      name_size_file: "data/bdc2018/val_name_size.txt"
      num_test_image: 37
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 9
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/bdc2018/val_name_size.txt"
  }
}
I0722 00:57:09.699631 23230 layer_factory.hpp:77] Creating layer data
I0722 00:57:09.699723 23230 net.cpp:100] Creating Layer data
I0722 00:57:09.699734 23230 net.cpp:408] data -> data
I0722 00:57:09.699745 23230 net.cpp:408] data -> label
I0722 00:57:09.701031 23238 db_lmdb.cpp:35] Opened lmdb examples/bdc2018/bdc2018_val_name_lmdb
I0722 00:57:09.705873 23230 annotated_data_layer.cpp:62] output data size: 2,3,1024,1024
I0722 00:57:09.759591 23230 net.cpp:150] Setting up data
I0722 00:57:09.759637 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.759644 23230 net.cpp:157] Top shape: 1 1 1 8 (8)
I0722 00:57:09.759647 23230 net.cpp:165] Memory required for data: 25165856
I0722 00:57:09.759656 23230 layer_factory.hpp:77] Creating layer data_data_0_split
I0722 00:57:09.759677 23230 net.cpp:100] Creating Layer data_data_0_split
I0722 00:57:09.759683 23230 net.cpp:434] data_data_0_split <- data
I0722 00:57:09.759694 23230 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0722 00:57:09.759712 23230 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0722 00:57:09.759722 23230 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0722 00:57:09.759732 23230 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0722 00:57:09.759739 23230 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0722 00:57:09.759747 23230 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0722 00:57:09.759752 23230 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0722 00:57:09.759995 23230 net.cpp:150] Setting up data_data_0_split
I0722 00:57:09.760008 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760013 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760018 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760022 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760026 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760030 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760035 23230 net.cpp:157] Top shape: 2 3 1024 1024 (6291456)
I0722 00:57:09.760038 23230 net.cpp:165] Memory required for data: 201326624
I0722 00:57:09.760042 23230 layer_factory.hpp:77] Creating layer conv1_1
I0722 00:57:09.760059 23230 net.cpp:100] Creating Layer conv1_1
I0722 00:57:09.760066 23230 net.cpp:434] conv1_1 <- data_data_0_split_0
I0722 00:57:09.760076 23230 net.cpp:408] conv1_1 -> conv1_1
I0722 00:57:09.770159 23230 net.cpp:150] Setting up conv1_1
I0722 00:57:09.770177 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.770182 23230 net.cpp:165] Memory required for data: 738197536
I0722 00:57:09.770197 23230 layer_factory.hpp:77] Creating layer relu1_1
I0722 00:57:09.770208 23230 net.cpp:100] Creating Layer relu1_1
I0722 00:57:09.770213 23230 net.cpp:434] relu1_1 <- conv1_1
I0722 00:57:09.770220 23230 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0722 00:57:09.770457 23230 net.cpp:150] Setting up relu1_1
I0722 00:57:09.770470 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.770473 23230 net.cpp:165] Memory required for data: 1275068448
I0722 00:57:09.770478 23230 layer_factory.hpp:77] Creating layer conv1_2
I0722 00:57:09.770493 23230 net.cpp:100] Creating Layer conv1_2
I0722 00:57:09.770498 23230 net.cpp:434] conv1_2 <- conv1_1
I0722 00:57:09.770507 23230 net.cpp:408] conv1_2 -> conv1_2
I0722 00:57:09.783227 23230 net.cpp:150] Setting up conv1_2
I0722 00:57:09.783254 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.783258 23230 net.cpp:165] Memory required for data: 1811939360
I0722 00:57:09.783272 23230 layer_factory.hpp:77] Creating layer relu1_2
I0722 00:57:09.783285 23230 net.cpp:100] Creating Layer relu1_2
I0722 00:57:09.783289 23230 net.cpp:434] relu1_2 <- conv1_2
I0722 00:57:09.783298 23230 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0722 00:57:09.783540 23230 net.cpp:150] Setting up relu1_2
I0722 00:57:09.783551 23230 net.cpp:157] Top shape: 2 64 1024 1024 (134217728)
I0722 00:57:09.783555 23230 net.cpp:165] Memory required for data: 2348810272
I0722 00:57:09.783560 23230 layer_factory.hpp:77] Creating layer pool1
I0722 00:57:09.783571 23230 net.cpp:100] Creating Layer pool1
I0722 00:57:09.783574 23230 net.cpp:434] pool1 <- conv1_2
I0722 00:57:09.783582 23230 net.cpp:408] pool1 -> pool1
I0722 00:57:09.783648 23230 net.cpp:150] Setting up pool1
I0722 00:57:09.783658 23230 net.cpp:157] Top shape: 2 64 512 512 (33554432)
I0722 00:57:09.783660 23230 net.cpp:165] Memory required for data: 2483028000
I0722 00:57:09.783664 23230 layer_factory.hpp:77] Creating layer conv2_1
I0722 00:57:09.783677 23230 net.cpp:100] Creating Layer conv2_1
I0722 00:57:09.783681 23230 net.cpp:434] conv2_1 <- pool1
I0722 00:57:09.783689 23230 net.cpp:408] conv2_1 -> conv2_1
I0722 00:57:09.790894 23230 net.cpp:150] Setting up conv2_1
I0722 00:57:09.790913 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.790918 23230 net.cpp:165] Memory required for data: 2751463456
I0722 00:57:09.790931 23230 layer_factory.hpp:77] Creating layer relu2_1
I0722 00:57:09.790944 23230 net.cpp:100] Creating Layer relu2_1
I0722 00:57:09.790951 23230 net.cpp:434] relu2_1 <- conv2_1
I0722 00:57:09.790958 23230 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0722 00:57:09.791193 23230 net.cpp:150] Setting up relu2_1
I0722 00:57:09.791208 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.791211 23230 net.cpp:165] Memory required for data: 3019898912
I0722 00:57:09.791237 23230 layer_factory.hpp:77] Creating layer conv2_2
I0722 00:57:09.791249 23230 net.cpp:100] Creating Layer conv2_2
I0722 00:57:09.791254 23230 net.cpp:434] conv2_2 <- conv2_1
I0722 00:57:09.791262 23230 net.cpp:408] conv2_2 -> conv2_2
I0722 00:57:09.800776 23230 net.cpp:150] Setting up conv2_2
I0722 00:57:09.800796 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.800801 23230 net.cpp:165] Memory required for data: 3288334368
I0722 00:57:09.800809 23230 layer_factory.hpp:77] Creating layer relu2_2
I0722 00:57:09.800818 23230 net.cpp:100] Creating Layer relu2_2
I0722 00:57:09.800824 23230 net.cpp:434] relu2_2 <- conv2_2
I0722 00:57:09.800832 23230 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0722 00:57:09.801069 23230 net.cpp:150] Setting up relu2_2
I0722 00:57:09.801082 23230 net.cpp:157] Top shape: 2 128 512 512 (67108864)
I0722 00:57:09.801086 23230 net.cpp:165] Memory required for data: 3556769824
I0722 00:57:09.801091 23230 layer_factory.hpp:77] Creating layer pool2
I0722 00:57:09.801100 23230 net.cpp:100] Creating Layer pool2
I0722 00:57:09.801103 23230 net.cpp:434] pool2 <- conv2_2
I0722 00:57:09.801110 23230 net.cpp:408] pool2 -> pool2
I0722 00:57:09.801174 23230 net.cpp:150] Setting up pool2
I0722 00:57:09.801184 23230 net.cpp:157] Top shape: 2 128 256 256 (16777216)
I0722 00:57:09.801188 23230 net.cpp:165] Memory required for data: 3623878688
I0722 00:57:09.801192 23230 layer_factory.hpp:77] Creating layer conv3_1
I0722 00:57:09.801203 23230 net.cpp:100] Creating Layer conv3_1
I0722 00:57:09.801208 23230 net.cpp:434] conv3_1 <- pool2
I0722 00:57:09.801215 23230 net.cpp:408] conv3_1 -> conv3_1
I0722 00:57:09.808404 23230 net.cpp:150] Setting up conv3_1
I0722 00:57:09.808426 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.808430 23230 net.cpp:165] Memory required for data: 3758096416
I0722 00:57:09.808445 23230 layer_factory.hpp:77] Creating layer relu3_1
I0722 00:57:09.808455 23230 net.cpp:100] Creating Layer relu3_1
I0722 00:57:09.808461 23230 net.cpp:434] relu3_1 <- conv3_1
I0722 00:57:09.808468 23230 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0722 00:57:09.808954 23230 net.cpp:150] Setting up relu3_1
I0722 00:57:09.808970 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.808974 23230 net.cpp:165] Memory required for data: 3892314144
I0722 00:57:09.808979 23230 layer_factory.hpp:77] Creating layer conv3_2
I0722 00:57:09.808990 23230 net.cpp:100] Creating Layer conv3_2
I0722 00:57:09.808997 23230 net.cpp:434] conv3_2 <- conv3_1
I0722 00:57:09.809005 23230 net.cpp:408] conv3_2 -> conv3_2
I0722 00:57:09.815508 23230 net.cpp:150] Setting up conv3_2
I0722 00:57:09.815528 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.815532 23230 net.cpp:165] Memory required for data: 4026531872
I0722 00:57:09.815541 23230 layer_factory.hpp:77] Creating layer relu3_2
I0722 00:57:09.815547 23230 net.cpp:100] Creating Layer relu3_2
I0722 00:57:09.815551 23230 net.cpp:434] relu3_2 <- conv3_2
I0722 00:57:09.815559 23230 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0722 00:57:09.815802 23230 net.cpp:150] Setting up relu3_2
I0722 00:57:09.815816 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.815819 23230 net.cpp:165] Memory required for data: 4160749600
I0722 00:57:09.815824 23230 layer_factory.hpp:77] Creating layer conv3_3
I0722 00:57:09.815842 23230 net.cpp:100] Creating Layer conv3_3
I0722 00:57:09.815848 23230 net.cpp:434] conv3_3 <- conv3_2
I0722 00:57:09.815855 23230 net.cpp:408] conv3_3 -> conv3_3
I0722 00:57:09.823336 23230 net.cpp:150] Setting up conv3_3
I0722 00:57:09.823355 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.823359 23230 net.cpp:165] Memory required for data: 4294967328
I0722 00:57:09.823369 23230 layer_factory.hpp:77] Creating layer relu3_3
I0722 00:57:09.823379 23230 net.cpp:100] Creating Layer relu3_3
I0722 00:57:09.823385 23230 net.cpp:434] relu3_3 <- conv3_3
I0722 00:57:09.823390 23230 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0722 00:57:09.823639 23230 net.cpp:150] Setting up relu3_3
I0722 00:57:09.823668 23230 net.cpp:157] Top shape: 2 256 256 256 (33554432)
I0722 00:57:09.823673 23230 net.cpp:165] Memory required for data: 4429185056
I0722 00:57:09.823676 23230 layer_factory.hpp:77] Creating layer pool3
I0722 00:57:09.823683 23230 net.cpp:100] Creating Layer pool3
I0722 00:57:09.823688 23230 net.cpp:434] pool3 <- conv3_3
I0722 00:57:09.823696 23230 net.cpp:408] pool3 -> pool3
I0722 00:57:09.823770 23230 net.cpp:150] Setting up pool3
I0722 00:57:09.823781 23230 net.cpp:157] Top shape: 2 256 128 128 (8388608)
I0722 00:57:09.823784 23230 net.cpp:165] Memory required for data: 4462739488
I0722 00:57:09.823787 23230 layer_factory.hpp:77] Creating layer conv4_1
I0722 00:57:09.823801 23230 net.cpp:100] Creating Layer conv4_1
I0722 00:57:09.823806 23230 net.cpp:434] conv4_1 <- pool3
I0722 00:57:09.823814 23230 net.cpp:408] conv4_1 -> conv4_1
I0722 00:57:09.834862 23230 net.cpp:150] Setting up conv4_1
I0722 00:57:09.834884 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.834888 23230 net.cpp:165] Memory required for data: 4529848352
I0722 00:57:09.834897 23230 layer_factory.hpp:77] Creating layer relu4_1
I0722 00:57:09.834903 23230 net.cpp:100] Creating Layer relu4_1
I0722 00:57:09.834908 23230 net.cpp:434] relu4_1 <- conv4_1
I0722 00:57:09.834913 23230 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0722 00:57:09.835152 23230 net.cpp:150] Setting up relu4_1
I0722 00:57:09.835165 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.835170 23230 net.cpp:165] Memory required for data: 4596957216
I0722 00:57:09.835173 23230 layer_factory.hpp:77] Creating layer conv4_2
I0722 00:57:09.835187 23230 net.cpp:100] Creating Layer conv4_2
I0722 00:57:09.835192 23230 net.cpp:434] conv4_2 <- conv4_1
I0722 00:57:09.835199 23230 net.cpp:408] conv4_2 -> conv4_2
I0722 00:57:09.857043 23230 net.cpp:150] Setting up conv4_2
I0722 00:57:09.857060 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.857064 23230 net.cpp:165] Memory required for data: 4664066080
I0722 00:57:09.857082 23230 layer_factory.hpp:77] Creating layer relu4_2
I0722 00:57:09.857091 23230 net.cpp:100] Creating Layer relu4_2
I0722 00:57:09.857095 23230 net.cpp:434] relu4_2 <- conv4_2
I0722 00:57:09.857103 23230 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0722 00:57:09.859169 23230 net.cpp:150] Setting up relu4_2
I0722 00:57:09.859182 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.859186 23230 net.cpp:165] Memory required for data: 4731174944
I0722 00:57:09.859190 23230 layer_factory.hpp:77] Creating layer conv4_3
I0722 00:57:09.859202 23230 net.cpp:100] Creating Layer conv4_3
I0722 00:57:09.859207 23230 net.cpp:434] conv4_3 <- conv4_2
I0722 00:57:09.859217 23230 net.cpp:408] conv4_3 -> conv4_3
I0722 00:57:09.881618 23230 net.cpp:150] Setting up conv4_3
I0722 00:57:09.881639 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.881644 23230 net.cpp:165] Memory required for data: 4798283808
I0722 00:57:09.881652 23230 layer_factory.hpp:77] Creating layer relu4_3
I0722 00:57:09.881660 23230 net.cpp:100] Creating Layer relu4_3
I0722 00:57:09.881664 23230 net.cpp:434] relu4_3 <- conv4_3
I0722 00:57:09.881670 23230 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0722 00:57:09.883677 23230 net.cpp:150] Setting up relu4_3
I0722 00:57:09.883692 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.883695 23230 net.cpp:165] Memory required for data: 4865392672
I0722 00:57:09.883699 23230 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0722 00:57:09.883710 23230 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0722 00:57:09.883714 23230 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0722 00:57:09.883723 23230 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0722 00:57:09.883730 23230 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0722 00:57:09.883798 23230 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0722 00:57:09.883807 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.883812 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:09.883834 23230 net.cpp:165] Memory required for data: 4999610400
I0722 00:57:09.883838 23230 layer_factory.hpp:77] Creating layer pool4
I0722 00:57:09.883849 23230 net.cpp:100] Creating Layer pool4
I0722 00:57:09.883853 23230 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0722 00:57:09.883859 23230 net.cpp:408] pool4 -> pool4
I0722 00:57:09.883922 23230 net.cpp:150] Setting up pool4
I0722 00:57:09.883931 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.883934 23230 net.cpp:165] Memory required for data: 5016387616
I0722 00:57:09.883939 23230 layer_factory.hpp:77] Creating layer conv5_1
I0722 00:57:09.883950 23230 net.cpp:100] Creating Layer conv5_1
I0722 00:57:09.883955 23230 net.cpp:434] conv5_1 <- pool4
I0722 00:57:09.883962 23230 net.cpp:408] conv5_1 -> conv5_1
I0722 00:57:09.907469 23230 net.cpp:150] Setting up conv5_1
I0722 00:57:09.907487 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.907493 23230 net.cpp:165] Memory required for data: 5033164832
I0722 00:57:09.907502 23230 layer_factory.hpp:77] Creating layer relu5_1
I0722 00:57:09.907510 23230 net.cpp:100] Creating Layer relu5_1
I0722 00:57:09.907515 23230 net.cpp:434] relu5_1 <- conv5_1
I0722 00:57:09.907521 23230 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0722 00:57:09.909517 23230 net.cpp:150] Setting up relu5_1
I0722 00:57:09.909536 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.909540 23230 net.cpp:165] Memory required for data: 5049942048
I0722 00:57:09.909544 23230 layer_factory.hpp:77] Creating layer conv5_2
I0722 00:57:09.909559 23230 net.cpp:100] Creating Layer conv5_2
I0722 00:57:09.909564 23230 net.cpp:434] conv5_2 <- conv5_1
I0722 00:57:09.909574 23230 net.cpp:408] conv5_2 -> conv5_2
I0722 00:57:09.933250 23230 net.cpp:150] Setting up conv5_2
I0722 00:57:09.933272 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.933276 23230 net.cpp:165] Memory required for data: 5066719264
I0722 00:57:09.933285 23230 layer_factory.hpp:77] Creating layer relu5_2
I0722 00:57:09.933295 23230 net.cpp:100] Creating Layer relu5_2
I0722 00:57:09.933300 23230 net.cpp:434] relu5_2 <- conv5_2
I0722 00:57:09.933305 23230 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0722 00:57:09.935314 23230 net.cpp:150] Setting up relu5_2
I0722 00:57:09.935329 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.935333 23230 net.cpp:165] Memory required for data: 5083496480
I0722 00:57:09.935336 23230 layer_factory.hpp:77] Creating layer conv5_3
I0722 00:57:09.935350 23230 net.cpp:100] Creating Layer conv5_3
I0722 00:57:09.935354 23230 net.cpp:434] conv5_3 <- conv5_2
I0722 00:57:09.935364 23230 net.cpp:408] conv5_3 -> conv5_3
I0722 00:57:09.959584 23230 net.cpp:150] Setting up conv5_3
I0722 00:57:09.959604 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.959609 23230 net.cpp:165] Memory required for data: 5100273696
I0722 00:57:09.959617 23230 layer_factory.hpp:77] Creating layer relu5_3
I0722 00:57:09.959638 23230 net.cpp:100] Creating Layer relu5_3
I0722 00:57:09.959643 23230 net.cpp:434] relu5_3 <- conv5_3
I0722 00:57:09.959650 23230 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0722 00:57:09.959895 23230 net.cpp:150] Setting up relu5_3
I0722 00:57:09.959908 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.959913 23230 net.cpp:165] Memory required for data: 5117050912
I0722 00:57:09.959916 23230 layer_factory.hpp:77] Creating layer pool5
I0722 00:57:09.959928 23230 net.cpp:100] Creating Layer pool5
I0722 00:57:09.959933 23230 net.cpp:434] pool5 <- conv5_3
I0722 00:57:09.959939 23230 net.cpp:408] pool5 -> pool5
I0722 00:57:09.960011 23230 net.cpp:150] Setting up pool5
I0722 00:57:09.960019 23230 net.cpp:157] Top shape: 2 512 64 64 (4194304)
I0722 00:57:09.960022 23230 net.cpp:165] Memory required for data: 5133828128
I0722 00:57:09.960026 23230 layer_factory.hpp:77] Creating layer fc6
I0722 00:57:09.960038 23230 net.cpp:100] Creating Layer fc6
I0722 00:57:09.960043 23230 net.cpp:434] fc6 <- pool5
I0722 00:57:09.960073 23230 net.cpp:408] fc6 -> fc6
I0722 00:57:09.998004 23230 net.cpp:150] Setting up fc6
I0722 00:57:09.998030 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.998035 23230 net.cpp:165] Memory required for data: 5167382560
I0722 00:57:09.998044 23230 layer_factory.hpp:77] Creating layer relu6
I0722 00:57:09.998064 23230 net.cpp:100] Creating Layer relu6
I0722 00:57:09.998070 23230 net.cpp:434] relu6 <- fc6
I0722 00:57:09.998077 23230 net.cpp:395] relu6 -> fc6 (in-place)
I0722 00:57:09.998368 23230 net.cpp:150] Setting up relu6
I0722 00:57:09.998383 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:09.998387 23230 net.cpp:165] Memory required for data: 5200936992
I0722 00:57:09.998391 23230 layer_factory.hpp:77] Creating layer fc7
I0722 00:57:09.998404 23230 net.cpp:100] Creating Layer fc7
I0722 00:57:09.998409 23230 net.cpp:434] fc7 <- fc6
I0722 00:57:09.998420 23230 net.cpp:408] fc7 -> fc7
I0722 00:57:10.013204 23230 net.cpp:150] Setting up fc7
I0722 00:57:10.013226 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.013231 23230 net.cpp:165] Memory required for data: 5234491424
I0722 00:57:10.013239 23230 layer_factory.hpp:77] Creating layer relu7
I0722 00:57:10.013248 23230 net.cpp:100] Creating Layer relu7
I0722 00:57:10.013253 23230 net.cpp:434] relu7 <- fc7
I0722 00:57:10.013262 23230 net.cpp:395] relu7 -> fc7 (in-place)
I0722 00:57:10.017782 23230 net.cpp:150] Setting up relu7
I0722 00:57:10.017817 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.017825 23230 net.cpp:165] Memory required for data: 5268045856
I0722 00:57:10.017833 23230 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0722 00:57:10.017850 23230 net.cpp:100] Creating Layer fc7_relu7_0_split
I0722 00:57:10.017860 23230 net.cpp:434] fc7_relu7_0_split <- fc7
I0722 00:57:10.017879 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0722 00:57:10.017899 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0722 00:57:10.017930 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0722 00:57:10.017947 23230 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0722 00:57:10.018110 23230 net.cpp:150] Setting up fc7_relu7_0_split
I0722 00:57:10.018126 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.018131 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.018136 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.018139 23230 net.cpp:157] Top shape: 2 1024 64 64 (8388608)
I0722 00:57:10.018143 23230 net.cpp:165] Memory required for data: 5402263584
I0722 00:57:10.018147 23230 layer_factory.hpp:77] Creating layer conv6_1
I0722 00:57:10.018162 23230 net.cpp:100] Creating Layer conv6_1
I0722 00:57:10.018167 23230 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0722 00:57:10.018177 23230 net.cpp:408] conv6_1 -> conv6_1
I0722 00:57:10.024518 23230 net.cpp:150] Setting up conv6_1
I0722 00:57:10.024535 23230 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0722 00:57:10.024540 23230 net.cpp:165] Memory required for data: 5410652192
I0722 00:57:10.024549 23230 layer_factory.hpp:77] Creating layer conv6_1_relu
I0722 00:57:10.024555 23230 net.cpp:100] Creating Layer conv6_1_relu
I0722 00:57:10.024560 23230 net.cpp:434] conv6_1_relu <- conv6_1
I0722 00:57:10.024569 23230 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0722 00:57:10.026345 23230 net.cpp:150] Setting up conv6_1_relu
I0722 00:57:10.026360 23230 net.cpp:157] Top shape: 2 256 64 64 (2097152)
I0722 00:57:10.026365 23230 net.cpp:165] Memory required for data: 5419040800
I0722 00:57:10.026370 23230 layer_factory.hpp:77] Creating layer conv6_2
I0722 00:57:10.026382 23230 net.cpp:100] Creating Layer conv6_2
I0722 00:57:10.026387 23230 net.cpp:434] conv6_2 <- conv6_1
I0722 00:57:10.026397 23230 net.cpp:408] conv6_2 -> conv6_2
I0722 00:57:10.040145 23230 net.cpp:150] Setting up conv6_2
I0722 00:57:10.040164 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.040169 23230 net.cpp:165] Memory required for data: 5423235104
I0722 00:57:10.040212 23230 layer_factory.hpp:77] Creating layer conv6_2_relu
I0722 00:57:10.040225 23230 net.cpp:100] Creating Layer conv6_2_relu
I0722 00:57:10.040228 23230 net.cpp:434] conv6_2_relu <- conv6_2
I0722 00:57:10.040235 23230 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0722 00:57:10.042245 23230 net.cpp:150] Setting up conv6_2_relu
I0722 00:57:10.042263 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.042266 23230 net.cpp:165] Memory required for data: 5427429408
I0722 00:57:10.042270 23230 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0722 00:57:10.042281 23230 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0722 00:57:10.042286 23230 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0722 00:57:10.042294 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0722 00:57:10.042302 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0722 00:57:10.042311 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0722 00:57:10.042317 23230 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0722 00:57:10.042428 23230 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0722 00:57:10.042438 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.042443 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.042446 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.042450 23230 net.cpp:157] Top shape: 2 512 32 32 (1048576)
I0722 00:57:10.042454 23230 net.cpp:165] Memory required for data: 5444206624
I0722 00:57:10.042457 23230 layer_factory.hpp:77] Creating layer conv7_1
I0722 00:57:10.042474 23230 net.cpp:100] Creating Layer conv7_1
I0722 00:57:10.042480 23230 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0722 00:57:10.042487 23230 net.cpp:408] conv7_1 -> conv7_1
I0722 00:57:10.049144 23230 net.cpp:150] Setting up conv7_1
I0722 00:57:10.049162 23230 net.cpp:157] Top shape: 2 128 32 32 (262144)
I0722 00:57:10.049166 23230 net.cpp:165] Memory required for data: 5445255200
I0722 00:57:10.049176 23230 layer_factory.hpp:77] Creating layer conv7_1_relu
I0722 00:57:10.049185 23230 net.cpp:100] Creating Layer conv7_1_relu
I0722 00:57:10.049190 23230 net.cpp:434] conv7_1_relu <- conv7_1
I0722 00:57:10.049198 23230 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0722 00:57:10.051208 23230 net.cpp:150] Setting up conv7_1_relu
I0722 00:57:10.051223 23230 net.cpp:157] Top shape: 2 128 32 32 (262144)
I0722 00:57:10.051228 23230 net.cpp:165] Memory required for data: 5446303776
I0722 00:57:10.051231 23230 layer_factory.hpp:77] Creating layer conv7_2
I0722 00:57:10.051244 23230 net.cpp:100] Creating Layer conv7_2
I0722 00:57:10.051249 23230 net.cpp:434] conv7_2 <- conv7_1
I0722 00:57:10.051259 23230 net.cpp:408] conv7_2 -> conv7_2
I0722 00:57:10.058094 23230 net.cpp:150] Setting up conv7_2
I0722 00:57:10.058115 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.058120 23230 net.cpp:165] Memory required for data: 5446828064
I0722 00:57:10.058127 23230 layer_factory.hpp:77] Creating layer conv7_2_relu
I0722 00:57:10.058135 23230 net.cpp:100] Creating Layer conv7_2_relu
I0722 00:57:10.058140 23230 net.cpp:434] conv7_2_relu <- conv7_2
I0722 00:57:10.058149 23230 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0722 00:57:10.060103 23230 net.cpp:150] Setting up conv7_2_relu
I0722 00:57:10.060119 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.060122 23230 net.cpp:165] Memory required for data: 5447352352
I0722 00:57:10.060127 23230 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0722 00:57:10.060135 23230 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0722 00:57:10.060139 23230 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0722 00:57:10.060148 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0722 00:57:10.060155 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0722 00:57:10.060163 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0722 00:57:10.060184 23230 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0722 00:57:10.060288 23230 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0722 00:57:10.060297 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.060302 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.060307 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.060312 23230 net.cpp:157] Top shape: 2 256 16 16 (131072)
I0722 00:57:10.060314 23230 net.cpp:165] Memory required for data: 5449449504
I0722 00:57:10.060320 23230 layer_factory.hpp:77] Creating layer conv8_1
I0722 00:57:10.060335 23230 net.cpp:100] Creating Layer conv8_1
I0722 00:57:10.060341 23230 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0722 00:57:10.060348 23230 net.cpp:408] conv8_1 -> conv8_1
I0722 00:57:10.066990 23230 net.cpp:150] Setting up conv8_1
I0722 00:57:10.067010 23230 net.cpp:157] Top shape: 2 128 16 16 (65536)
I0722 00:57:10.067014 23230 net.cpp:165] Memory required for data: 5449711648
I0722 00:57:10.067023 23230 layer_factory.hpp:77] Creating layer conv8_1_relu
I0722 00:57:10.067029 23230 net.cpp:100] Creating Layer conv8_1_relu
I0722 00:57:10.067034 23230 net.cpp:434] conv8_1_relu <- conv8_1
I0722 00:57:10.067041 23230 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0722 00:57:10.069056 23230 net.cpp:150] Setting up conv8_1_relu
I0722 00:57:10.069072 23230 net.cpp:157] Top shape: 2 128 16 16 (65536)
I0722 00:57:10.069075 23230 net.cpp:165] Memory required for data: 5449973792
I0722 00:57:10.069079 23230 layer_factory.hpp:77] Creating layer conv8_2
I0722 00:57:10.069092 23230 net.cpp:100] Creating Layer conv8_2
I0722 00:57:10.069097 23230 net.cpp:434] conv8_2 <- conv8_1
I0722 00:57:10.069103 23230 net.cpp:408] conv8_2 -> conv8_2
I0722 00:57:10.075963 23230 net.cpp:150] Setting up conv8_2
I0722 00:57:10.075984 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.075989 23230 net.cpp:165] Memory required for data: 5450375200
I0722 00:57:10.075996 23230 layer_factory.hpp:77] Creating layer conv8_2_relu
I0722 00:57:10.076004 23230 net.cpp:100] Creating Layer conv8_2_relu
I0722 00:57:10.076009 23230 net.cpp:434] conv8_2_relu <- conv8_2
I0722 00:57:10.076016 23230 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0722 00:57:10.078039 23230 net.cpp:150] Setting up conv8_2_relu
I0722 00:57:10.078063 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.078068 23230 net.cpp:165] Memory required for data: 5450776608
I0722 00:57:10.078073 23230 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0722 00:57:10.078079 23230 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0722 00:57:10.078084 23230 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0722 00:57:10.078092 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0722 00:57:10.078101 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0722 00:57:10.078107 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0722 00:57:10.078114 23230 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0722 00:57:10.078235 23230 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0722 00:57:10.078245 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.078250 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.078254 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.078258 23230 net.cpp:157] Top shape: 2 256 14 14 (100352)
I0722 00:57:10.078261 23230 net.cpp:165] Memory required for data: 5452382240
I0722 00:57:10.078269 23230 layer_factory.hpp:77] Creating layer conv9_1
I0722 00:57:10.078281 23230 net.cpp:100] Creating Layer conv9_1
I0722 00:57:10.078287 23230 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0722 00:57:10.078297 23230 net.cpp:408] conv9_1 -> conv9_1
I0722 00:57:10.084028 23230 net.cpp:150] Setting up conv9_1
I0722 00:57:10.084045 23230 net.cpp:157] Top shape: 2 128 14 14 (50176)
I0722 00:57:10.084062 23230 net.cpp:165] Memory required for data: 5452582944
I0722 00:57:10.084071 23230 layer_factory.hpp:77] Creating layer conv9_1_relu
I0722 00:57:10.084079 23230 net.cpp:100] Creating Layer conv9_1_relu
I0722 00:57:10.084084 23230 net.cpp:434] conv9_1_relu <- conv9_1
I0722 00:57:10.084092 23230 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0722 00:57:10.085091 23230 net.cpp:150] Setting up conv9_1_relu
I0722 00:57:10.085111 23230 net.cpp:157] Top shape: 2 128 14 14 (50176)
I0722 00:57:10.085115 23230 net.cpp:165] Memory required for data: 5452783648
I0722 00:57:10.085119 23230 layer_factory.hpp:77] Creating layer conv9_2
I0722 00:57:10.085134 23230 net.cpp:100] Creating Layer conv9_2
I0722 00:57:10.085139 23230 net.cpp:434] conv9_2 <- conv9_1
I0722 00:57:10.085150 23230 net.cpp:408] conv9_2 -> conv9_2
I0722 00:57:10.089241 23230 net.cpp:150] Setting up conv9_2
I0722 00:57:10.089260 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:10.089264 23230 net.cpp:165] Memory required for data: 5453078560
I0722 00:57:10.089272 23230 layer_factory.hpp:77] Creating layer conv9_2_relu
I0722 00:57:10.089282 23230 net.cpp:100] Creating Layer conv9_2_relu
I0722 00:57:10.089287 23230 net.cpp:434] conv9_2_relu <- conv9_2
I0722 00:57:10.089293 23230 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0722 00:57:10.089812 23230 net.cpp:150] Setting up conv9_2_relu
I0722 00:57:10.089829 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:10.089833 23230 net.cpp:165] Memory required for data: 5453373472
I0722 00:57:10.089838 23230 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0722 00:57:10.089848 23230 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0722 00:57:10.089853 23230 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0722 00:57:10.089859 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0722 00:57:10.089869 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0722 00:57:10.089877 23230 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0722 00:57:10.089972 23230 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0722 00:57:10.089982 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:10.089985 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:10.089989 23230 net.cpp:157] Top shape: 2 256 12 12 (73728)
I0722 00:57:10.089993 23230 net.cpp:165] Memory required for data: 5454258208
I0722 00:57:10.089996 23230 layer_factory.hpp:77] Creating layer conv4_3_norm
I0722 00:57:10.090008 23230 net.cpp:100] Creating Layer conv4_3_norm
I0722 00:57:10.090013 23230 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0722 00:57:10.090018 23230 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0722 00:57:10.090293 23230 net.cpp:150] Setting up conv4_3_norm
I0722 00:57:10.090304 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:10.090308 23230 net.cpp:165] Memory required for data: 5521367072
I0722 00:57:10.090314 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:10.090322 23230 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:10.090325 23230 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0722 00:57:10.090330 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0722 00:57:10.090338 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0722 00:57:10.090348 23230 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0722 00:57:10.090420 23230 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0722 00:57:10.090430 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:10.090433 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:10.090437 23230 net.cpp:157] Top shape: 2 512 128 128 (16777216)
I0722 00:57:10.090441 23230 net.cpp:165] Memory required for data: 5722693664
I0722 00:57:10.090445 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:10.090472 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:10.090477 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018 <- conv4_3_norm_conv4_3_norm_0_split_0
I0722 00:57:10.090484 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:10.098800 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:10.098839 23230 net.cpp:157] Top shape: 2 16 128 128 (524288)
I0722 00:57:10.098848 23230 net.cpp:165] Memory required for data: 5724790816
I0722 00:57:10.098865 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.098882 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.098891 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 <- conv4_3_norm_mbox_loc_bdc2018
I0722 00:57:10.098909 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.099170 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.099180 23230 net.cpp:157] Top shape: 2 128 128 16 (524288)
I0722 00:57:10.099184 23230 net.cpp:165] Memory required for data: 5726887968
I0722 00:57:10.099189 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.099197 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.099201 23230 net.cpp:434] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 <- conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.099210 23230 net.cpp:408] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 -> conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.099264 23230 net.cpp:150] Setting up conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.099274 23230 net.cpp:157] Top shape: 2 262144 (524288)
I0722 00:57:10.099278 23230 net.cpp:165] Memory required for data: 5728985120
I0722 00:57:10.099282 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:10.099304 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:10.099310 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new <- conv4_3_norm_conv4_3_norm_0_split_1
I0722 00:57:10.099318 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:10.101992 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:10.102010 23230 net.cpp:157] Top shape: 2 36 128 128 (1179648)
I0722 00:57:10.102015 23230 net.cpp:165] Memory required for data: 5733703712
I0722 00:57:10.102022 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.102033 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.102038 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv4_3_norm_mbox_conf_bdc2018_new
I0722 00:57:10.102046 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.102226 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.102238 23230 net.cpp:157] Top shape: 2 128 128 36 (1179648)
I0722 00:57:10.102241 23230 net.cpp:165] Memory required for data: 5738422304
I0722 00:57:10.102246 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.102255 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.102259 23230 net.cpp:434] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.102267 23230 net.cpp:408] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.102308 23230 net.cpp:150] Setting up conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.102318 23230 net.cpp:157] Top shape: 2 589824 (1179648)
I0722 00:57:10.102334 23230 net.cpp:165] Memory required for data: 5743140896
I0722 00:57:10.102339 23230 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0722 00:57:10.102350 23230 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0722 00:57:10.102355 23230 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0722 00:57:10.102361 23230 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0722 00:57:10.102367 23230 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0722 00:57:10.102414 23230 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0722 00:57:10.102423 23230 net.cpp:157] Top shape: 1 2 262144 (524288)
I0722 00:57:10.102427 23230 net.cpp:165] Memory required for data: 5745238048
I0722 00:57:10.102429 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018
I0722 00:57:10.102443 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018
I0722 00:57:10.102449 23230 net.cpp:434] fc7_mbox_loc_bdc2018 <- fc7_relu7_0_split_1
I0722 00:57:10.102463 23230 net.cpp:408] fc7_mbox_loc_bdc2018 -> fc7_mbox_loc_bdc2018
I0722 00:57:10.105182 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018
I0722 00:57:10.105199 23230 net.cpp:157] Top shape: 2 24 64 64 (196608)
I0722 00:57:10.105203 23230 net.cpp:165] Memory required for data: 5746024480
I0722 00:57:10.105211 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.105222 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.105226 23230 net.cpp:434] fc7_mbox_loc_bdc2018_perm_bdc2018 <- fc7_mbox_loc_bdc2018
I0722 00:57:10.105233 23230 net.cpp:408] fc7_mbox_loc_bdc2018_perm_bdc2018 -> fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.105404 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.105414 23230 net.cpp:157] Top shape: 2 64 64 24 (196608)
I0722 00:57:10.105417 23230 net.cpp:165] Memory required for data: 5746810912
I0722 00:57:10.105422 23230 layer_factory.hpp:77] Creating layer fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.105430 23230 net.cpp:100] Creating Layer fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.105434 23230 net.cpp:434] fc7_mbox_loc_bdc2018_flat_bdc2018 <- fc7_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.105440 23230 net.cpp:408] fc7_mbox_loc_bdc2018_flat_bdc2018 -> fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.105479 23230 net.cpp:150] Setting up fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.105487 23230 net.cpp:157] Top shape: 2 98304 (196608)
I0722 00:57:10.105491 23230 net.cpp:165] Memory required for data: 5747597344
I0722 00:57:10.105494 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new
I0722 00:57:10.105509 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new
I0722 00:57:10.105512 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new <- fc7_relu7_0_split_2
I0722 00:57:10.105520 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new -> fc7_mbox_conf_bdc2018_new
I0722 00:57:10.111726 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new
I0722 00:57:10.111745 23230 net.cpp:157] Top shape: 2 54 64 64 (442368)
I0722 00:57:10.111750 23230 net.cpp:165] Memory required for data: 5749366816
I0722 00:57:10.111758 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.111769 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.111774 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new <- fc7_mbox_conf_bdc2018_new
I0722 00:57:10.111783 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new -> fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.111961 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.111974 23230 net.cpp:157] Top shape: 2 64 64 54 (442368)
I0722 00:57:10.111976 23230 net.cpp:165] Memory required for data: 5751136288
I0722 00:57:10.111980 23230 layer_factory.hpp:77] Creating layer fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.111989 23230 net.cpp:100] Creating Layer fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.112006 23230 net.cpp:434] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new <- fc7_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.112015 23230 net.cpp:408] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new -> fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.112057 23230 net.cpp:150] Setting up fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.112068 23230 net.cpp:157] Top shape: 2 221184 (442368)
I0722 00:57:10.112072 23230 net.cpp:165] Memory required for data: 5752905760
I0722 00:57:10.112076 23230 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0722 00:57:10.112084 23230 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0722 00:57:10.112088 23230 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0722 00:57:10.112093 23230 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0722 00:57:10.112102 23230 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0722 00:57:10.112143 23230 net.cpp:150] Setting up fc7_mbox_priorbox
I0722 00:57:10.112154 23230 net.cpp:157] Top shape: 1 2 98304 (196608)
I0722 00:57:10.112157 23230 net.cpp:165] Memory required for data: 5753692192
I0722 00:57:10.112160 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018
I0722 00:57:10.112175 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018
I0722 00:57:10.112179 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018 <- conv6_2_conv6_2_relu_0_split_1
I0722 00:57:10.112186 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018 -> conv6_2_mbox_loc_bdc2018
I0722 00:57:10.115679 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018
I0722 00:57:10.115697 23230 net.cpp:157] Top shape: 2 24 32 32 (49152)
I0722 00:57:10.115701 23230 net.cpp:165] Memory required for data: 5753888800
I0722 00:57:10.115710 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.115717 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.115721 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018_perm_bdc2018 <- conv6_2_mbox_loc_bdc2018
I0722 00:57:10.115731 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018_perm_bdc2018 -> conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.115905 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.115914 23230 net.cpp:157] Top shape: 2 32 32 24 (49152)
I0722 00:57:10.115918 23230 net.cpp:165] Memory required for data: 5754085408
I0722 00:57:10.115921 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.115928 23230 net.cpp:100] Creating Layer conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.115932 23230 net.cpp:434] conv6_2_mbox_loc_bdc2018_flat_bdc2018 <- conv6_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.115941 23230 net.cpp:408] conv6_2_mbox_loc_bdc2018_flat_bdc2018 -> conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.115981 23230 net.cpp:150] Setting up conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.115989 23230 net.cpp:157] Top shape: 2 24576 (49152)
I0722 00:57:10.115993 23230 net.cpp:165] Memory required for data: 5754282016
I0722 00:57:10.115996 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new
I0722 00:57:10.116009 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new
I0722 00:57:10.116014 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new <- conv6_2_conv6_2_relu_0_split_2
I0722 00:57:10.116022 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new
I0722 00:57:10.122520 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new
I0722 00:57:10.122539 23230 net.cpp:157] Top shape: 2 54 32 32 (110592)
I0722 00:57:10.122542 23230 net.cpp:165] Memory required for data: 5754724384
I0722 00:57:10.122550 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.122560 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.122567 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv6_2_mbox_conf_bdc2018_new
I0722 00:57:10.122573 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.122763 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.122774 23230 net.cpp:157] Top shape: 2 32 32 54 (110592)
I0722 00:57:10.122777 23230 net.cpp:165] Memory required for data: 5755166752
I0722 00:57:10.122781 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.122790 23230 net.cpp:100] Creating Layer conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.122795 23230 net.cpp:434] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.122802 23230 net.cpp:408] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.122843 23230 net.cpp:150] Setting up conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.122850 23230 net.cpp:157] Top shape: 2 55296 (110592)
I0722 00:57:10.122853 23230 net.cpp:165] Memory required for data: 5755609120
I0722 00:57:10.122858 23230 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0722 00:57:10.122867 23230 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0722 00:57:10.122871 23230 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0722 00:57:10.122877 23230 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0722 00:57:10.122884 23230 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0722 00:57:10.122926 23230 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0722 00:57:10.122936 23230 net.cpp:157] Top shape: 1 2 24576 (49152)
I0722 00:57:10.122938 23230 net.cpp:165] Memory required for data: 5755805728
I0722 00:57:10.122942 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018
I0722 00:57:10.122954 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018
I0722 00:57:10.122959 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018 <- conv7_2_conv7_2_relu_0_split_1
I0722 00:57:10.122969 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018 -> conv7_2_mbox_loc_bdc2018
I0722 00:57:10.129456 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018
I0722 00:57:10.129475 23230 net.cpp:157] Top shape: 2 24 16 16 (12288)
I0722 00:57:10.129479 23230 net.cpp:165] Memory required for data: 5755854880
I0722 00:57:10.129487 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.129495 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.129500 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018_perm_bdc2018 <- conv7_2_mbox_loc_bdc2018
I0722 00:57:10.129508 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018_perm_bdc2018 -> conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.129678 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.129690 23230 net.cpp:157] Top shape: 2 16 16 24 (12288)
I0722 00:57:10.129693 23230 net.cpp:165] Memory required for data: 5755904032
I0722 00:57:10.129698 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.129704 23230 net.cpp:100] Creating Layer conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.129709 23230 net.cpp:434] conv7_2_mbox_loc_bdc2018_flat_bdc2018 <- conv7_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.129716 23230 net.cpp:408] conv7_2_mbox_loc_bdc2018_flat_bdc2018 -> conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.129753 23230 net.cpp:150] Setting up conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.129765 23230 net.cpp:157] Top shape: 2 6144 (12288)
I0722 00:57:10.129767 23230 net.cpp:165] Memory required for data: 5755953184
I0722 00:57:10.129771 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new
I0722 00:57:10.129783 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new
I0722 00:57:10.129787 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new <- conv7_2_conv7_2_relu_0_split_2
I0722 00:57:10.129794 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new
I0722 00:57:10.136399 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new
I0722 00:57:10.136430 23230 net.cpp:157] Top shape: 2 54 16 16 (27648)
I0722 00:57:10.136435 23230 net.cpp:165] Memory required for data: 5756063776
I0722 00:57:10.136442 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.136452 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.136457 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv7_2_mbox_conf_bdc2018_new
I0722 00:57:10.136464 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.136641 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.136651 23230 net.cpp:157] Top shape: 2 16 16 54 (27648)
I0722 00:57:10.136654 23230 net.cpp:165] Memory required for data: 5756174368
I0722 00:57:10.136657 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.136664 23230 net.cpp:100] Creating Layer conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.136669 23230 net.cpp:434] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.136677 23230 net.cpp:408] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.136719 23230 net.cpp:150] Setting up conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.136728 23230 net.cpp:157] Top shape: 2 13824 (27648)
I0722 00:57:10.136730 23230 net.cpp:165] Memory required for data: 5756284960
I0722 00:57:10.136734 23230 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0722 00:57:10.136741 23230 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0722 00:57:10.136745 23230 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0722 00:57:10.136750 23230 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0722 00:57:10.136759 23230 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0722 00:57:10.136806 23230 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0722 00:57:10.136816 23230 net.cpp:157] Top shape: 1 2 6144 (12288)
I0722 00:57:10.136818 23230 net.cpp:165] Memory required for data: 5756334112
I0722 00:57:10.136822 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018
I0722 00:57:10.136837 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018
I0722 00:57:10.136840 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018 <- conv8_2_conv8_2_relu_0_split_1
I0722 00:57:10.136847 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018 -> conv8_2_mbox_loc_bdc2018
I0722 00:57:10.140926 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018
I0722 00:57:10.140946 23230 net.cpp:157] Top shape: 2 16 14 14 (6272)
I0722 00:57:10.140950 23230 net.cpp:165] Memory required for data: 5756359200
I0722 00:57:10.140969 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.140980 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.140985 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018_perm_bdc2018 <- conv8_2_mbox_loc_bdc2018
I0722 00:57:10.140992 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018_perm_bdc2018 -> conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.141173 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.141183 23230 net.cpp:157] Top shape: 2 14 14 16 (6272)
I0722 00:57:10.141186 23230 net.cpp:165] Memory required for data: 5756384288
I0722 00:57:10.141191 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.141197 23230 net.cpp:100] Creating Layer conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.141201 23230 net.cpp:434] conv8_2_mbox_loc_bdc2018_flat_bdc2018 <- conv8_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.141211 23230 net.cpp:408] conv8_2_mbox_loc_bdc2018_flat_bdc2018 -> conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.141252 23230 net.cpp:150] Setting up conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.141260 23230 net.cpp:157] Top shape: 2 3136 (6272)
I0722 00:57:10.141283 23230 net.cpp:165] Memory required for data: 5756409376
I0722 00:57:10.141288 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new
I0722 00:57:10.141301 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new
I0722 00:57:10.141307 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new <- conv8_2_conv8_2_relu_0_split_2
I0722 00:57:10.141317 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new
I0722 00:57:10.143609 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new
I0722 00:57:10.143625 23230 net.cpp:157] Top shape: 2 36 14 14 (14112)
I0722 00:57:10.143630 23230 net.cpp:165] Memory required for data: 5756465824
I0722 00:57:10.143638 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.143648 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.143656 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv8_2_mbox_conf_bdc2018_new
I0722 00:57:10.143664 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.143844 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.143857 23230 net.cpp:157] Top shape: 2 14 14 36 (14112)
I0722 00:57:10.143860 23230 net.cpp:165] Memory required for data: 5756522272
I0722 00:57:10.143864 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.143872 23230 net.cpp:100] Creating Layer conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.143875 23230 net.cpp:434] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.143883 23230 net.cpp:408] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.143923 23230 net.cpp:150] Setting up conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.143934 23230 net.cpp:157] Top shape: 2 7056 (14112)
I0722 00:57:10.143936 23230 net.cpp:165] Memory required for data: 5756578720
I0722 00:57:10.143940 23230 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0722 00:57:10.143947 23230 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0722 00:57:10.143952 23230 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0722 00:57:10.143957 23230 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0722 00:57:10.143965 23230 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0722 00:57:10.144009 23230 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0722 00:57:10.144017 23230 net.cpp:157] Top shape: 1 2 3136 (6272)
I0722 00:57:10.144021 23230 net.cpp:165] Memory required for data: 5756603808
I0722 00:57:10.144024 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018
I0722 00:57:10.144037 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018
I0722 00:57:10.144043 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018 <- conv9_2_conv9_2_relu_0_split_0
I0722 00:57:10.144050 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018 -> conv9_2_mbox_loc_bdc2018
I0722 00:57:10.149531 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018
I0722 00:57:10.149549 23230 net.cpp:157] Top shape: 2 16 12 12 (4608)
I0722 00:57:10.149554 23230 net.cpp:165] Memory required for data: 5756622240
I0722 00:57:10.149561 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.149574 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.149580 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018_perm_bdc2018 <- conv9_2_mbox_loc_bdc2018
I0722 00:57:10.149588 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018_perm_bdc2018 -> conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.149768 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.149778 23230 net.cpp:157] Top shape: 2 12 12 16 (4608)
I0722 00:57:10.149783 23230 net.cpp:165] Memory required for data: 5756640672
I0722 00:57:10.149801 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.149807 23230 net.cpp:100] Creating Layer conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.149811 23230 net.cpp:434] conv9_2_mbox_loc_bdc2018_flat_bdc2018 <- conv9_2_mbox_loc_bdc2018_perm_bdc2018
I0722 00:57:10.149817 23230 net.cpp:408] conv9_2_mbox_loc_bdc2018_flat_bdc2018 -> conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.149863 23230 net.cpp:150] Setting up conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.149871 23230 net.cpp:157] Top shape: 2 2304 (4608)
I0722 00:57:10.149874 23230 net.cpp:165] Memory required for data: 5756659104
I0722 00:57:10.149878 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new
I0722 00:57:10.149891 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new
I0722 00:57:10.149895 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new <- conv9_2_conv9_2_relu_0_split_1
I0722 00:57:10.149904 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new
I0722 00:57:10.156024 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new
I0722 00:57:10.156044 23230 net.cpp:157] Top shape: 2 36 12 12 (10368)
I0722 00:57:10.156049 23230 net.cpp:165] Memory required for data: 5756700576
I0722 00:57:10.156056 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.156064 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.156074 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new <- conv9_2_mbox_conf_bdc2018_new
I0722 00:57:10.156080 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.156263 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.156275 23230 net.cpp:157] Top shape: 2 12 12 36 (10368)
I0722 00:57:10.156278 23230 net.cpp:165] Memory required for data: 5756742048
I0722 00:57:10.156281 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.156289 23230 net.cpp:100] Creating Layer conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.156293 23230 net.cpp:434] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new <- conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new
I0722 00:57:10.156301 23230 net.cpp:408] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new -> conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.156343 23230 net.cpp:150] Setting up conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.156350 23230 net.cpp:157] Top shape: 2 5184 (10368)
I0722 00:57:10.156353 23230 net.cpp:165] Memory required for data: 5756783520
I0722 00:57:10.156358 23230 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0722 00:57:10.156365 23230 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0722 00:57:10.156369 23230 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0722 00:57:10.156376 23230 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0722 00:57:10.156383 23230 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0722 00:57:10.156426 23230 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0722 00:57:10.156433 23230 net.cpp:157] Top shape: 1 2 2304 (4608)
I0722 00:57:10.156436 23230 net.cpp:165] Memory required for data: 5756801952
I0722 00:57:10.156440 23230 layer_factory.hpp:77] Creating layer mbox_loc
I0722 00:57:10.156448 23230 net.cpp:100] Creating Layer mbox_loc
I0722 00:57:10.156452 23230 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.156461 23230 net.cpp:434] mbox_loc <- fc7_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.156466 23230 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.156471 23230 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.156474 23230 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.156479 23230 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_bdc2018_flat_bdc2018
I0722 00:57:10.164448 23230 net.cpp:408] mbox_loc -> mbox_loc
I0722 00:57:10.164536 23230 net.cpp:150] Setting up mbox_loc
I0722 00:57:10.164548 23230 net.cpp:157] Top shape: 2 396608 (793216)
I0722 00:57:10.164551 23230 net.cpp:165] Memory required for data: 5759974816
I0722 00:57:10.164556 23230 layer_factory.hpp:77] Creating layer mbox_conf
I0722 00:57:10.164563 23230 net.cpp:100] Creating Layer mbox_conf
I0722 00:57:10.164568 23230 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164574 23230 net.cpp:434] mbox_conf <- fc7_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164579 23230 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164584 23230 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164588 23230 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164593 23230 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new
I0722 00:57:10.164602 23230 net.cpp:408] mbox_conf -> mbox_conf
I0722 00:57:10.164649 23230 net.cpp:150] Setting up mbox_conf
I0722 00:57:10.164657 23230 net.cpp:157] Top shape: 2 892368 (1784736)
I0722 00:57:10.164660 23230 net.cpp:165] Memory required for data: 5767113760
I0722 00:57:10.164664 23230 layer_factory.hpp:77] Creating layer mbox_priorbox
I0722 00:57:10.164670 23230 net.cpp:100] Creating Layer mbox_priorbox
I0722 00:57:10.164674 23230 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0722 00:57:10.164680 23230 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0722 00:57:10.164685 23230 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0722 00:57:10.164690 23230 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0722 00:57:10.164693 23230 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0722 00:57:10.164698 23230 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0722 00:57:10.164703 23230 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0722 00:57:10.164747 23230 net.cpp:150] Setting up mbox_priorbox
I0722 00:57:10.164755 23230 net.cpp:157] Top shape: 1 2 396608 (793216)
I0722 00:57:10.164759 23230 net.cpp:165] Memory required for data: 5770286624
I0722 00:57:10.164763 23230 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0722 00:57:10.164774 23230 net.cpp:100] Creating Layer mbox_conf_reshape
I0722 00:57:10.164779 23230 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0722 00:57:10.164785 23230 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0722 00:57:10.164840 23230 net.cpp:150] Setting up mbox_conf_reshape
I0722 00:57:10.164849 23230 net.cpp:157] Top shape: 2 99152 9 (1784736)
I0722 00:57:10.164854 23230 net.cpp:165] Memory required for data: 5777425568
I0722 00:57:10.164857 23230 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0722 00:57:10.164865 23230 net.cpp:100] Creating Layer mbox_conf_softmax
I0722 00:57:10.164870 23230 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0722 00:57:10.164878 23230 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0722 00:57:10.165236 23230 net.cpp:150] Setting up mbox_conf_softmax
I0722 00:57:10.165251 23230 net.cpp:157] Top shape: 2 99152 9 (1784736)
I0722 00:57:10.165256 23230 net.cpp:165] Memory required for data: 5784564512
I0722 00:57:10.165259 23230 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0722 00:57:10.165266 23230 net.cpp:100] Creating Layer mbox_conf_flatten
I0722 00:57:10.165271 23230 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0722 00:57:10.165277 23230 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0722 00:57:10.165323 23230 net.cpp:150] Setting up mbox_conf_flatten
I0722 00:57:10.165333 23230 net.cpp:157] Top shape: 2 892368 (1784736)
I0722 00:57:10.165336 23230 net.cpp:165] Memory required for data: 5791703456
I0722 00:57:10.165340 23230 layer_factory.hpp:77] Creating layer detection_out
I0722 00:57:10.165359 23230 net.cpp:100] Creating Layer detection_out
I0722 00:57:10.165364 23230 net.cpp:434] detection_out <- mbox_loc
I0722 00:57:10.165370 23230 net.cpp:434] detection_out <- mbox_conf_flatten
I0722 00:57:10.165388 23230 net.cpp:434] detection_out <- mbox_priorbox
I0722 00:57:10.165400 23230 net.cpp:408] detection_out -> detection_out
W0722 00:57:10.165454 23230 detection_output_layer.cpp:49] Failed to create directory: /home/user/data/bdc2018/results/SSD_1024x1024/Main
I0722 00:57:10.166234 23230 net.cpp:150] Setting up detection_out
I0722 00:57:10.166250 23230 net.cpp:157] Top shape: 1 1 1 7 (7)
I0722 00:57:10.166254 23230 net.cpp:165] Memory required for data: 5791703484
I0722 00:57:10.166258 23230 layer_factory.hpp:77] Creating layer detection_eval
I0722 00:57:10.166267 23230 net.cpp:100] Creating Layer detection_eval
I0722 00:57:10.166272 23230 net.cpp:434] detection_eval <- detection_out
I0722 00:57:10.166277 23230 net.cpp:434] detection_eval <- label
I0722 00:57:10.166285 23230 net.cpp:408] detection_eval -> detection_eval
I0722 00:57:10.166529 23230 net.cpp:150] Setting up detection_eval
I0722 00:57:10.166543 23230 net.cpp:157] Top shape: 1 1 9 5 (45)
I0722 00:57:10.166545 23230 net.cpp:165] Memory required for data: 5791703664
I0722 00:57:10.166549 23230 net.cpp:228] detection_eval does not need backward computation.
I0722 00:57:10.166554 23230 net.cpp:228] detection_out does not need backward computation.
I0722 00:57:10.166558 23230 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0722 00:57:10.166563 23230 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0722 00:57:10.166566 23230 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0722 00:57:10.166570 23230 net.cpp:228] mbox_priorbox does not need backward computation.
I0722 00:57:10.166576 23230 net.cpp:228] mbox_conf does not need backward computation.
I0722 00:57:10.166581 23230 net.cpp:228] mbox_loc does not need backward computation.
I0722 00:57:10.166587 23230 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0722 00:57:10.166592 23230 net.cpp:228] conv9_2_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166596 23230 net.cpp:228] conv9_2_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166600 23230 net.cpp:228] conv9_2_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166604 23230 net.cpp:228] conv9_2_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166609 23230 net.cpp:228] conv9_2_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166612 23230 net.cpp:228] conv9_2_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166616 23230 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0722 00:57:10.166621 23230 net.cpp:228] conv8_2_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166625 23230 net.cpp:228] conv8_2_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166630 23230 net.cpp:228] conv8_2_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166633 23230 net.cpp:228] conv8_2_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166637 23230 net.cpp:228] conv8_2_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166641 23230 net.cpp:228] conv8_2_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166646 23230 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0722 00:57:10.166651 23230 net.cpp:228] conv7_2_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166654 23230 net.cpp:228] conv7_2_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166658 23230 net.cpp:228] conv7_2_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166662 23230 net.cpp:228] conv7_2_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166666 23230 net.cpp:228] conv7_2_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166671 23230 net.cpp:228] conv7_2_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166687 23230 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0722 00:57:10.166692 23230 net.cpp:228] conv6_2_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166695 23230 net.cpp:228] conv6_2_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166699 23230 net.cpp:228] conv6_2_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166703 23230 net.cpp:228] conv6_2_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166707 23230 net.cpp:228] conv6_2_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166710 23230 net.cpp:228] conv6_2_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166715 23230 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0722 00:57:10.166726 23230 net.cpp:228] fc7_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166730 23230 net.cpp:228] fc7_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166734 23230 net.cpp:228] fc7_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166739 23230 net.cpp:228] fc7_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166743 23230 net.cpp:228] fc7_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166748 23230 net.cpp:228] fc7_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166751 23230 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0722 00:57:10.166756 23230 net.cpp:228] conv4_3_norm_mbox_conf_bdc2018_new_flat_bdc2018_new does not need backward computation.
I0722 00:57:10.166760 23230 net.cpp:228] conv4_3_norm_mbox_conf_bdc2018_new_perm_bdc2018_new does not need backward computation.
I0722 00:57:10.166764 23230 net.cpp:228] conv4_3_norm_mbox_conf_bdc2018_new does not need backward computation.
I0722 00:57:10.166769 23230 net.cpp:228] conv4_3_norm_mbox_loc_bdc2018_flat_bdc2018 does not need backward computation.
I0722 00:57:10.166772 23230 net.cpp:228] conv4_3_norm_mbox_loc_bdc2018_perm_bdc2018 does not need backward computation.
I0722 00:57:10.166777 23230 net.cpp:228] conv4_3_norm_mbox_loc_bdc2018 does not need backward computation.
I0722 00:57:10.166781 23230 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0722 00:57:10.166785 23230 net.cpp:228] conv4_3_norm does not need backward computation.
I0722 00:57:10.166790 23230 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0722 00:57:10.166793 23230 net.cpp:228] conv9_2_relu does not need backward computation.
I0722 00:57:10.166797 23230 net.cpp:228] conv9_2 does not need backward computation.
I0722 00:57:10.166800 23230 net.cpp:228] conv9_1_relu does not need backward computation.
I0722 00:57:10.166805 23230 net.cpp:228] conv9_1 does not need backward computation.
I0722 00:57:10.166808 23230 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0722 00:57:10.166812 23230 net.cpp:228] conv8_2_relu does not need backward computation.
I0722 00:57:10.166816 23230 net.cpp:228] conv8_2 does not need backward computation.
I0722 00:57:10.166820 23230 net.cpp:228] conv8_1_relu does not need backward computation.
I0722 00:57:10.166823 23230 net.cpp:228] conv8_1 does not need backward computation.
I0722 00:57:10.166827 23230 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0722 00:57:10.166831 23230 net.cpp:228] conv7_2_relu does not need backward computation.
I0722 00:57:10.166836 23230 net.cpp:228] conv7_2 does not need backward computation.
I0722 00:57:10.166838 23230 net.cpp:228] conv7_1_relu does not need backward computation.
I0722 00:57:10.166842 23230 net.cpp:228] conv7_1 does not need backward computation.
I0722 00:57:10.166846 23230 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0722 00:57:10.166857 23230 net.cpp:228] conv6_2_relu does not need backward computation.
I0722 00:57:10.166862 23230 net.cpp:228] conv6_2 does not need backward computation.
I0722 00:57:10.166865 23230 net.cpp:228] conv6_1_relu does not need backward computation.
I0722 00:57:10.166868 23230 net.cpp:228] conv6_1 does not need backward computation.
I0722 00:57:10.166873 23230 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0722 00:57:10.166878 23230 net.cpp:228] relu7 does not need backward computation.
I0722 00:57:10.166882 23230 net.cpp:228] fc7 does not need backward computation.
I0722 00:57:10.166887 23230 net.cpp:228] relu6 does not need backward computation.
I0722 00:57:10.166890 23230 net.cpp:228] fc6 does not need backward computation.
I0722 00:57:10.166894 23230 net.cpp:228] pool5 does not need backward computation.
I0722 00:57:10.166899 23230 net.cpp:228] relu5_3 does not need backward computation.
I0722 00:57:10.166903 23230 net.cpp:228] conv5_3 does not need backward computation.
I0722 00:57:10.166906 23230 net.cpp:228] relu5_2 does not need backward computation.
I0722 00:57:10.166910 23230 net.cpp:228] conv5_2 does not need backward computation.
I0722 00:57:10.166914 23230 net.cpp:228] relu5_1 does not need backward computation.
I0722 00:57:10.166919 23230 net.cpp:228] conv5_1 does not need backward computation.
I0722 00:57:10.166923 23230 net.cpp:228] pool4 does not need backward computation.
I0722 00:57:10.166927 23230 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0722 00:57:10.166931 23230 net.cpp:228] relu4_3 does not need backward computation.
I0722 00:57:10.166935 23230 net.cpp:228] conv4_3 does not need backward computation.
I0722 00:57:10.166939 23230 net.cpp:228] relu4_2 does not need backward computation.
I0722 00:57:10.166944 23230 net.cpp:228] conv4_2 does not need backward computation.
I0722 00:57:10.166949 23230 net.cpp:228] relu4_1 does not need backward computation.
I0722 00:57:10.166952 23230 net.cpp:228] conv4_1 does not need backward computation.
I0722 00:57:10.166956 23230 net.cpp:228] pool3 does not need backward computation.
I0722 00:57:10.166960 23230 net.cpp:228] relu3_3 does not need backward computation.
I0722 00:57:10.166965 23230 net.cpp:228] conv3_3 does not need backward computation.
I0722 00:57:10.166968 23230 net.cpp:228] relu3_2 does not need backward computation.
I0722 00:57:10.166971 23230 net.cpp:228] conv3_2 does not need backward computation.
I0722 00:57:10.166975 23230 net.cpp:228] relu3_1 does not need backward computation.
I0722 00:57:10.166980 23230 net.cpp:228] conv3_1 does not need backward computation.
I0722 00:57:10.166983 23230 net.cpp:228] pool2 does not need backward computation.
I0722 00:57:10.166987 23230 net.cpp:228] relu2_2 does not need backward computation.
I0722 00:57:10.166991 23230 net.cpp:228] conv2_2 does not need backward computation.
I0722 00:57:10.166996 23230 net.cpp:228] relu2_1 does not need backward computation.
I0722 00:57:10.166999 23230 net.cpp:228] conv2_1 does not need backward computation.
I0722 00:57:10.167006 23230 net.cpp:228] pool1 does not need backward computation.
I0722 00:57:10.167009 23230 net.cpp:228] relu1_2 does not need backward computation.
I0722 00:57:10.167013 23230 net.cpp:228] conv1_2 does not need backward computation.
I0722 00:57:10.167017 23230 net.cpp:228] relu1_1 does not need backward computation.
I0722 00:57:10.167021 23230 net.cpp:228] conv1_1 does not need backward computation.
I0722 00:57:10.167026 23230 net.cpp:228] data_data_0_split does not need backward computation.
I0722 00:57:10.167031 23230 net.cpp:228] data does not need backward computation.
I0722 00:57:10.167033 23230 net.cpp:270] This network produces output detection_eval
I0722 00:57:10.167152 23230 net.cpp:283] Network initialization done.
I0722 00:57:10.167603 23230 solver.cpp:75] Solver scaffolding done.
I0722 00:57:10.171638 23230 caffe.cpp:241] Resuming from models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_114125.solverstate
I0722 00:57:10.378331 23230 sgd_solver.cpp:356] SGDSolver: restoring history
I0722 00:57:10.511740 23230 parallel.cpp:392] GPUs pairs 0:1, 2:3, 0:2
I0722 00:57:10.912348 23230 annotated_data_layer.cpp:62] output data size: 2,3,1024,1024
I0722 00:57:12.462074 23230 annotated_data_layer.cpp:62] output data size: 2,3,1024,1024
I0722 00:57:13.673491 23230 parallel.cpp:234] GPU 2 does not have p2p access to GPU 0
I0722 00:57:14.039621 23230 annotated_data_layer.cpp:62] output data size: 2,3,1024,1024
I0722 00:57:15.246686 23230 parallel.cpp:425] Starting Optimization
I0722 00:57:15.246841 23230 solver.cpp:294] Solving VGG_VOC0712_SSD_1024x1024_train
I0722 00:57:15.246893 23230 solver.cpp:295] Learning Rate Policy: multistep
I0722 00:58:25.629940 23230 solver.cpp:243] Iteration 114130, loss = 2.31725
I0722 00:58:25.630131 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 00:58:25.630182 23230 sgd_solver.cpp:138] Iteration 114130, lr = 1e-05
I0722 01:00:12.330588 23230 solver.cpp:243] Iteration 114140, loss = 2.65331
I0722 01:00:12.330835 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40147 (* 1 = 2.40147 loss)
I0722 01:00:12.330904 23230 sgd_solver.cpp:138] Iteration 114140, lr = 1e-05
I0722 01:01:39.521250 23230 solver.cpp:243] Iteration 114150, loss = 2.60077
I0722 01:01:39.521546 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.88572 (* 1 = 3.88572 loss)
I0722 01:01:39.521615 23230 sgd_solver.cpp:138] Iteration 114150, lr = 1e-05
I0722 01:03:06.198155 23230 solver.cpp:243] Iteration 114160, loss = 2.52882
I0722 01:03:06.198467 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7762 (* 1 = 1.7762 loss)
I0722 01:03:06.198607 23230 sgd_solver.cpp:138] Iteration 114160, lr = 1e-05
I0722 01:04:32.841910 23230 solver.cpp:243] Iteration 114170, loss = 2.64815
I0722 01:04:32.842245 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.21157 (* 1 = 3.21157 loss)
I0722 01:04:32.842370 23230 sgd_solver.cpp:138] Iteration 114170, lr = 1e-05
I0722 01:05:57.972918 23230 solver.cpp:243] Iteration 114180, loss = 2.74713
I0722 01:05:57.973147 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.43488 (* 1 = 5.43488 loss)
I0722 01:05:57.973194 23230 sgd_solver.cpp:138] Iteration 114180, lr = 1e-05
I0722 01:07:23.612048 23230 solver.cpp:243] Iteration 114190, loss = 2.68155
I0722 01:07:23.612356 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17956 (* 1 = 3.17956 loss)
I0722 01:07:23.612458 23230 sgd_solver.cpp:138] Iteration 114190, lr = 1e-05
I0722 01:08:49.223076 23230 solver.cpp:243] Iteration 114200, loss = 2.58919
I0722 01:08:49.223364 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.68018 (* 1 = 2.68018 loss)
I0722 01:08:49.578490 23230 sgd_solver.cpp:138] Iteration 114200, lr = 1e-05
I0722 01:10:15.276887 23230 solver.cpp:243] Iteration 114210, loss = 2.47404
I0722 01:10:15.277143 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.01028 (* 1 = 1.01028 loss)
I0722 01:10:15.630633 23230 sgd_solver.cpp:138] Iteration 114210, lr = 1e-05
I0722 01:11:38.941747 23230 solver.cpp:243] Iteration 114220, loss = 2.61872
I0722 01:11:38.941993 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.00333 (* 1 = 2.00333 loss)
I0722 01:11:38.942037 23230 sgd_solver.cpp:138] Iteration 114220, lr = 1e-05
I0722 01:13:05.287783 23230 solver.cpp:243] Iteration 114230, loss = 2.43962
I0722 01:13:05.288043 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.94961 (* 1 = 2.94961 loss)
I0722 01:13:05.288081 23230 sgd_solver.cpp:138] Iteration 114230, lr = 1e-05
I0722 01:14:26.190925 23230 solver.cpp:243] Iteration 114240, loss = 2.62731
I0722 01:14:26.191138 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.79284 (* 1 = 3.79284 loss)
I0722 01:14:26.961745 23230 sgd_solver.cpp:138] Iteration 114240, lr = 1e-05
I0722 01:15:51.338428 23230 solver.cpp:243] Iteration 114250, loss = 2.73285
I0722 01:15:51.338969 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74799 (* 1 = 2.74799 loss)
I0722 01:15:51.339110 23230 sgd_solver.cpp:138] Iteration 114250, lr = 1e-05
I0722 01:17:14.592260 23230 solver.cpp:243] Iteration 114260, loss = 2.48655
I0722 01:17:14.594008 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.44116 (* 1 = 3.44116 loss)
I0722 01:17:14.594126 23230 sgd_solver.cpp:138] Iteration 114260, lr = 1e-05
I0722 01:18:40.588560 23230 solver.cpp:243] Iteration 114270, loss = 2.7212
I0722 01:18:40.588800 23230 solver.cpp:259]     Train net output #0: mbox_loss = 9.56378 (* 1 = 9.56378 loss)
I0722 01:18:40.588853 23230 sgd_solver.cpp:138] Iteration 114270, lr = 1e-05
I0722 01:20:08.959218 23230 solver.cpp:243] Iteration 114280, loss = 2.60821
I0722 01:20:08.959990 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.79899 (* 1 = 1.79899 loss)
I0722 01:20:09.718331 23230 sgd_solver.cpp:138] Iteration 114280, lr = 1e-05
I0722 01:21:36.895944 23230 solver.cpp:243] Iteration 114290, loss = 2.43369
I0722 01:21:36.896222 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.19327 (* 1 = 1.19327 loss)
I0722 01:21:36.896265 23230 sgd_solver.cpp:138] Iteration 114290, lr = 1e-05
I0722 01:23:03.339856 23230 solver.cpp:243] Iteration 114300, loss = 2.44708
I0722 01:23:03.340085 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.74992 (* 1 = 1.74992 loss)
I0722 01:23:03.706921 23230 sgd_solver.cpp:138] Iteration 114300, lr = 1e-05
I0722 01:24:28.367836 23230 solver.cpp:243] Iteration 114310, loss = 2.71445
I0722 01:24:28.368122 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17775 (* 1 = 2.17775 loss)
I0722 01:24:28.368230 23230 sgd_solver.cpp:138] Iteration 114310, lr = 1e-05
I0722 01:25:54.467015 23230 solver.cpp:243] Iteration 114320, loss = 2.51306
I0722 01:25:54.467309 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24932 (* 1 = 2.24932 loss)
I0722 01:25:54.467417 23230 sgd_solver.cpp:138] Iteration 114320, lr = 1e-05
I0722 01:27:18.070690 23230 solver.cpp:243] Iteration 114330, loss = 2.71059
I0722 01:27:18.070917 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01173 (* 1 = 3.01173 loss)
I0722 01:27:18.070963 23230 sgd_solver.cpp:138] Iteration 114330, lr = 1e-05
I0722 01:28:44.277155 23230 solver.cpp:243] Iteration 114340, loss = 2.7636
I0722 01:28:44.277415 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27364 (* 1 = 2.27364 loss)
I0722 01:28:44.277505 23230 sgd_solver.cpp:138] Iteration 114340, lr = 1e-05
I0722 01:30:09.464818 23230 solver.cpp:243] Iteration 114350, loss = 2.52753
I0722 01:30:09.465116 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.27915 (* 1 = 1.27915 loss)
I0722 01:30:09.465221 23230 sgd_solver.cpp:138] Iteration 114350, lr = 1e-05
I0722 01:31:37.415712 23230 solver.cpp:243] Iteration 114360, loss = 2.74566
I0722 01:31:37.415982 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.91555 (* 1 = 1.91555 loss)
I0722 01:31:37.416026 23230 sgd_solver.cpp:138] Iteration 114360, lr = 1e-05
I0722 01:33:03.130316 23230 solver.cpp:243] Iteration 114370, loss = 2.70285
I0722 01:33:03.130578 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.56053 (* 1 = 1.56053 loss)
I0722 01:33:03.517863 23230 sgd_solver.cpp:138] Iteration 114370, lr = 1e-05
I0722 01:34:27.339290 23230 solver.cpp:243] Iteration 114380, loss = 2.3976
I0722 01:34:27.339542 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03118 (* 1 = 2.03118 loss)
I0722 01:34:28.722383 23230 sgd_solver.cpp:138] Iteration 114380, lr = 1e-05
I0722 01:35:54.764060 23230 solver.cpp:243] Iteration 114390, loss = 2.49297
I0722 01:35:54.764358 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2436 (* 1 = 2.2436 loss)
I0722 01:35:54.764458 23230 sgd_solver.cpp:138] Iteration 114390, lr = 1e-05
I0722 01:37:17.664178 23230 solver.cpp:243] Iteration 114400, loss = 2.58445
I0722 01:37:17.665426 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.94518 (* 1 = 2.94518 loss)
I0722 01:37:17.665464 23230 sgd_solver.cpp:138] Iteration 114400, lr = 1e-05
I0722 01:38:41.231326 23230 solver.cpp:243] Iteration 114410, loss = 2.90405
I0722 01:38:41.231590 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25826 (* 1 = 1.25826 loss)
I0722 01:38:41.231637 23230 sgd_solver.cpp:138] Iteration 114410, lr = 1e-05
I0722 01:40:04.120985 23230 solver.cpp:243] Iteration 114420, loss = 2.59738
I0722 01:40:04.121276 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.97987 (* 1 = 2.97987 loss)
I0722 01:40:04.121383 23230 sgd_solver.cpp:138] Iteration 114420, lr = 1e-05
I0722 01:41:26.763903 23230 solver.cpp:243] Iteration 114430, loss = 2.50977
I0722 01:41:26.764189 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.17263 (* 1 = 1.17263 loss)
I0722 01:41:26.764302 23230 sgd_solver.cpp:138] Iteration 114430, lr = 1e-05
I0722 01:42:50.678315 23230 solver.cpp:243] Iteration 114440, loss = 2.49542
I0722 01:42:50.678596 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.41562 (* 1 = 3.41562 loss)
I0722 01:42:50.678706 23230 sgd_solver.cpp:138] Iteration 114440, lr = 1e-05
I0722 01:44:15.669399 23230 solver.cpp:243] Iteration 114450, loss = 2.36641
I0722 01:44:15.669657 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.58561 (* 1 = 4.58561 loss)
I0722 01:44:15.669700 23230 sgd_solver.cpp:138] Iteration 114450, lr = 1e-05
I0722 01:45:40.375056 23230 solver.cpp:243] Iteration 114460, loss = 2.75299
I0722 01:45:40.375283 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01262 (* 1 = 3.01262 loss)
I0722 01:45:40.375324 23230 sgd_solver.cpp:138] Iteration 114460, lr = 1e-05
I0722 01:47:05.906834 23230 solver.cpp:243] Iteration 114470, loss = 2.46794
I0722 01:47:05.907127 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.89635 (* 1 = 1.89635 loss)
I0722 01:47:05.907240 23230 sgd_solver.cpp:138] Iteration 114470, lr = 1e-05
I0722 01:48:33.476548 23230 solver.cpp:243] Iteration 114480, loss = 2.52008
I0722 01:48:33.476845 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.46185 (* 1 = 2.46185 loss)
I0722 01:48:33.476951 23230 sgd_solver.cpp:138] Iteration 114480, lr = 1e-05
I0722 01:49:59.286614 23230 solver.cpp:243] Iteration 114490, loss = 2.49827
I0722 01:49:59.286931 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35372 (* 1 = 2.35372 loss)
I0722 01:49:59.287017 23230 sgd_solver.cpp:138] Iteration 114490, lr = 1e-05
I0722 01:51:27.590984 23230 solver.cpp:243] Iteration 114500, loss = 2.43769
I0722 01:51:27.591195 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.34411 (* 1 = 3.34411 loss)
I0722 01:51:27.591238 23230 sgd_solver.cpp:138] Iteration 114500, lr = 1e-05
I0722 01:52:53.824978 23230 solver.cpp:243] Iteration 114510, loss = 2.5179
I0722 01:52:53.825253 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.67506 (* 1 = 1.67506 loss)
I0722 01:52:53.825314 23230 sgd_solver.cpp:138] Iteration 114510, lr = 1e-05
I0722 01:54:16.631597 23230 solver.cpp:243] Iteration 114520, loss = 2.42899
I0722 01:54:16.631891 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74053 (* 1 = 2.74053 loss)
I0722 01:54:16.631991 23230 sgd_solver.cpp:138] Iteration 114520, lr = 1e-05
I0722 01:55:44.974697 23230 solver.cpp:243] Iteration 114530, loss = 2.4939
I0722 01:55:44.974925 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.68036 (* 1 = 2.68036 loss)
I0722 01:55:44.974982 23230 sgd_solver.cpp:138] Iteration 114530, lr = 1e-05
I0722 01:57:11.709671 23230 solver.cpp:243] Iteration 114540, loss = 2.38949
I0722 01:57:11.709964 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.58436 (* 1 = 1.58436 loss)
I0722 01:57:11.710119 23230 sgd_solver.cpp:138] Iteration 114540, lr = 1e-05
I0722 01:58:38.588867 23230 solver.cpp:243] Iteration 114550, loss = 2.59949
I0722 01:58:38.589056 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.45638 (* 1 = 4.45638 loss)
I0722 01:58:38.980398 23230 sgd_solver.cpp:138] Iteration 114550, lr = 1e-05
I0722 02:00:05.287181 23230 solver.cpp:243] Iteration 114560, loss = 2.69393
I0722 02:00:05.287533 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.76902 (* 1 = 2.76902 loss)
I0722 02:00:06.072633 23230 sgd_solver.cpp:138] Iteration 114560, lr = 1e-05
I0722 02:01:32.395830 23230 solver.cpp:243] Iteration 114570, loss = 2.47695
I0722 02:01:32.396175 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.0143 (* 1 = 4.0143 loss)
I0722 02:01:32.396276 23230 sgd_solver.cpp:138] Iteration 114570, lr = 1e-05
I0722 02:02:57.620440 23230 solver.cpp:243] Iteration 114580, loss = 2.67046
I0722 02:02:57.620735 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.18349 (* 1 = 1.18349 loss)
I0722 02:02:57.620836 23230 sgd_solver.cpp:138] Iteration 114580, lr = 1e-05
I0722 02:04:22.711280 23230 solver.cpp:243] Iteration 114590, loss = 2.53969
I0722 02:04:22.711540 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.87448 (* 1 = 5.87448 loss)
I0722 02:04:23.089610 23230 sgd_solver.cpp:138] Iteration 114590, lr = 1e-05
I0722 02:05:46.835346 23230 solver.cpp:243] Iteration 114600, loss = 2.64543
I0722 02:05:46.835605 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.38898 (* 1 = 1.38898 loss)
I0722 02:05:46.835728 23230 sgd_solver.cpp:138] Iteration 114600, lr = 1e-05
I0722 02:07:12.814456 23230 solver.cpp:243] Iteration 114610, loss = 2.42974
I0722 02:07:12.814898 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.05497 (* 1 = 1.05497 loss)
I0722 02:07:13.913401 23230 sgd_solver.cpp:138] Iteration 114610, lr = 1e-05
I0722 02:08:41.690176 23230 solver.cpp:243] Iteration 114620, loss = 2.75911
I0722 02:08:41.690449 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50686 (* 1 = 2.50686 loss)
I0722 02:08:41.690508 23230 sgd_solver.cpp:138] Iteration 114620, lr = 1e-05
I0722 02:10:08.736601 23230 solver.cpp:243] Iteration 114630, loss = 2.25082
I0722 02:10:08.736927 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31863 (* 1 = 2.31863 loss)
I0722 02:10:08.737069 23230 sgd_solver.cpp:138] Iteration 114630, lr = 1e-05
I0722 02:11:36.908800 23230 solver.cpp:243] Iteration 114640, loss = 2.5478
I0722 02:11:36.909040 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 02:11:37.744081 23230 sgd_solver.cpp:138] Iteration 114640, lr = 1e-05
I0722 02:13:03.531751 23230 solver.cpp:243] Iteration 114650, loss = 2.44267
I0722 02:13:03.532001 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32972 (* 1 = 1.32972 loss)
I0722 02:13:03.532047 23230 sgd_solver.cpp:138] Iteration 114650, lr = 1e-05
I0722 02:14:30.995159 23230 solver.cpp:243] Iteration 114660, loss = 2.6513
I0722 02:14:30.995407 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85131 (* 1 = 2.85131 loss)
I0722 02:14:30.995448 23230 sgd_solver.cpp:138] Iteration 114660, lr = 1e-05
I0722 02:15:57.217612 23230 solver.cpp:243] Iteration 114670, loss = 2.40955
I0722 02:15:57.219218 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37548 (* 1 = 2.37548 loss)
I0722 02:15:57.219274 23230 sgd_solver.cpp:138] Iteration 114670, lr = 1e-05
I0722 02:17:23.120682 23230 solver.cpp:243] Iteration 114680, loss = 2.49345
I0722 02:17:23.120884 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69638 (* 1 = 1.69638 loss)
I0722 02:17:23.120925 23230 sgd_solver.cpp:138] Iteration 114680, lr = 1e-05
I0722 02:18:50.072695 23230 solver.cpp:243] Iteration 114690, loss = 2.71499
I0722 02:18:50.073016 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85215 (* 1 = 1.85215 loss)
I0722 02:18:50.073119 23230 sgd_solver.cpp:138] Iteration 114690, lr = 1e-05
I0722 02:20:17.369041 23230 solver.cpp:243] Iteration 114700, loss = 2.37822
I0722 02:20:17.369379 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.52867 (* 1 = 2.52867 loss)
I0722 02:20:17.722371 23230 sgd_solver.cpp:138] Iteration 114700, lr = 1e-05
I0722 02:21:44.788810 23230 solver.cpp:243] Iteration 114710, loss = 2.70178
I0722 02:21:44.789108 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.46599 (* 1 = 2.46599 loss)
I0722 02:21:44.789222 23230 sgd_solver.cpp:138] Iteration 114710, lr = 1e-05
I0722 02:23:10.319929 23230 solver.cpp:243] Iteration 114720, loss = 2.67491
I0722 02:23:10.320293 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 02:23:11.068248 23230 sgd_solver.cpp:138] Iteration 114720, lr = 1e-05
I0722 02:24:36.653343 23230 solver.cpp:243] Iteration 114730, loss = 2.53614
I0722 02:24:36.653713 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02718 (* 1 = 2.02718 loss)
I0722 02:24:37.619078 23230 sgd_solver.cpp:138] Iteration 114730, lr = 1e-05
I0722 02:26:00.449395 23230 solver.cpp:243] Iteration 114740, loss = 2.54221
I0722 02:26:00.449630 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.19637 (* 1 = 1.19637 loss)
I0722 02:26:00.449681 23230 sgd_solver.cpp:138] Iteration 114740, lr = 1e-05
I0722 02:27:27.292809 23230 solver.cpp:243] Iteration 114750, loss = 2.66484
I0722 02:27:27.293182 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26765 (* 1 = 2.26765 loss)
I0722 02:27:28.639643 23230 sgd_solver.cpp:138] Iteration 114750, lr = 1e-05
I0722 02:28:54.591567 23230 solver.cpp:243] Iteration 114760, loss = 2.57029
I0722 02:28:54.591823 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.29587 (* 1 = 4.29587 loss)
I0722 02:28:54.591876 23230 sgd_solver.cpp:138] Iteration 114760, lr = 1e-05
I0722 02:30:21.733705 23230 solver.cpp:243] Iteration 114770, loss = 2.33258
I0722 02:30:21.733932 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35184 (* 1 = 2.35184 loss)
I0722 02:30:22.123335 23230 sgd_solver.cpp:138] Iteration 114770, lr = 1e-05
I0722 02:31:48.899801 23230 solver.cpp:243] Iteration 114780, loss = 2.53905
I0722 02:31:48.900022 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.24805 (* 1 = 1.24805 loss)
I0722 02:31:48.900061 23230 sgd_solver.cpp:138] Iteration 114780, lr = 1e-05
I0722 02:33:16.274426 23230 solver.cpp:243] Iteration 114790, loss = 2.56245
I0722 02:33:16.274700 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47555 (* 1 = 2.47555 loss)
I0722 02:33:16.274773 23230 sgd_solver.cpp:138] Iteration 114790, lr = 1e-05
I0722 02:34:42.032547 23230 solver.cpp:243] Iteration 114800, loss = 2.65995
I0722 02:34:42.032799 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.28859 (* 1 = 2.28859 loss)
I0722 02:34:42.032871 23230 sgd_solver.cpp:138] Iteration 114800, lr = 1e-05
I0722 02:36:12.884817 23230 solver.cpp:243] Iteration 114810, loss = 2.74423
I0722 02:36:12.885066 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.18662 (* 1 = 1.18662 loss)
I0722 02:36:12.885116 23230 sgd_solver.cpp:138] Iteration 114810, lr = 1e-05
I0722 02:37:41.390326 23230 solver.cpp:243] Iteration 114820, loss = 2.68196
I0722 02:37:41.390594 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20814 (* 1 = 1.20814 loss)
I0722 02:37:41.390700 23230 sgd_solver.cpp:138] Iteration 114820, lr = 1e-05
I0722 02:39:06.709440 23230 solver.cpp:243] Iteration 114830, loss = 2.54253
I0722 02:39:06.709729 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.08695 (* 1 = 4.08695 loss)
I0722 02:39:06.709838 23230 sgd_solver.cpp:138] Iteration 114830, lr = 1e-05
I0722 02:40:29.955812 23230 solver.cpp:243] Iteration 114840, loss = 2.65938
I0722 02:40:29.956041 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.39737 (* 1 = 2.39737 loss)
I0722 02:40:29.956085 23230 sgd_solver.cpp:138] Iteration 114840, lr = 1e-05
I0722 02:41:57.054868 23230 solver.cpp:243] Iteration 114850, loss = 2.41055
I0722 02:41:57.055178 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.74893 (* 1 = 1.74893 loss)
I0722 02:41:57.816864 23230 sgd_solver.cpp:138] Iteration 114850, lr = 1e-05
I0722 02:43:24.730924 23230 solver.cpp:243] Iteration 114860, loss = 2.60491
I0722 02:43:24.731168 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.57177 (* 1 = 3.57177 loss)
I0722 02:43:24.731209 23230 sgd_solver.cpp:138] Iteration 114860, lr = 1e-05
I0722 02:44:52.672696 23230 solver.cpp:243] Iteration 114870, loss = 2.92518
I0722 02:44:52.673007 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.30089 (* 1 = 3.30089 loss)
I0722 02:44:52.673100 23230 sgd_solver.cpp:138] Iteration 114870, lr = 1e-05
I0722 02:46:20.499846 23230 solver.cpp:243] Iteration 114880, loss = 2.49789
I0722 02:46:20.500149 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.90296 (* 1 = 1.90296 loss)
I0722 02:46:20.500186 23230 sgd_solver.cpp:138] Iteration 114880, lr = 1e-05
I0722 02:47:46.263331 23230 solver.cpp:243] Iteration 114890, loss = 2.59487
I0722 02:47:46.263561 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.77312 (* 1 = 4.77312 loss)
I0722 02:47:46.263605 23230 sgd_solver.cpp:138] Iteration 114890, lr = 1e-05
I0722 02:49:13.246593 23230 solver.cpp:243] Iteration 114900, loss = 2.44435
I0722 02:49:13.246819 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83155 (* 1 = 2.83155 loss)
I0722 02:49:13.246863 23230 sgd_solver.cpp:138] Iteration 114900, lr = 1e-05
I0722 02:50:40.167379 23230 solver.cpp:243] Iteration 114910, loss = 2.52313
I0722 02:50:40.167709 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.55274 (* 1 = 3.55274 loss)
I0722 02:50:40.167800 23230 sgd_solver.cpp:138] Iteration 114910, lr = 1e-05
I0722 02:52:05.239209 23230 solver.cpp:243] Iteration 114920, loss = 2.58182
I0722 02:52:05.239563 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.55478 (* 1 = 2.55478 loss)
I0722 02:52:05.239676 23230 sgd_solver.cpp:138] Iteration 114920, lr = 1e-05
I0722 02:53:32.726860 23230 solver.cpp:243] Iteration 114930, loss = 2.43373
I0722 02:53:32.727082 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37347 (* 1 = 2.37347 loss)
I0722 02:53:32.727128 23230 sgd_solver.cpp:138] Iteration 114930, lr = 1e-05
I0722 02:54:55.628887 23230 solver.cpp:243] Iteration 114940, loss = 2.35404
I0722 02:54:55.629139 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.04434 (* 1 = 5.04434 loss)
I0722 02:54:55.629191 23230 sgd_solver.cpp:138] Iteration 114940, lr = 1e-05
I0722 02:56:22.085490 23230 solver.cpp:243] Iteration 114950, loss = 2.66694
I0722 02:56:22.085738 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69723 (* 1 = 2.69723 loss)
I0722 02:56:22.085781 23230 sgd_solver.cpp:138] Iteration 114950, lr = 1e-05
I0722 02:57:51.634393 23230 solver.cpp:243] Iteration 114960, loss = 2.58552
I0722 02:57:51.634645 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85613 (* 1 = 1.85613 loss)
I0722 02:57:51.634714 23230 sgd_solver.cpp:138] Iteration 114960, lr = 1e-05
I0722 02:59:16.384335 23230 solver.cpp:243] Iteration 114970, loss = 2.64858
I0722 02:59:16.384587 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.77775 (* 1 = 2.77775 loss)
I0722 02:59:16.384639 23230 sgd_solver.cpp:138] Iteration 114970, lr = 1e-05
I0722 03:00:43.186318 23230 solver.cpp:243] Iteration 114980, loss = 2.59367
I0722 03:00:43.186648 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.96181 (* 1 = 1.96181 loss)
I0722 03:00:43.186760 23230 sgd_solver.cpp:138] Iteration 114980, lr = 1e-05
I0722 03:02:08.366462 23230 solver.cpp:243] Iteration 114990, loss = 2.18458
I0722 03:02:08.366799 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.13974 (* 1 = 3.13974 loss)
I0722 03:02:09.204465 23230 sgd_solver.cpp:138] Iteration 114990, lr = 1e-05
I0722 03:03:26.084414 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_115000.caffemodel
I0722 03:03:26.918520 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_115000.solverstate
I0722 03:03:27.117131 23230 solver.cpp:433] Iteration 115000, Testing net (#0)
I0722 03:03:27.148492 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 03:03:30.621526 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.619755
I0722 03:03:39.093854 23230 solver.cpp:243] Iteration 115000, loss = 2.73626
I0722 03:03:39.093966 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96603 (* 1 = 2.96603 loss)
I0722 03:03:39.094017 23230 sgd_solver.cpp:138] Iteration 115000, lr = 1e-05
I0722 03:05:06.898118 23230 solver.cpp:243] Iteration 115010, loss = 2.56451
I0722 03:05:06.898489 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.28959 (* 1 = 3.28959 loss)
I0722 03:05:06.898619 23230 sgd_solver.cpp:138] Iteration 115010, lr = 1e-05
I0722 03:06:33.974264 23230 solver.cpp:243] Iteration 115020, loss = 2.52162
I0722 03:06:33.974551 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.49462 (* 1 = 2.49462 loss)
I0722 03:06:33.974661 23230 sgd_solver.cpp:138] Iteration 115020, lr = 1e-05
I0722 03:08:01.111408 23230 solver.cpp:243] Iteration 115030, loss = 2.36988
I0722 03:08:01.111657 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 03:08:01.844789 23230 sgd_solver.cpp:138] Iteration 115030, lr = 1e-05
I0722 03:09:25.841133 23230 solver.cpp:243] Iteration 115040, loss = 2.5349
I0722 03:09:25.841408 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.30504 (* 1 = 1.30504 loss)
I0722 03:09:26.213335 23230 sgd_solver.cpp:138] Iteration 115040, lr = 1e-05
I0722 03:10:51.494832 23230 solver.cpp:243] Iteration 115050, loss = 2.42882
I0722 03:10:51.495103 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 03:10:51.858908 23230 sgd_solver.cpp:138] Iteration 115050, lr = 1e-05
I0722 03:12:18.424046 23230 solver.cpp:243] Iteration 115060, loss = 2.44515
I0722 03:12:18.424353 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.16168 (* 1 = 4.16168 loss)
I0722 03:12:18.424468 23230 sgd_solver.cpp:138] Iteration 115060, lr = 1e-05
I0722 03:13:45.516242 23230 solver.cpp:243] Iteration 115070, loss = 2.58146
I0722 03:13:45.516502 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.18795 (* 1 = 4.18795 loss)
I0722 03:13:45.516564 23230 sgd_solver.cpp:138] Iteration 115070, lr = 1e-05
I0722 03:15:10.489184 23230 solver.cpp:243] Iteration 115080, loss = 2.63568
I0722 03:15:10.489452 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45869 (* 1 = 1.45869 loss)
I0722 03:15:10.489498 23230 sgd_solver.cpp:138] Iteration 115080, lr = 1e-05
I0722 03:16:35.536402 23230 solver.cpp:243] Iteration 115090, loss = 2.52056
I0722 03:16:35.536728 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.03452 (* 1 = 4.03452 loss)
I0722 03:16:35.536828 23230 sgd_solver.cpp:138] Iteration 115090, lr = 1e-05
I0722 03:17:58.847582 23230 solver.cpp:243] Iteration 115100, loss = 2.49682
I0722 03:17:58.847937 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.21425 (* 1 = 3.21425 loss)
I0722 03:18:00.178143 23230 sgd_solver.cpp:138] Iteration 115100, lr = 1e-05
I0722 03:19:27.657367 23230 solver.cpp:243] Iteration 115110, loss = 2.60784
I0722 03:19:27.657683 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.19443 (* 1 = 3.19443 loss)
I0722 03:19:27.657794 23230 sgd_solver.cpp:138] Iteration 115110, lr = 1e-05
I0722 03:20:54.894706 23230 solver.cpp:243] Iteration 115120, loss = 2.75264
I0722 03:20:54.894942 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.08101 (* 1 = 2.08101 loss)
I0722 03:20:54.894982 23230 sgd_solver.cpp:138] Iteration 115120, lr = 1e-05
I0722 03:22:14.587218 23230 solver.cpp:243] Iteration 115130, loss = 2.64984
I0722 03:22:14.587458 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.8744 (* 1 = 3.8744 loss)
I0722 03:22:14.587507 23230 sgd_solver.cpp:138] Iteration 115130, lr = 1e-05
I0722 03:23:40.586104 23230 solver.cpp:243] Iteration 115140, loss = 2.54523
I0722 03:23:40.586345 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.75417 (* 1 = 2.75417 loss)
I0722 03:23:40.586392 23230 sgd_solver.cpp:138] Iteration 115140, lr = 1e-05
I0722 03:25:06.048326 23230 solver.cpp:243] Iteration 115150, loss = 2.67121
I0722 03:25:06.048622 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20009 (* 1 = 1.20009 loss)
I0722 03:25:06.048678 23230 sgd_solver.cpp:138] Iteration 115150, lr = 1e-05
I0722 03:26:31.076575 23230 solver.cpp:243] Iteration 115160, loss = 2.58045
I0722 03:26:31.076916 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.86881 (* 1 = 1.86881 loss)
I0722 03:26:31.460945 23230 sgd_solver.cpp:138] Iteration 115160, lr = 1e-05
I0722 03:27:57.198690 23230 solver.cpp:243] Iteration 115170, loss = 2.54168
I0722 03:27:57.198957 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.78138 (* 1 = 3.78138 loss)
I0722 03:27:57.199015 23230 sgd_solver.cpp:138] Iteration 115170, lr = 1e-05
I0722 03:29:21.553406 23230 solver.cpp:243] Iteration 115180, loss = 2.40238
I0722 03:29:21.553642 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83765 (* 1 = 2.83765 loss)
I0722 03:29:21.553692 23230 sgd_solver.cpp:138] Iteration 115180, lr = 1e-05
I0722 03:30:48.408972 23230 solver.cpp:243] Iteration 115190, loss = 2.70887
I0722 03:30:48.409199 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.39841 (* 1 = 2.39841 loss)
I0722 03:30:48.409241 23230 sgd_solver.cpp:138] Iteration 115190, lr = 1e-05
I0722 03:32:14.284885 23230 solver.cpp:243] Iteration 115200, loss = 2.63121
I0722 03:32:14.286857 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9008 (* 1 = 1.9008 loss)
I0722 03:32:14.286904 23230 sgd_solver.cpp:138] Iteration 115200, lr = 1e-05
I0722 03:33:43.108091 23230 solver.cpp:243] Iteration 115210, loss = 2.59903
I0722 03:33:43.108388 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9065 (* 1 = 1.9065 loss)
I0722 03:33:43.108527 23230 sgd_solver.cpp:138] Iteration 115210, lr = 1e-05
I0722 03:35:13.377660 23230 solver.cpp:243] Iteration 115220, loss = 2.78507
I0722 03:35:13.377934 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.828618 (* 1 = 0.828618 loss)
I0722 03:35:13.377984 23230 sgd_solver.cpp:138] Iteration 115220, lr = 1e-05
I0722 03:36:40.412590 23230 solver.cpp:243] Iteration 115230, loss = 2.37917
I0722 03:36:40.412839 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.94194 (* 1 = 3.94194 loss)
I0722 03:36:40.412881 23230 sgd_solver.cpp:138] Iteration 115230, lr = 1e-05
I0722 03:38:03.166031 23230 solver.cpp:243] Iteration 115240, loss = 2.58452
I0722 03:38:03.166265 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3162 (* 1 = 2.3162 loss)
I0722 03:38:03.917887 23230 sgd_solver.cpp:138] Iteration 115240, lr = 1e-05
I0722 03:39:28.943766 23230 solver.cpp:243] Iteration 115250, loss = 2.57952
I0722 03:39:28.944056 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.42473 (* 1 = 3.42473 loss)
I0722 03:39:28.944169 23230 sgd_solver.cpp:138] Iteration 115250, lr = 1e-05
I0722 03:40:53.986033 23230 solver.cpp:243] Iteration 115260, loss = 2.53085
I0722 03:40:53.986326 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.76901 (* 1 = 1.76901 loss)
I0722 03:40:53.986393 23230 sgd_solver.cpp:138] Iteration 115260, lr = 1e-05
I0722 03:42:19.772294 23230 solver.cpp:243] Iteration 115270, loss = 2.53977
I0722 03:42:19.772564 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.54417 (* 1 = 2.54417 loss)
I0722 03:42:19.772644 23230 sgd_solver.cpp:138] Iteration 115270, lr = 1e-05
I0722 03:43:42.499429 23230 solver.cpp:243] Iteration 115280, loss = 2.66718
I0722 03:43:42.499733 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.53908 (* 1 = 1.53908 loss)
I0722 03:43:42.499851 23230 sgd_solver.cpp:138] Iteration 115280, lr = 1e-05
I0722 03:45:08.429373 23230 solver.cpp:243] Iteration 115290, loss = 2.77437
I0722 03:45:08.429723 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69097 (* 1 = 1.69097 loss)
I0722 03:45:08.429833 23230 sgd_solver.cpp:138] Iteration 115290, lr = 1e-05
I0722 03:46:33.019699 23230 solver.cpp:243] Iteration 115300, loss = 2.46905
I0722 03:46:33.019932 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8897 (* 1 = 2.8897 loss)
I0722 03:46:33.019984 23230 sgd_solver.cpp:138] Iteration 115300, lr = 1e-05
I0722 03:47:59.116330 23230 solver.cpp:243] Iteration 115310, loss = 2.49629
I0722 03:47:59.116576 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.672 (* 1 = 1.672 loss)
I0722 03:47:59.116633 23230 sgd_solver.cpp:138] Iteration 115310, lr = 1e-05
I0722 03:49:22.075409 23230 solver.cpp:243] Iteration 115320, loss = 2.76698
I0722 03:49:22.075709 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.36486 (* 1 = 2.36486 loss)
I0722 03:49:22.075764 23230 sgd_solver.cpp:138] Iteration 115320, lr = 1e-05
I0722 03:50:47.707748 23230 solver.cpp:243] Iteration 115330, loss = 2.19505
I0722 03:50:47.708052 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.59205 (* 1 = 2.59205 loss)
I0722 03:50:47.708143 23230 sgd_solver.cpp:138] Iteration 115330, lr = 1e-05
I0722 03:52:14.780764 23230 solver.cpp:243] Iteration 115340, loss = 2.53405
I0722 03:52:14.780999 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.43675 (* 1 = 1.43675 loss)
I0722 03:52:14.781045 23230 sgd_solver.cpp:138] Iteration 115340, lr = 1e-05
I0722 03:53:42.999050 23230 solver.cpp:243] Iteration 115350, loss = 2.52945
I0722 03:53:42.999334 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.9078 (* 1 = 2.9078 loss)
I0722 03:53:42.999441 23230 sgd_solver.cpp:138] Iteration 115350, lr = 1e-05
I0722 03:55:07.655691 23230 solver.cpp:243] Iteration 115360, loss = 2.54531
I0722 03:55:07.655954 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04705 (* 1 = 3.04705 loss)
I0722 03:55:07.656003 23230 sgd_solver.cpp:138] Iteration 115360, lr = 1e-05
I0722 03:56:33.205399 23230 solver.cpp:243] Iteration 115370, loss = 2.40122
I0722 03:56:33.205687 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.34913 (* 1 = 2.34913 loss)
I0722 03:56:33.205778 23230 sgd_solver.cpp:138] Iteration 115370, lr = 1e-05
I0722 03:58:01.373575 23230 solver.cpp:243] Iteration 115380, loss = 2.64419
I0722 03:58:01.373864 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7505 (* 1 = 2.7505 loss)
I0722 03:58:01.373953 23230 sgd_solver.cpp:138] Iteration 115380, lr = 1e-05
I0722 03:59:26.601852 23230 solver.cpp:243] Iteration 115390, loss = 2.4733
I0722 03:59:26.602103 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45497 (* 1 = 1.45497 loss)
I0722 03:59:26.602144 23230 sgd_solver.cpp:138] Iteration 115390, lr = 1e-05
I0722 04:00:52.509043 23230 solver.cpp:243] Iteration 115400, loss = 2.62166
I0722 04:00:52.509277 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.89847 (* 1 = 1.89847 loss)
I0722 04:00:52.509318 23230 sgd_solver.cpp:138] Iteration 115400, lr = 1e-05
I0722 04:02:16.620185 23230 solver.cpp:243] Iteration 115410, loss = 2.55908
I0722 04:02:16.620440 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.927271 (* 1 = 0.927271 loss)
I0722 04:02:16.620491 23230 sgd_solver.cpp:138] Iteration 115410, lr = 1e-05
I0722 04:03:41.443693 23230 solver.cpp:243] Iteration 115420, loss = 2.73466
I0722 04:03:41.443964 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.11835 (* 1 = 3.11835 loss)
I0722 04:03:41.444042 23230 sgd_solver.cpp:138] Iteration 115420, lr = 1e-05
I0722 04:05:04.857866 23230 solver.cpp:243] Iteration 115430, loss = 2.5511
I0722 04:05:04.858170 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.21977 (* 1 = 2.21977 loss)
I0722 04:05:04.858261 23230 sgd_solver.cpp:138] Iteration 115430, lr = 1e-05
I0722 04:06:29.030478 23230 solver.cpp:243] Iteration 115440, loss = 2.79027
I0722 04:06:29.030829 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.39059 (* 1 = 3.39059 loss)
I0722 04:06:29.030933 23230 sgd_solver.cpp:138] Iteration 115440, lr = 1e-05
I0722 04:07:55.691860 23230 solver.cpp:243] Iteration 115450, loss = 2.50181
I0722 04:07:55.692102 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.75516 (* 1 = 1.75516 loss)
I0722 04:07:55.692143 23230 sgd_solver.cpp:138] Iteration 115450, lr = 1e-05
I0722 04:09:20.464514 23230 solver.cpp:243] Iteration 115460, loss = 2.58116
I0722 04:09:20.464742 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.16094 (* 1 = 3.16094 loss)
I0722 04:09:20.464793 23230 sgd_solver.cpp:138] Iteration 115460, lr = 1e-05
I0722 04:10:46.637058 23230 solver.cpp:243] Iteration 115470, loss = 2.61248
I0722 04:10:46.637286 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.03899 (* 1 = 3.03899 loss)
I0722 04:10:46.637339 23230 sgd_solver.cpp:138] Iteration 115470, lr = 1e-05
I0722 04:12:12.627424 23230 solver.cpp:243] Iteration 115480, loss = 2.53623
I0722 04:12:12.627734 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.23662 (* 1 = 1.23662 loss)
I0722 04:12:12.627775 23230 sgd_solver.cpp:138] Iteration 115480, lr = 1e-05
I0722 04:13:40.081817 23230 solver.cpp:243] Iteration 115490, loss = 2.4972
I0722 04:13:40.082154 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.31628 (* 1 = 3.31628 loss)
I0722 04:13:40.082264 23230 sgd_solver.cpp:138] Iteration 115490, lr = 1e-05
I0722 04:15:06.604439 23230 solver.cpp:243] Iteration 115500, loss = 2.71199
I0722 04:15:06.604693 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.45877 (* 1 = 3.45877 loss)
I0722 04:15:06.604737 23230 sgd_solver.cpp:138] Iteration 115500, lr = 1e-05
I0722 04:16:30.075086 23230 solver.cpp:243] Iteration 115510, loss = 2.60721
I0722 04:16:30.075322 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82866 (* 1 = 1.82866 loss)
I0722 04:16:30.075364 23230 sgd_solver.cpp:138] Iteration 115510, lr = 1e-05
I0722 04:17:55.900681 23230 solver.cpp:243] Iteration 115520, loss = 2.46398
I0722 04:17:55.901062 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.26905 (* 1 = 3.26905 loss)
I0722 04:17:56.308284 23230 sgd_solver.cpp:138] Iteration 115520, lr = 1e-05
I0722 04:19:16.073150 23230 solver.cpp:243] Iteration 115530, loss = 2.4879
I0722 04:19:16.073449 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.5918 (* 1 = 2.5918 loss)
I0722 04:19:16.854095 23230 sgd_solver.cpp:138] Iteration 115530, lr = 1e-05
I0722 04:20:40.631160 23230 solver.cpp:243] Iteration 115540, loss = 2.50122
I0722 04:20:40.631392 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.78463 (* 1 = 1.78463 loss)
I0722 04:20:41.412694 23230 sgd_solver.cpp:138] Iteration 115540, lr = 1e-05
I0722 04:22:03.131016 23230 solver.cpp:243] Iteration 115550, loss = 2.46575
I0722 04:22:03.131317 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.55 (* 1 = 1.55 loss)
I0722 04:22:03.131428 23230 sgd_solver.cpp:138] Iteration 115550, lr = 1e-05
I0722 04:23:26.530513 23230 solver.cpp:243] Iteration 115560, loss = 2.70393
I0722 04:23:26.530779 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80939 (* 1 = 1.80939 loss)
I0722 04:23:26.530827 23230 sgd_solver.cpp:138] Iteration 115560, lr = 1e-05
I0722 04:24:53.395895 23230 solver.cpp:243] Iteration 115570, loss = 2.72911
I0722 04:24:53.396124 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35834 (* 1 = 2.35834 loss)
I0722 04:24:54.151989 23230 sgd_solver.cpp:138] Iteration 115570, lr = 1e-05
I0722 04:26:19.496677 23230 solver.cpp:243] Iteration 115580, loss = 2.28687
I0722 04:26:19.496950 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.2393 (* 1 = 3.2393 loss)
I0722 04:26:19.496996 23230 sgd_solver.cpp:138] Iteration 115580, lr = 1e-05
I0722 04:27:45.038101 23230 solver.cpp:243] Iteration 115590, loss = 2.56569
I0722 04:27:45.038378 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.13361 (* 1 = 1.13361 loss)
I0722 04:27:45.038473 23230 sgd_solver.cpp:138] Iteration 115590, lr = 1e-05
I0722 04:29:13.791152 23230 solver.cpp:243] Iteration 115600, loss = 2.4472
I0722 04:29:13.791451 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.89375 (* 1 = 2.89375 loss)
I0722 04:29:14.145663 23230 sgd_solver.cpp:138] Iteration 115600, lr = 1e-05
I0722 04:30:39.019346 23230 solver.cpp:243] Iteration 115610, loss = 2.17341
I0722 04:30:39.019600 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83658 (* 1 = 2.83658 loss)
I0722 04:30:39.019655 23230 sgd_solver.cpp:138] Iteration 115610, lr = 1e-05
I0722 04:32:04.717876 23230 solver.cpp:243] Iteration 115620, loss = 2.4394
I0722 04:32:04.718185 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08664 (* 1 = 3.08664 loss)
I0722 04:32:04.718281 23230 sgd_solver.cpp:138] Iteration 115620, lr = 1e-05
I0722 04:33:28.803467 23230 solver.cpp:243] Iteration 115630, loss = 2.51523
I0722 04:33:28.803848 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.71222 (* 1 = 3.71222 loss)
I0722 04:33:28.803973 23230 sgd_solver.cpp:138] Iteration 115630, lr = 1e-05
I0722 04:34:53.159220 23230 solver.cpp:243] Iteration 115640, loss = 2.63417
I0722 04:34:53.159535 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.21776 (* 1 = 2.21776 loss)
I0722 04:34:53.159667 23230 sgd_solver.cpp:138] Iteration 115640, lr = 1e-05
I0722 04:36:18.285719 23230 solver.cpp:243] Iteration 115650, loss = 2.61622
I0722 04:36:18.286085 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.20628 (* 1 = 3.20628 loss)
I0722 04:36:18.286185 23230 sgd_solver.cpp:138] Iteration 115650, lr = 1e-05
I0722 04:37:44.596483 23230 solver.cpp:243] Iteration 115660, loss = 2.69109
I0722 04:37:44.596791 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.08209 (* 1 = 2.08209 loss)
I0722 04:37:44.596877 23230 sgd_solver.cpp:138] Iteration 115660, lr = 1e-05
I0722 04:39:11.133476 23230 solver.cpp:243] Iteration 115670, loss = 2.49057
I0722 04:39:11.133730 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.52195 (* 1 = 2.52195 loss)
I0722 04:39:11.133776 23230 sgd_solver.cpp:138] Iteration 115670, lr = 1e-05
I0722 04:40:34.235489 23230 solver.cpp:243] Iteration 115680, loss = 2.59273
I0722 04:40:34.235764 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.11941 (* 1 = 2.11941 loss)
I0722 04:40:35.161011 23230 sgd_solver.cpp:138] Iteration 115680, lr = 1e-05
I0722 04:41:59.146078 23230 solver.cpp:243] Iteration 115690, loss = 2.30481
I0722 04:41:59.146314 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.7663 (* 1 = 4.7663 loss)
I0722 04:41:59.146359 23230 sgd_solver.cpp:138] Iteration 115690, lr = 1e-05
I0722 04:43:22.336880 23230 solver.cpp:243] Iteration 115700, loss = 2.56969
I0722 04:43:22.337215 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05385 (* 1 = 2.05385 loss)
I0722 04:43:22.337311 23230 sgd_solver.cpp:138] Iteration 115700, lr = 1e-05
I0722 04:44:46.822360 23230 solver.cpp:243] Iteration 115710, loss = 2.59824
I0722 04:44:46.822585 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.42259 (* 1 = 4.42259 loss)
I0722 04:44:46.822625 23230 sgd_solver.cpp:138] Iteration 115710, lr = 1e-05
I0722 04:46:08.533212 23230 solver.cpp:243] Iteration 115720, loss = 2.70563
I0722 04:46:08.533476 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17222 (* 1 = 2.17222 loss)
I0722 04:46:09.510035 23230 sgd_solver.cpp:138] Iteration 115720, lr = 1e-05
I0722 04:47:32.648353 23230 solver.cpp:243] Iteration 115730, loss = 2.31465
I0722 04:47:32.648612 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.30485 (* 1 = 2.30485 loss)
I0722 04:47:32.648661 23230 sgd_solver.cpp:138] Iteration 115730, lr = 1e-05
I0722 04:48:59.181120 23230 solver.cpp:243] Iteration 115740, loss = 2.59328
I0722 04:48:59.181394 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.68937 (* 1 = 1.68937 loss)
I0722 04:48:59.181473 23230 sgd_solver.cpp:138] Iteration 115740, lr = 1e-05
I0722 04:50:26.779618 23230 solver.cpp:243] Iteration 115750, loss = 2.53699
I0722 04:50:26.779918 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3228 (* 1 = 2.3228 loss)
I0722 04:50:26.780041 23230 sgd_solver.cpp:138] Iteration 115750, lr = 1e-05
I0722 04:51:56.933353 23230 solver.cpp:243] Iteration 115760, loss = 2.65044
I0722 04:51:56.933629 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.05076 (* 1 = 1.05076 loss)
I0722 04:51:57.346678 23230 sgd_solver.cpp:138] Iteration 115760, lr = 1e-05
I0722 04:53:24.461518 23230 solver.cpp:243] Iteration 115770, loss = 2.69924
I0722 04:53:24.461833 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25424 (* 1 = 1.25424 loss)
I0722 04:53:24.810248 23230 sgd_solver.cpp:138] Iteration 115770, lr = 1e-05
I0722 04:54:49.783457 23230 solver.cpp:243] Iteration 115780, loss = 2.25611
I0722 04:54:49.783704 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.5713 (* 1 = 1.5713 loss)
I0722 04:54:49.783742 23230 sgd_solver.cpp:138] Iteration 115780, lr = 1e-05
I0722 04:56:18.163950 23230 solver.cpp:243] Iteration 115790, loss = 2.6225
I0722 04:56:18.164274 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.58825 (* 1 = 3.58825 loss)
I0722 04:56:18.164350 23230 sgd_solver.cpp:138] Iteration 115790, lr = 1e-05
I0722 04:57:43.764207 23230 solver.cpp:243] Iteration 115800, loss = 2.41675
I0722 04:57:43.764497 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03934 (* 1 = 2.03934 loss)
I0722 04:57:43.764575 23230 sgd_solver.cpp:138] Iteration 115800, lr = 1e-05
I0722 04:59:09.657187 23230 solver.cpp:243] Iteration 115810, loss = 2.5665
I0722 04:59:09.657521 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69089 (* 1 = 2.69089 loss)
I0722 04:59:09.657651 23230 sgd_solver.cpp:138] Iteration 115810, lr = 1e-05
I0722 05:00:37.449254 23230 solver.cpp:243] Iteration 115820, loss = 2.45449
I0722 05:00:37.449610 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.78412 (* 1 = 1.78412 loss)
I0722 05:00:37.449739 23230 sgd_solver.cpp:138] Iteration 115820, lr = 1e-05
I0722 05:02:05.689047 23230 solver.cpp:243] Iteration 115830, loss = 2.67318
I0722 05:02:05.689319 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82826 (* 1 = 2.82826 loss)
I0722 05:02:05.689436 23230 sgd_solver.cpp:138] Iteration 115830, lr = 1e-05
I0722 05:03:34.606886 23230 solver.cpp:243] Iteration 115840, loss = 2.66808
I0722 05:03:34.607157 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.44827 (* 1 = 2.44827 loss)
I0722 05:03:34.607223 23230 sgd_solver.cpp:138] Iteration 115840, lr = 1e-05
I0722 05:05:00.297644 23230 solver.cpp:243] Iteration 115850, loss = 2.5734
I0722 05:05:00.297874 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.35332 (* 1 = 1.35332 loss)
I0722 05:05:00.297929 23230 sgd_solver.cpp:138] Iteration 115850, lr = 1e-05
I0722 05:06:29.100646 23230 solver.cpp:243] Iteration 115860, loss = 2.62356
I0722 05:06:29.100879 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.0724 (* 1 = 5.0724 loss)
I0722 05:06:29.100922 23230 sgd_solver.cpp:138] Iteration 115860, lr = 1e-05
I0722 05:07:55.328135 23230 solver.cpp:243] Iteration 115870, loss = 2.70368
I0722 05:07:55.328469 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32872 (* 1 = 3.32872 loss)
I0722 05:07:55.328570 23230 sgd_solver.cpp:138] Iteration 115870, lr = 1e-05
I0722 05:09:21.003999 23230 solver.cpp:243] Iteration 115880, loss = 2.54688
I0722 05:09:21.004338 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.15365 (* 1 = 1.15365 loss)
I0722 05:09:22.013429 23230 sgd_solver.cpp:138] Iteration 115880, lr = 1e-05
I0722 05:10:48.156759 23230 solver.cpp:243] Iteration 115890, loss = 2.59946
I0722 05:10:48.157153 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.72939 (* 1 = 2.72939 loss)
I0722 05:10:48.157271 23230 sgd_solver.cpp:138] Iteration 115890, lr = 1e-05
I0722 05:12:12.492521 23230 solver.cpp:243] Iteration 115900, loss = 2.61255
I0722 05:12:12.492789 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01219 (* 1 = 3.01219 loss)
I0722 05:12:12.492830 23230 sgd_solver.cpp:138] Iteration 115900, lr = 1e-05
I0722 05:13:40.526340 23230 solver.cpp:243] Iteration 115910, loss = 2.64725
I0722 05:13:40.526837 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67313 (* 1 = 2.67313 loss)
I0722 05:13:40.526897 23230 sgd_solver.cpp:138] Iteration 115910, lr = 1e-05
I0722 05:15:06.857504 23230 solver.cpp:243] Iteration 115920, loss = 2.52548
I0722 05:15:06.857733 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.23044 (* 1 = 2.23044 loss)
I0722 05:15:06.857774 23230 sgd_solver.cpp:138] Iteration 115920, lr = 1e-05
I0722 05:16:30.731482 23230 solver.cpp:243] Iteration 115930, loss = 2.50673
I0722 05:16:30.731772 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85633 (* 1 = 1.85633 loss)
I0722 05:16:30.731844 23230 sgd_solver.cpp:138] Iteration 115930, lr = 1e-05
I0722 05:17:55.873376 23230 solver.cpp:243] Iteration 115940, loss = 2.43238
I0722 05:17:55.873677 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.25988 (* 1 = 3.25988 loss)
I0722 05:17:56.234184 23230 sgd_solver.cpp:138] Iteration 115940, lr = 1e-05
I0722 05:19:24.117444 23230 solver.cpp:243] Iteration 115950, loss = 2.49164
I0722 05:19:24.117704 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7405 (* 1 = 1.7405 loss)
I0722 05:19:24.117816 23230 sgd_solver.cpp:138] Iteration 115950, lr = 1e-05
I0722 05:20:52.722399 23230 solver.cpp:243] Iteration 115960, loss = 2.46809
I0722 05:20:52.722695 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.11242 (* 1 = 3.11242 loss)
I0722 05:20:52.722878 23230 sgd_solver.cpp:138] Iteration 115960, lr = 1e-05
I0722 05:22:20.312798 23230 solver.cpp:243] Iteration 115970, loss = 2.67005
I0722 05:22:20.313099 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.23053 (* 1 = 3.23053 loss)
I0722 05:22:20.313163 23230 sgd_solver.cpp:138] Iteration 115970, lr = 1e-05
I0722 05:23:47.622326 23230 solver.cpp:243] Iteration 115980, loss = 2.47432
I0722 05:23:47.622601 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 05:23:47.622712 23230 sgd_solver.cpp:138] Iteration 115980, lr = 1e-05
I0722 05:25:12.205065 23230 solver.cpp:243] Iteration 115990, loss = 2.54034
I0722 05:25:12.206216 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.76605 (* 1 = 1.76605 loss)
I0722 05:25:12.618448 23230 sgd_solver.cpp:138] Iteration 115990, lr = 1e-05
I0722 05:26:28.827436 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_116000.caffemodel
I0722 05:26:29.655619 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_116000.solverstate
I0722 05:26:29.858698 23230 solver.cpp:433] Iteration 116000, Testing net (#0)
I0722 05:26:29.858891 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 05:26:33.381863 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.614335
I0722 05:26:41.678949 23230 solver.cpp:243] Iteration 116000, loss = 2.53685
I0722 05:26:41.679044 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.15029 (* 1 = 1.15029 loss)
I0722 05:26:41.679091 23230 sgd_solver.cpp:138] Iteration 116000, lr = 1e-05
I0722 05:28:04.078147 23230 solver.cpp:243] Iteration 116010, loss = 2.48629
I0722 05:28:04.078444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05671 (* 1 = 2.05671 loss)
I0722 05:28:04.078555 23230 sgd_solver.cpp:138] Iteration 116010, lr = 1e-05
I0722 05:29:28.722719 23230 solver.cpp:243] Iteration 116020, loss = 2.60088
I0722 05:29:28.723004 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38665 (* 1 = 2.38665 loss)
I0722 05:29:28.723109 23230 sgd_solver.cpp:138] Iteration 116020, lr = 1e-05
I0722 05:30:54.360996 23230 solver.cpp:243] Iteration 116030, loss = 2.59238
I0722 05:30:54.361222 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.98478 (* 1 = 3.98478 loss)
I0722 05:30:54.361260 23230 sgd_solver.cpp:138] Iteration 116030, lr = 1e-05
I0722 05:32:20.494046 23230 solver.cpp:243] Iteration 116040, loss = 2.59689
I0722 05:32:20.494328 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.4015 (* 1 = 3.4015 loss)
I0722 05:32:20.494406 23230 sgd_solver.cpp:138] Iteration 116040, lr = 1e-05
I0722 05:33:45.606181 23230 solver.cpp:243] Iteration 116050, loss = 2.73558
I0722 05:33:45.606464 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.88888 (* 1 = 3.88888 loss)
I0722 05:33:45.970253 23230 sgd_solver.cpp:138] Iteration 116050, lr = 1e-05
I0722 05:35:12.420816 23230 solver.cpp:243] Iteration 116060, loss = 2.71957
I0722 05:35:12.421054 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.61444 (* 1 = 3.61444 loss)
I0722 05:35:12.421103 23230 sgd_solver.cpp:138] Iteration 116060, lr = 1e-05
I0722 05:36:40.591274 23230 solver.cpp:243] Iteration 116070, loss = 2.59056
I0722 05:36:40.591665 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78501 (* 1 = 2.78501 loss)
I0722 05:36:40.591810 23230 sgd_solver.cpp:138] Iteration 116070, lr = 1e-05
I0722 05:38:07.564328 23230 solver.cpp:243] Iteration 116080, loss = 2.44781
I0722 05:38:07.564651 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.98771 (* 1 = 3.98771 loss)
I0722 05:38:07.564792 23230 sgd_solver.cpp:138] Iteration 116080, lr = 1e-05
I0722 05:39:34.751351 23230 solver.cpp:243] Iteration 116090, loss = 2.60729
I0722 05:39:34.751624 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.25516 (* 1 = 2.25516 loss)
I0722 05:39:34.751777 23230 sgd_solver.cpp:138] Iteration 116090, lr = 1e-05
I0722 05:41:01.710916 23230 solver.cpp:243] Iteration 116100, loss = 2.53733
I0722 05:41:01.711182 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.45206 (* 1 = 2.45206 loss)
I0722 05:41:02.072010 23230 sgd_solver.cpp:138] Iteration 116100, lr = 1e-05
I0722 05:42:23.836882 23230 solver.cpp:243] Iteration 116110, loss = 2.69168
I0722 05:42:23.837146 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.36982 (* 1 = 2.36982 loss)
I0722 05:42:23.837245 23230 sgd_solver.cpp:138] Iteration 116110, lr = 1e-05
I0722 05:43:44.767083 23230 solver.cpp:243] Iteration 116120, loss = 2.50373
I0722 05:43:44.767349 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.95683 (* 1 = 1.95683 loss)
I0722 05:43:45.499198 23230 sgd_solver.cpp:138] Iteration 116120, lr = 1e-05
I0722 05:45:12.550743 23230 solver.cpp:243] Iteration 116130, loss = 2.34644
I0722 05:45:12.551120 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.55163 (* 1 = 3.55163 loss)
I0722 05:45:12.551270 23230 sgd_solver.cpp:138] Iteration 116130, lr = 1e-05
I0722 05:46:39.113668 23230 solver.cpp:243] Iteration 116140, loss = 2.40959
I0722 05:46:39.113991 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.28974 (* 1 = 3.28974 loss)
I0722 05:46:39.499140 23230 sgd_solver.cpp:138] Iteration 116140, lr = 1e-05
I0722 05:48:06.928560 23230 solver.cpp:243] Iteration 116150, loss = 2.42541
I0722 05:48:06.928807 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31795 (* 1 = 2.31795 loss)
I0722 05:48:07.678207 23230 sgd_solver.cpp:138] Iteration 116150, lr = 1e-05
I0722 05:49:31.630908 23230 solver.cpp:243] Iteration 116160, loss = 2.36798
I0722 05:49:31.631119 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03468 (* 1 = 2.03468 loss)
I0722 05:49:31.631167 23230 sgd_solver.cpp:138] Iteration 116160, lr = 1e-05
I0722 05:50:56.038394 23230 solver.cpp:243] Iteration 116170, loss = 2.57999
I0722 05:50:56.038687 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.0064 (* 1 = 3.0064 loss)
I0722 05:50:56.038801 23230 sgd_solver.cpp:138] Iteration 116170, lr = 1e-05
I0722 05:52:21.484570 23230 solver.cpp:243] Iteration 116180, loss = 2.46559
I0722 05:52:21.484901 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.35859 (* 1 = 3.35859 loss)
I0722 05:52:21.485016 23230 sgd_solver.cpp:138] Iteration 116180, lr = 1e-05
I0722 05:53:49.239390 23230 solver.cpp:243] Iteration 116190, loss = 2.52315
I0722 05:53:49.239630 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.75293 (* 1 = 1.75293 loss)
I0722 05:53:49.239675 23230 sgd_solver.cpp:138] Iteration 116190, lr = 1e-05
I0722 05:55:15.439661 23230 solver.cpp:243] Iteration 116200, loss = 2.5886
I0722 05:55:15.439918 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27269 (* 1 = 3.27269 loss)
I0722 05:55:16.195860 23230 sgd_solver.cpp:138] Iteration 116200, lr = 1e-05
I0722 05:56:41.141479 23230 solver.cpp:243] Iteration 116210, loss = 2.52064
I0722 05:56:41.141752 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.13886 (* 1 = 3.13886 loss)
I0722 05:56:41.141800 23230 sgd_solver.cpp:138] Iteration 116210, lr = 1e-05
I0722 05:58:07.530295 23230 solver.cpp:243] Iteration 116220, loss = 2.67154
I0722 05:58:07.530505 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.51858 (* 1 = 2.51858 loss)
I0722 05:58:07.530562 23230 sgd_solver.cpp:138] Iteration 116220, lr = 1e-05
I0722 05:59:31.012073 23230 solver.cpp:243] Iteration 116230, loss = 2.49658
I0722 05:59:31.012491 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24962 (* 1 = 2.24962 loss)
I0722 05:59:31.375797 23230 sgd_solver.cpp:138] Iteration 116230, lr = 1e-05
I0722 06:00:54.342373 23230 solver.cpp:243] Iteration 116240, loss = 2.4538
I0722 06:00:54.342610 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.52555 (* 1 = 3.52555 loss)
I0722 06:00:55.054695 23230 sgd_solver.cpp:138] Iteration 116240, lr = 1e-05
I0722 06:02:22.946882 23230 solver.cpp:243] Iteration 116250, loss = 2.62946
I0722 06:02:22.947096 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.46122 (* 1 = 2.46122 loss)
I0722 06:02:22.947144 23230 sgd_solver.cpp:138] Iteration 116250, lr = 1e-05
I0722 06:03:52.646406 23230 solver.cpp:243] Iteration 116260, loss = 2.50341
I0722 06:03:52.646692 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78817 (* 1 = 2.78817 loss)
I0722 06:03:52.646783 23230 sgd_solver.cpp:138] Iteration 116260, lr = 1e-05
I0722 06:05:17.398468 23230 solver.cpp:243] Iteration 116270, loss = 2.94444
I0722 06:05:17.398754 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.4926 (* 1 = 5.4926 loss)
I0722 06:05:19.256603 23230 sgd_solver.cpp:138] Iteration 116270, lr = 1e-05
I0722 06:06:45.985553 23230 solver.cpp:243] Iteration 116280, loss = 2.64494
I0722 06:06:45.985846 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15513 (* 1 = 2.15513 loss)
I0722 06:06:46.338733 23230 sgd_solver.cpp:138] Iteration 116280, lr = 1e-05
I0722 06:08:10.596375 23230 solver.cpp:243] Iteration 116290, loss = 2.33255
I0722 06:08:10.596613 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.22984 (* 1 = 2.22984 loss)
I0722 06:08:11.368582 23230 sgd_solver.cpp:138] Iteration 116290, lr = 1e-05
I0722 06:09:37.240613 23230 solver.cpp:243] Iteration 116300, loss = 2.64478
I0722 06:09:37.240885 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.2322 (* 1 = 6.2322 loss)
I0722 06:09:37.240952 23230 sgd_solver.cpp:138] Iteration 116300, lr = 1e-05
I0722 06:11:00.845286 23230 solver.cpp:243] Iteration 116310, loss = 2.63958
I0722 06:11:00.845559 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.71718 (* 1 = 1.71718 loss)
I0722 06:11:01.214434 23230 sgd_solver.cpp:138] Iteration 116310, lr = 1e-05
I0722 06:12:28.362846 23230 solver.cpp:243] Iteration 116320, loss = 2.72656
I0722 06:12:28.363077 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.39235 (* 1 = 1.39235 loss)
I0722 06:12:28.363121 23230 sgd_solver.cpp:138] Iteration 116320, lr = 1e-05
I0722 06:13:54.465886 23230 solver.cpp:243] Iteration 116330, loss = 2.35484
I0722 06:13:54.466152 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.58411 (* 1 = 3.58411 loss)
I0722 06:13:54.466229 23230 sgd_solver.cpp:138] Iteration 116330, lr = 1e-05
I0722 06:15:17.983911 23230 solver.cpp:243] Iteration 116340, loss = 2.55555
I0722 06:15:17.984185 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60157 (* 1 = 2.60157 loss)
I0722 06:15:19.243127 23230 sgd_solver.cpp:138] Iteration 116340, lr = 1e-05
I0722 06:16:45.851171 23230 solver.cpp:243] Iteration 116350, loss = 2.4627
I0722 06:16:45.851444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40694 (* 1 = 2.40694 loss)
I0722 06:16:45.851546 23230 sgd_solver.cpp:138] Iteration 116350, lr = 1e-05
I0722 06:18:12.201843 23230 solver.cpp:243] Iteration 116360, loss = 2.56863
I0722 06:18:12.202170 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85708 (* 1 = 1.85708 loss)
I0722 06:18:12.603344 23230 sgd_solver.cpp:138] Iteration 116360, lr = 1e-05
I0722 06:19:37.806210 23230 solver.cpp:243] Iteration 116370, loss = 2.62852
I0722 06:19:37.806514 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03758 (* 1 = 2.03758 loss)
I0722 06:19:37.806608 23230 sgd_solver.cpp:138] Iteration 116370, lr = 1e-05
I0722 06:21:05.468180 23230 solver.cpp:243] Iteration 116380, loss = 2.4161
I0722 06:21:05.468444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.02473 (* 1 = 5.02473 loss)
I0722 06:21:05.856209 23230 sgd_solver.cpp:138] Iteration 116380, lr = 1e-05
I0722 06:22:34.680410 23230 solver.cpp:243] Iteration 116390, loss = 2.56332
I0722 06:22:34.680760 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.19632 (* 1 = 3.19632 loss)
I0722 06:22:34.680874 23230 sgd_solver.cpp:138] Iteration 116390, lr = 1e-05
I0722 06:24:04.141578 23230 solver.cpp:243] Iteration 116400, loss = 2.62497
I0722 06:24:04.141849 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.24908 (* 1 = 3.24908 loss)
I0722 06:24:04.141930 23230 sgd_solver.cpp:138] Iteration 116400, lr = 1e-05
I0722 06:25:32.982851 23230 solver.cpp:243] Iteration 116410, loss = 2.49242
I0722 06:25:32.983112 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.35894 (* 1 = 1.35894 loss)
I0722 06:25:32.983170 23230 sgd_solver.cpp:138] Iteration 116410, lr = 1e-05
I0722 06:27:02.035058 23230 solver.cpp:243] Iteration 116420, loss = 2.44686
I0722 06:27:02.035291 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.64939 (* 1 = 3.64939 loss)
I0722 06:27:02.035336 23230 sgd_solver.cpp:138] Iteration 116420, lr = 1e-05
I0722 06:28:29.056627 23230 solver.cpp:243] Iteration 116430, loss = 2.76708
I0722 06:28:29.056984 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03062 (* 1 = 2.03062 loss)
I0722 06:28:29.413586 23230 sgd_solver.cpp:138] Iteration 116430, lr = 1e-05
I0722 06:30:01.011050 23230 solver.cpp:243] Iteration 116440, loss = 2.32658
I0722 06:30:01.011349 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.981319 (* 1 = 0.981319 loss)
I0722 06:30:01.365275 23230 sgd_solver.cpp:138] Iteration 116440, lr = 1e-05
I0722 06:31:30.504925 23230 solver.cpp:243] Iteration 116450, loss = 2.34389
I0722 06:31:30.505220 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76249 (* 1 = 3.76249 loss)
I0722 06:31:30.505331 23230 sgd_solver.cpp:138] Iteration 116450, lr = 1e-05
I0722 06:33:00.618643 23230 solver.cpp:243] Iteration 116460, loss = 2.52278
I0722 06:33:00.618963 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.99953 (* 1 = 2.99953 loss)
I0722 06:33:00.619053 23230 sgd_solver.cpp:138] Iteration 116460, lr = 1e-05
I0722 06:34:28.692775 23230 solver.cpp:243] Iteration 116470, loss = 2.44145
I0722 06:34:28.693015 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38585 (* 1 = 2.38585 loss)
I0722 06:34:28.693053 23230 sgd_solver.cpp:138] Iteration 116470, lr = 1e-05
I0722 06:35:55.033902 23230 solver.cpp:243] Iteration 116480, loss = 2.3304
I0722 06:35:55.034245 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4176 (* 1 = 2.4176 loss)
I0722 06:35:55.034328 23230 sgd_solver.cpp:138] Iteration 116480, lr = 1e-05
I0722 06:37:22.833750 23230 solver.cpp:243] Iteration 116490, loss = 2.5953
I0722 06:37:22.834048 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.59381 (* 1 = 3.59381 loss)
I0722 06:37:22.834187 23230 sgd_solver.cpp:138] Iteration 116490, lr = 1e-05
I0722 06:38:52.175047 23230 solver.cpp:243] Iteration 116500, loss = 2.65554
I0722 06:38:52.175379 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82203 (* 1 = 2.82203 loss)
I0722 06:38:52.175525 23230 sgd_solver.cpp:138] Iteration 116500, lr = 1e-05
I0722 06:40:14.182557 23230 solver.cpp:243] Iteration 116510, loss = 2.58975
I0722 06:40:14.182802 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83904 (* 1 = 2.83904 loss)
I0722 06:40:14.182852 23230 sgd_solver.cpp:138] Iteration 116510, lr = 1e-05
I0722 06:41:39.497426 23230 solver.cpp:243] Iteration 116520, loss = 2.3453
I0722 06:41:39.497740 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.19848 (* 1 = 2.19848 loss)
I0722 06:41:39.497846 23230 sgd_solver.cpp:138] Iteration 116520, lr = 1e-05
I0722 06:43:07.880452 23230 solver.cpp:243] Iteration 116530, loss = 2.69232
I0722 06:43:07.880754 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.06952 (* 1 = 4.06952 loss)
I0722 06:43:07.880867 23230 sgd_solver.cpp:138] Iteration 116530, lr = 1e-05
I0722 06:44:34.853549 23230 solver.cpp:243] Iteration 116540, loss = 2.50803
I0722 06:44:34.853888 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.97273 (* 1 = 1.97273 loss)
I0722 06:44:34.853981 23230 sgd_solver.cpp:138] Iteration 116540, lr = 1e-05
I0722 06:46:00.763743 23230 solver.cpp:243] Iteration 116550, loss = 2.58043
I0722 06:46:00.764024 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.31901 (* 1 = 1.31901 loss)
I0722 06:46:01.212714 23230 sgd_solver.cpp:138] Iteration 116550, lr = 1e-05
I0722 06:47:27.464576 23230 solver.cpp:243] Iteration 116560, loss = 2.45806
I0722 06:47:27.464872 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.70254 (* 1 = 1.70254 loss)
I0722 06:47:27.465031 23230 sgd_solver.cpp:138] Iteration 116560, lr = 1e-05
I0722 06:48:53.509526 23230 solver.cpp:243] Iteration 116570, loss = 2.58709
I0722 06:48:53.509764 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27653 (* 1 = 2.27653 loss)
I0722 06:48:53.509805 23230 sgd_solver.cpp:138] Iteration 116570, lr = 1e-05
I0722 06:50:20.148677 23230 solver.cpp:243] Iteration 116580, loss = 2.60599
I0722 06:50:20.148990 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.54839 (* 1 = 1.54839 loss)
I0722 06:50:20.149108 23230 sgd_solver.cpp:138] Iteration 116580, lr = 1e-05
I0722 06:51:46.257848 23230 solver.cpp:243] Iteration 116590, loss = 2.58934
I0722 06:51:46.258142 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.81082 (* 1 = 2.81082 loss)
I0722 06:51:47.162113 23230 sgd_solver.cpp:138] Iteration 116590, lr = 1e-05
I0722 06:53:13.879356 23230 solver.cpp:243] Iteration 116600, loss = 2.72764
I0722 06:53:13.879634 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.19886 (* 1 = 1.19886 loss)
I0722 06:53:13.879703 23230 sgd_solver.cpp:138] Iteration 116600, lr = 1e-05
I0722 06:54:37.102380 23230 solver.cpp:243] Iteration 116610, loss = 2.5762
I0722 06:54:37.102617 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.42954 (* 1 = 1.42954 loss)
I0722 06:54:37.102663 23230 sgd_solver.cpp:138] Iteration 116610, lr = 1e-05
I0722 06:56:00.146170 23230 solver.cpp:243] Iteration 116620, loss = 2.59274
I0722 06:56:00.146391 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.90282 (* 1 = 3.90282 loss)
I0722 06:56:00.146433 23230 sgd_solver.cpp:138] Iteration 116620, lr = 1e-05
I0722 06:57:23.695873 23230 solver.cpp:243] Iteration 116630, loss = 2.41552
I0722 06:57:23.696104 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.03837 (* 1 = 4.03837 loss)
I0722 06:57:23.696157 23230 sgd_solver.cpp:138] Iteration 116630, lr = 1e-05
I0722 06:58:49.733958 23230 solver.cpp:243] Iteration 116640, loss = 2.46217
I0722 06:58:49.734915 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69632 (* 1 = 2.69632 loss)
I0722 06:58:49.734968 23230 sgd_solver.cpp:138] Iteration 116640, lr = 1e-05
I0722 07:00:15.278285 23230 solver.cpp:243] Iteration 116650, loss = 2.66359
I0722 07:00:15.278606 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.9736 (* 1 = 3.9736 loss)
I0722 07:00:15.278682 23230 sgd_solver.cpp:138] Iteration 116650, lr = 1e-05
I0722 07:01:40.622221 23230 solver.cpp:243] Iteration 116660, loss = 2.69034
I0722 07:01:40.622520 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.5269 (* 1 = 2.5269 loss)
I0722 07:01:40.980424 23230 sgd_solver.cpp:138] Iteration 116660, lr = 1e-05
I0722 07:03:08.692167 23230 solver.cpp:243] Iteration 116670, loss = 2.63945
I0722 07:03:08.692613 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.70017 (* 1 = 2.70017 loss)
I0722 07:03:08.692653 23230 sgd_solver.cpp:138] Iteration 116670, lr = 1e-05
I0722 07:04:35.037310 23230 solver.cpp:243] Iteration 116680, loss = 2.48302
I0722 07:04:35.037624 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32379 (* 1 = 3.32379 loss)
I0722 07:04:35.476629 23230 sgd_solver.cpp:138] Iteration 116680, lr = 1e-05
I0722 07:05:57.396785 23230 solver.cpp:243] Iteration 116690, loss = 2.52297
I0722 07:05:57.397009 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.15054 (* 1 = 3.15054 loss)
I0722 07:05:58.233093 23230 sgd_solver.cpp:138] Iteration 116690, lr = 1e-05
I0722 07:07:22.334549 23230 solver.cpp:243] Iteration 116700, loss = 2.73846
I0722 07:07:22.334847 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82352 (* 1 = 2.82352 loss)
I0722 07:07:22.334894 23230 sgd_solver.cpp:138] Iteration 116700, lr = 1e-05
I0722 07:08:47.142159 23230 solver.cpp:243] Iteration 116710, loss = 2.6415
I0722 07:08:47.142478 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.87794 (* 1 = 1.87794 loss)
I0722 07:08:47.511668 23230 sgd_solver.cpp:138] Iteration 116710, lr = 1e-05
I0722 07:10:10.179592 23230 solver.cpp:243] Iteration 116720, loss = 2.53347
I0722 07:10:10.179827 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0378 (* 1 = 2.0378 loss)
I0722 07:10:10.179877 23230 sgd_solver.cpp:138] Iteration 116720, lr = 1e-05
I0722 07:11:36.850972 23230 solver.cpp:243] Iteration 116730, loss = 2.80604
I0722 07:11:36.851305 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.88903 (* 1 = 1.88903 loss)
I0722 07:11:36.851414 23230 sgd_solver.cpp:138] Iteration 116730, lr = 1e-05
I0722 07:13:04.208678 23230 solver.cpp:243] Iteration 116740, loss = 2.43158
I0722 07:13:04.208925 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.07263 (* 1 = 4.07263 loss)
I0722 07:13:04.208978 23230 sgd_solver.cpp:138] Iteration 116740, lr = 1e-05
I0722 07:14:31.053040 23230 solver.cpp:243] Iteration 116750, loss = 2.39186
I0722 07:14:31.053339 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 07:14:31.053452 23230 sgd_solver.cpp:138] Iteration 116750, lr = 1e-05
I0722 07:15:57.688694 23230 solver.cpp:243] Iteration 116760, loss = 2.64767
I0722 07:15:57.688982 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.07727 (* 1 = 2.07727 loss)
I0722 07:15:57.689108 23230 sgd_solver.cpp:138] Iteration 116760, lr = 1e-05
I0722 07:17:24.223299 23230 solver.cpp:243] Iteration 116770, loss = 2.64881
I0722 07:17:24.223554 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.5353 (* 1 = 2.5353 loss)
I0722 07:17:24.223597 23230 sgd_solver.cpp:138] Iteration 116770, lr = 1e-05
I0722 07:18:50.877576 23230 solver.cpp:243] Iteration 116780, loss = 2.59643
I0722 07:18:50.877821 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.62811 (* 1 = 2.62811 loss)
I0722 07:18:50.877866 23230 sgd_solver.cpp:138] Iteration 116780, lr = 1e-05
I0722 07:20:17.080669 23230 solver.cpp:243] Iteration 116790, loss = 2.27315
I0722 07:20:17.080979 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.53242 (* 1 = 2.53242 loss)
I0722 07:20:17.436123 23230 sgd_solver.cpp:138] Iteration 116790, lr = 1e-05
I0722 07:21:40.552791 23230 solver.cpp:243] Iteration 116800, loss = 2.52252
I0722 07:21:40.553107 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.67892 (* 1 = 5.67892 loss)
I0722 07:21:41.523939 23230 sgd_solver.cpp:138] Iteration 116800, lr = 1e-05
I0722 07:23:04.679076 23230 solver.cpp:243] Iteration 116810, loss = 2.4743
I0722 07:23:04.679389 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.19789 (* 1 = 2.19789 loss)
I0722 07:23:04.679509 23230 sgd_solver.cpp:138] Iteration 116810, lr = 1e-05
I0722 07:24:31.482209 23230 solver.cpp:243] Iteration 116820, loss = 2.46811
I0722 07:24:31.482455 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45901 (* 1 = 1.45901 loss)
I0722 07:24:31.482498 23230 sgd_solver.cpp:138] Iteration 116820, lr = 1e-05
I0722 07:25:59.844579 23230 solver.cpp:243] Iteration 116830, loss = 2.48818
I0722 07:25:59.844869 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32111 (* 1 = 1.32111 loss)
I0722 07:25:59.844972 23230 sgd_solver.cpp:138] Iteration 116830, lr = 1e-05
I0722 07:27:26.872109 23230 solver.cpp:243] Iteration 116840, loss = 2.63178
I0722 07:27:26.872423 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.88414 (* 1 = 1.88414 loss)
I0722 07:27:27.224082 23230 sgd_solver.cpp:138] Iteration 116840, lr = 1e-05
I0722 07:28:55.338884 23230 solver.cpp:243] Iteration 116850, loss = 2.53836
I0722 07:28:55.340415 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.19926 (* 1 = 2.19926 loss)
I0722 07:28:55.340502 23230 sgd_solver.cpp:138] Iteration 116850, lr = 1e-05
I0722 07:30:23.491071 23230 solver.cpp:243] Iteration 116860, loss = 2.47934
I0722 07:30:23.491377 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.07069 (* 1 = 2.07069 loss)
I0722 07:30:23.864073 23230 sgd_solver.cpp:138] Iteration 116860, lr = 1e-05
I0722 07:31:47.290906 23230 solver.cpp:243] Iteration 116870, loss = 2.38634
I0722 07:31:47.291204 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.39516 (* 1 = 2.39516 loss)
I0722 07:31:47.291312 23230 sgd_solver.cpp:138] Iteration 116870, lr = 1e-05
I0722 07:33:16.409004 23230 solver.cpp:243] Iteration 116880, loss = 2.75976
I0722 07:33:16.409318 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4374 (* 1 = 2.4374 loss)
I0722 07:33:16.409425 23230 sgd_solver.cpp:138] Iteration 116880, lr = 1e-05
I0722 07:34:40.157207 23230 solver.cpp:243] Iteration 116890, loss = 2.52832
I0722 07:34:40.158622 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.51144 (* 1 = 3.51144 loss)
I0722 07:34:40.939070 23230 sgd_solver.cpp:138] Iteration 116890, lr = 1e-05
I0722 07:36:07.087648 23230 solver.cpp:243] Iteration 116900, loss = 2.607
I0722 07:36:07.087893 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20147 (* 1 = 1.20147 loss)
I0722 07:36:07.087939 23230 sgd_solver.cpp:138] Iteration 116900, lr = 1e-05
I0722 07:37:32.032063 23230 solver.cpp:243] Iteration 116910, loss = 2.65657
I0722 07:37:32.032332 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.86359 (* 1 = 2.86359 loss)
I0722 07:37:32.032387 23230 sgd_solver.cpp:138] Iteration 116910, lr = 1e-05
I0722 07:38:59.051934 23230 solver.cpp:243] Iteration 116920, loss = 2.78471
I0722 07:38:59.052188 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.4667 (* 1 = 1.4667 loss)
I0722 07:38:59.052294 23230 sgd_solver.cpp:138] Iteration 116920, lr = 1e-05
I0722 07:40:24.445497 23230 solver.cpp:243] Iteration 116930, loss = 2.46349
I0722 07:40:24.445765 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.29949 (* 1 = 2.29949 loss)
I0722 07:40:24.445866 23230 sgd_solver.cpp:138] Iteration 116930, lr = 1e-05
I0722 07:41:50.708225 23230 solver.cpp:243] Iteration 116940, loss = 2.74833
I0722 07:41:50.708573 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.43159 (* 1 = 4.43159 loss)
I0722 07:41:50.708653 23230 sgd_solver.cpp:138] Iteration 116940, lr = 1e-05
I0722 07:43:15.146821 23230 solver.cpp:243] Iteration 116950, loss = 2.39367
I0722 07:43:15.147054 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.86483 (* 1 = 1.86483 loss)
I0722 07:43:15.147105 23230 sgd_solver.cpp:138] Iteration 116950, lr = 1e-05
I0722 07:44:42.309947 23230 solver.cpp:243] Iteration 116960, loss = 2.58122
I0722 07:44:42.310181 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24177 (* 1 = 2.24177 loss)
I0722 07:44:42.310226 23230 sgd_solver.cpp:138] Iteration 116960, lr = 1e-05
I0722 07:46:08.210826 23230 solver.cpp:243] Iteration 116970, loss = 2.34405
I0722 07:46:08.211118 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.71266 (* 1 = 1.71266 loss)
I0722 07:46:08.211225 23230 sgd_solver.cpp:138] Iteration 116970, lr = 1e-05
I0722 07:47:34.746577 23230 solver.cpp:243] Iteration 116980, loss = 2.58088
I0722 07:47:34.746821 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.91817 (* 1 = 2.91817 loss)
I0722 07:47:34.746894 23230 sgd_solver.cpp:138] Iteration 116980, lr = 1e-05
I0722 07:48:59.520922 23230 solver.cpp:243] Iteration 116990, loss = 2.56276
I0722 07:48:59.521198 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67762 (* 1 = 2.67762 loss)
I0722 07:48:59.521253 23230 sgd_solver.cpp:138] Iteration 116990, lr = 1e-05
I0722 07:50:16.072402 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_117000.caffemodel
I0722 07:50:16.527457 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_117000.solverstate
I0722 07:50:16.722915 23230 solver.cpp:433] Iteration 117000, Testing net (#0)
I0722 07:50:16.723168 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 07:50:20.123304 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.611856
I0722 07:50:28.576020 23230 solver.cpp:243] Iteration 117000, loss = 2.54336
I0722 07:50:28.576107 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.68882 (* 1 = 1.68882 loss)
I0722 07:50:28.576150 23230 sgd_solver.cpp:138] Iteration 117000, lr = 1e-05
I0722 07:51:54.189913 23230 solver.cpp:243] Iteration 117010, loss = 2.66787
I0722 07:51:54.190261 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.34342 (* 1 = 1.34342 loss)
I0722 07:51:54.190377 23230 sgd_solver.cpp:138] Iteration 117010, lr = 1e-05
I0722 07:53:19.051816 23230 solver.cpp:243] Iteration 117020, loss = 2.33852
I0722 07:53:19.052129 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.75981 (* 1 = 2.75981 loss)
I0722 07:53:19.052245 23230 sgd_solver.cpp:138] Iteration 117020, lr = 1e-05
I0722 07:54:45.019482 23230 solver.cpp:243] Iteration 117030, loss = 2.45119
I0722 07:54:45.019814 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67351 (* 1 = 2.67351 loss)
I0722 07:54:45.019922 23230 sgd_solver.cpp:138] Iteration 117030, lr = 1e-05
I0722 07:56:09.379927 23230 solver.cpp:243] Iteration 117040, loss = 2.61048
I0722 07:56:09.380206 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.72287 (* 1 = 3.72287 loss)
I0722 07:56:09.732213 23230 sgd_solver.cpp:138] Iteration 117040, lr = 1e-05
I0722 07:57:35.284767 23230 solver.cpp:243] Iteration 117050, loss = 2.34765
I0722 07:57:35.285110 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.84628 (* 1 = 1.84628 loss)
I0722 07:57:35.285210 23230 sgd_solver.cpp:138] Iteration 117050, lr = 1e-05
I0722 07:59:03.491945 23230 solver.cpp:243] Iteration 117060, loss = 2.51907
I0722 07:59:03.492283 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.08851 (* 1 = 2.08851 loss)
I0722 07:59:03.492357 23230 sgd_solver.cpp:138] Iteration 117060, lr = 1e-05
I0722 08:00:29.092517 23230 solver.cpp:243] Iteration 117070, loss = 2.62401
I0722 08:00:29.092769 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74605 (* 1 = 2.74605 loss)
I0722 08:00:29.092819 23230 sgd_solver.cpp:138] Iteration 117070, lr = 1e-05
I0722 08:01:54.355064 23230 solver.cpp:243] Iteration 117080, loss = 2.53315
I0722 08:01:54.355298 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31124 (* 1 = 2.31124 loss)
I0722 08:01:54.355343 23230 sgd_solver.cpp:138] Iteration 117080, lr = 1e-05
I0722 08:03:21.619766 23230 solver.cpp:243] Iteration 117090, loss = 2.69779
I0722 08:03:21.620390 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.95412 (* 1 = 2.95412 loss)
I0722 08:03:21.620496 23230 sgd_solver.cpp:138] Iteration 117090, lr = 1e-05
I0722 08:04:45.279794 23230 solver.cpp:243] Iteration 117100, loss = 2.69599
I0722 08:04:45.280100 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.955386 (* 1 = 0.955386 loss)
I0722 08:04:45.280221 23230 sgd_solver.cpp:138] Iteration 117100, lr = 1e-05
I0722 08:06:08.761271 23230 solver.cpp:243] Iteration 117110, loss = 2.46986
I0722 08:06:08.761536 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.03946 (* 1 = 3.03946 loss)
I0722 08:06:09.170157 23230 sgd_solver.cpp:138] Iteration 117110, lr = 1e-05
I0722 08:07:32.997217 23230 solver.cpp:243] Iteration 117120, loss = 2.64858
I0722 08:07:32.997439 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.842555 (* 1 = 0.842555 loss)
I0722 08:07:33.372354 23230 sgd_solver.cpp:138] Iteration 117120, lr = 1e-05
I0722 08:08:59.166486 23230 solver.cpp:243] Iteration 117130, loss = 2.55461
I0722 08:08:59.166694 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45097 (* 1 = 1.45097 loss)
I0722 08:08:59.166754 23230 sgd_solver.cpp:138] Iteration 117130, lr = 1e-05
I0722 08:10:27.195372 23230 solver.cpp:243] Iteration 117140, loss = 2.6146
I0722 08:10:27.195724 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35686 (* 1 = 2.35686 loss)
I0722 08:10:27.195824 23230 sgd_solver.cpp:138] Iteration 117140, lr = 1e-05
I0722 08:11:54.693570 23230 solver.cpp:243] Iteration 117150, loss = 2.40509
I0722 08:11:54.693940 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.00144 (* 1 = 2.00144 loss)
I0722 08:11:54.694137 23230 sgd_solver.cpp:138] Iteration 117150, lr = 1e-05
I0722 08:13:22.473726 23230 solver.cpp:243] Iteration 117160, loss = 2.48593
I0722 08:13:22.474030 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.34038 (* 1 = 2.34038 loss)
I0722 08:13:22.474212 23230 sgd_solver.cpp:138] Iteration 117160, lr = 1e-05
I0722 08:14:45.510105 23230 solver.cpp:243] Iteration 117170, loss = 2.62671
I0722 08:14:45.510363 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.80229 (* 1 = 4.80229 loss)
I0722 08:14:45.510413 23230 sgd_solver.cpp:138] Iteration 117170, lr = 1e-05
I0722 08:16:12.265231 23230 solver.cpp:243] Iteration 117180, loss = 2.36381
I0722 08:16:12.265470 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.66818 (* 1 = 3.66818 loss)
I0722 08:16:12.265514 23230 sgd_solver.cpp:138] Iteration 117180, lr = 1e-05
I0722 08:17:38.100383 23230 solver.cpp:243] Iteration 117190, loss = 2.31936
I0722 08:17:38.100736 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.45487 (* 1 = 3.45487 loss)
I0722 08:17:38.467407 23230 sgd_solver.cpp:138] Iteration 117190, lr = 1e-05
I0722 08:19:05.570577 23230 solver.cpp:243] Iteration 117200, loss = 2.50317
I0722 08:19:05.570827 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.59059 (* 1 = 6.59059 loss)
I0722 08:19:05.570883 23230 sgd_solver.cpp:138] Iteration 117200, lr = 1e-05
I0722 08:20:34.458745 23230 solver.cpp:243] Iteration 117210, loss = 3.05315
I0722 08:20:34.459003 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.79437 (* 1 = 1.79437 loss)
I0722 08:20:34.459049 23230 sgd_solver.cpp:138] Iteration 117210, lr = 1e-05
I0722 08:22:00.818328 23230 solver.cpp:243] Iteration 117220, loss = 2.52271
I0722 08:22:00.818555 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85949 (* 1 = 1.85949 loss)
I0722 08:22:00.818605 23230 sgd_solver.cpp:138] Iteration 117220, lr = 1e-05
I0722 08:23:27.304253 23230 solver.cpp:243] Iteration 117230, loss = 2.58341
I0722 08:23:27.304592 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.48475 (* 1 = 1.48475 loss)
I0722 08:23:27.304698 23230 sgd_solver.cpp:138] Iteration 117230, lr = 1e-05
I0722 08:24:54.330772 23230 solver.cpp:243] Iteration 117240, loss = 2.76687
I0722 08:24:54.331069 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.66522 (* 1 = 3.66522 loss)
I0722 08:24:55.801199 23230 sgd_solver.cpp:138] Iteration 117240, lr = 1e-05
I0722 08:26:22.965562 23230 solver.cpp:243] Iteration 117250, loss = 2.83154
I0722 08:26:22.965804 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.6901 (* 1 = 2.6901 loss)
I0722 08:26:22.965850 23230 sgd_solver.cpp:138] Iteration 117250, lr = 1e-05
I0722 08:27:50.556867 23230 solver.cpp:243] Iteration 117260, loss = 2.59505
I0722 08:27:50.557122 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.29531 (* 1 = 5.29531 loss)
I0722 08:27:50.557180 23230 sgd_solver.cpp:138] Iteration 117260, lr = 1e-05
I0722 08:29:18.152637 23230 solver.cpp:243] Iteration 117270, loss = 2.55133
I0722 08:29:18.152874 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.74385 (* 1 = 1.74385 loss)
I0722 08:29:18.152922 23230 sgd_solver.cpp:138] Iteration 117270, lr = 1e-05
I0722 08:30:41.401654 23230 solver.cpp:243] Iteration 117280, loss = 2.58952
I0722 08:30:41.401973 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.16142 (* 1 = 1.16142 loss)
I0722 08:30:41.769048 23230 sgd_solver.cpp:138] Iteration 117280, lr = 1e-05
I0722 08:32:08.769564 23230 solver.cpp:243] Iteration 117290, loss = 2.56135
I0722 08:32:08.769810 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57904 (* 1 = 2.57904 loss)
I0722 08:32:08.769858 23230 sgd_solver.cpp:138] Iteration 117290, lr = 1e-05
I0722 08:33:33.393204 23230 solver.cpp:243] Iteration 117300, loss = 2.51747
I0722 08:33:33.393514 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.02496 (* 1 = 1.02496 loss)
I0722 08:33:33.393622 23230 sgd_solver.cpp:138] Iteration 117300, lr = 1e-05
I0722 08:34:57.542515 23230 solver.cpp:243] Iteration 117310, loss = 2.67754
I0722 08:34:57.542768 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.16878 (* 1 = 4.16878 loss)
I0722 08:34:57.542821 23230 sgd_solver.cpp:138] Iteration 117310, lr = 1e-05
I0722 08:36:24.983731 23230 solver.cpp:243] Iteration 117320, loss = 2.50912
I0722 08:36:24.984014 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32886 (* 1 = 3.32886 loss)
I0722 08:36:24.984122 23230 sgd_solver.cpp:138] Iteration 117320, lr = 1e-05
I0722 08:37:50.966392 23230 solver.cpp:243] Iteration 117330, loss = 2.55982
I0722 08:37:50.966668 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.54728 (* 1 = 2.54728 loss)
I0722 08:37:50.966789 23230 sgd_solver.cpp:138] Iteration 117330, lr = 1e-05
I0722 08:39:16.090884 23230 solver.cpp:243] Iteration 117340, loss = 2.57661
I0722 08:39:16.091151 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.18826 (* 1 = 2.18826 loss)
I0722 08:39:16.091269 23230 sgd_solver.cpp:138] Iteration 117340, lr = 1e-05
I0722 08:40:40.845918 23230 solver.cpp:243] Iteration 117350, loss = 2.7639
I0722 08:40:40.846202 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.10578 (* 1 = 3.10578 loss)
I0722 08:40:41.663378 23230 sgd_solver.cpp:138] Iteration 117350, lr = 1e-05
I0722 08:42:06.275647 23230 solver.cpp:243] Iteration 117360, loss = 2.61665
I0722 08:42:06.275929 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.16629 (* 1 = 2.16629 loss)
I0722 08:42:06.276031 23230 sgd_solver.cpp:138] Iteration 117360, lr = 1e-05
I0722 08:43:32.069833 23230 solver.cpp:243] Iteration 117370, loss = 2.56829
I0722 08:43:32.070122 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.96163 (* 1 = 1.96163 loss)
I0722 08:43:32.070185 23230 sgd_solver.cpp:138] Iteration 117370, lr = 1e-05
I0722 08:45:00.507473 23230 solver.cpp:243] Iteration 117380, loss = 2.4754
I0722 08:45:00.507802 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37702 (* 1 = 3.37702 loss)
I0722 08:45:00.507925 23230 sgd_solver.cpp:138] Iteration 117380, lr = 1e-05
I0722 08:46:28.911099 23230 solver.cpp:243] Iteration 117390, loss = 2.64612
I0722 08:46:28.911402 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.99869 (* 1 = 2.99869 loss)
I0722 08:46:28.911499 23230 sgd_solver.cpp:138] Iteration 117390, lr = 1e-05
I0722 08:47:57.140758 23230 solver.cpp:243] Iteration 117400, loss = 2.66469
I0722 08:47:57.141067 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.79777 (* 1 = 2.79777 loss)
I0722 08:47:57.909683 23230 sgd_solver.cpp:138] Iteration 117400, lr = 1e-05
I0722 08:49:24.069764 23230 solver.cpp:243] Iteration 117410, loss = 2.50223
I0722 08:49:24.070039 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.87494 (* 1 = 1.87494 loss)
I0722 08:49:24.070117 23230 sgd_solver.cpp:138] Iteration 117410, lr = 1e-05
I0722 08:50:50.631160 23230 solver.cpp:243] Iteration 117420, loss = 2.52728
I0722 08:50:50.631459 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.70218 (* 1 = 2.70218 loss)
I0722 08:50:50.631568 23230 sgd_solver.cpp:138] Iteration 117420, lr = 1e-05
I0722 08:52:16.893836 23230 solver.cpp:243] Iteration 117430, loss = 2.42658
I0722 08:52:16.894058 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.54652 (* 1 = 2.54652 loss)
I0722 08:52:17.639742 23230 sgd_solver.cpp:138] Iteration 117430, lr = 1e-05
I0722 08:53:41.353502 23230 solver.cpp:243] Iteration 117440, loss = 2.51433
I0722 08:53:41.353747 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45423 (* 1 = 1.45423 loss)
I0722 08:53:41.715823 23230 sgd_solver.cpp:138] Iteration 117440, lr = 1e-05
I0722 08:55:03.937646 23230 solver.cpp:243] Iteration 117450, loss = 2.50167
I0722 08:55:03.938007 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.64186 (* 1 = 4.64186 loss)
I0722 08:55:04.297374 23230 sgd_solver.cpp:138] Iteration 117450, lr = 1e-05
I0722 08:56:27.000579 23230 solver.cpp:243] Iteration 117460, loss = 2.5091
I0722 08:56:27.000840 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.23029 (* 1 = 3.23029 loss)
I0722 08:56:27.770429 23230 sgd_solver.cpp:138] Iteration 117460, lr = 1e-05
I0722 08:57:54.472190 23230 solver.cpp:243] Iteration 117470, loss = 2.38163
I0722 08:57:54.472447 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.70022 (* 1 = 4.70022 loss)
I0722 08:57:54.472486 23230 sgd_solver.cpp:138] Iteration 117470, lr = 1e-05
I0722 08:59:22.594240 23230 solver.cpp:243] Iteration 117480, loss = 2.41502
I0722 08:59:22.594485 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.72347 (* 1 = 4.72347 loss)
I0722 08:59:22.594532 23230 sgd_solver.cpp:138] Iteration 117480, lr = 1e-05
I0722 09:00:46.466780 23230 solver.cpp:243] Iteration 117490, loss = 2.5697
I0722 09:00:46.467028 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.56607 (* 1 = 2.56607 loss)
I0722 09:00:46.467101 23230 sgd_solver.cpp:138] Iteration 117490, lr = 1e-05
I0722 09:02:13.397373 23230 solver.cpp:243] Iteration 117500, loss = 2.56778
I0722 09:02:13.397688 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.70627 (* 1 = 2.70627 loss)
I0722 09:02:13.397786 23230 sgd_solver.cpp:138] Iteration 117500, lr = 1e-05
I0722 09:03:39.275827 23230 solver.cpp:243] Iteration 117510, loss = 2.44888
I0722 09:03:39.276075 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.70676 (* 1 = 2.70676 loss)
I0722 09:03:39.276130 23230 sgd_solver.cpp:138] Iteration 117510, lr = 1e-05
I0722 09:05:05.843509 23230 solver.cpp:243] Iteration 117520, loss = 2.57386
I0722 09:05:05.843739 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96197 (* 1 = 2.96197 loss)
I0722 09:05:05.843786 23230 sgd_solver.cpp:138] Iteration 117520, lr = 1e-05
I0722 09:06:33.400046 23230 solver.cpp:243] Iteration 117530, loss = 2.53671
I0722 09:06:33.400283 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.1509 (* 1 = 1.1509 loss)
I0722 09:06:33.400327 23230 sgd_solver.cpp:138] Iteration 117530, lr = 1e-05
I0722 09:07:59.279144 23230 solver.cpp:243] Iteration 117540, loss = 2.54326
I0722 09:07:59.279433 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.80471 (* 1 = 3.80471 loss)
I0722 09:07:59.279475 23230 sgd_solver.cpp:138] Iteration 117540, lr = 1e-05
I0722 09:09:28.300441 23230 solver.cpp:243] Iteration 117550, loss = 2.38784
I0722 09:09:28.300729 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37878 (* 1 = 3.37878 loss)
I0722 09:09:28.300832 23230 sgd_solver.cpp:138] Iteration 117550, lr = 1e-05
I0722 09:10:56.285568 23230 solver.cpp:243] Iteration 117560, loss = 2.50629
I0722 09:10:56.285878 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37731 (* 1 = 2.37731 loss)
I0722 09:10:57.628034 23230 sgd_solver.cpp:138] Iteration 117560, lr = 1e-05
I0722 09:12:27.946420 23230 solver.cpp:243] Iteration 117570, loss = 2.70471
I0722 09:12:27.946624 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80618 (* 1 = 2.80618 loss)
I0722 09:12:27.946673 23230 sgd_solver.cpp:138] Iteration 117570, lr = 1e-05
I0722 09:13:53.679157 23230 solver.cpp:243] Iteration 117580, loss = 2.6146
I0722 09:13:53.679412 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80081 (* 1 = 1.80081 loss)
I0722 09:13:53.679460 23230 sgd_solver.cpp:138] Iteration 117580, lr = 1e-05
I0722 09:15:20.591225 23230 solver.cpp:243] Iteration 117590, loss = 2.50732
I0722 09:15:20.591450 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.95146 (* 1 = 3.95146 loss)
I0722 09:15:20.591501 23230 sgd_solver.cpp:138] Iteration 117590, lr = 1e-05
I0722 09:16:47.239454 23230 solver.cpp:243] Iteration 117600, loss = 2.54916
I0722 09:16:47.239688 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.72936 (* 1 = 1.72936 loss)
I0722 09:16:47.602692 23230 sgd_solver.cpp:138] Iteration 117600, lr = 1e-05
I0722 09:18:14.716141 23230 solver.cpp:243] Iteration 117610, loss = 2.45782
I0722 09:18:14.716506 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.34664 (* 1 = 3.34664 loss)
I0722 09:18:14.716619 23230 sgd_solver.cpp:138] Iteration 117610, lr = 1e-05
I0722 09:19:44.745249 23230 solver.cpp:243] Iteration 117620, loss = 2.42003
I0722 09:19:44.745522 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.11132 (* 1 = 2.11132 loss)
I0722 09:19:44.745597 23230 sgd_solver.cpp:138] Iteration 117620, lr = 1e-05
I0722 09:21:13.327342 23230 solver.cpp:243] Iteration 117630, loss = 2.53781
I0722 09:21:13.327592 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4262 (* 1 = 2.4262 loss)
I0722 09:21:13.327661 23230 sgd_solver.cpp:138] Iteration 117630, lr = 1e-05
I0722 09:22:37.352072 23230 solver.cpp:243] Iteration 117640, loss = 2.48086
I0722 09:22:37.352321 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.9722 (* 1 = 2.9722 loss)
I0722 09:22:37.352373 23230 sgd_solver.cpp:138] Iteration 117640, lr = 1e-05
I0722 09:24:06.377293 23230 solver.cpp:243] Iteration 117650, loss = 2.79381
I0722 09:24:06.377563 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24673 (* 1 = 2.24673 loss)
I0722 09:24:06.377666 23230 sgd_solver.cpp:138] Iteration 117650, lr = 1e-05
I0722 09:25:31.883260 23230 solver.cpp:243] Iteration 117660, loss = 2.60024
I0722 09:25:31.883464 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.61311 (* 1 = 3.61311 loss)
I0722 09:25:31.883510 23230 sgd_solver.cpp:138] Iteration 117660, lr = 1e-05
I0722 09:26:56.564088 23230 solver.cpp:243] Iteration 117670, loss = 2.44681
I0722 09:26:56.564333 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.77133 (* 1 = 1.77133 loss)
I0722 09:26:56.946637 23230 sgd_solver.cpp:138] Iteration 117670, lr = 1e-05
I0722 09:28:22.713455 23230 solver.cpp:243] Iteration 117680, loss = 2.70532
I0722 09:28:22.713721 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32876 (* 1 = 1.32876 loss)
I0722 09:28:22.713845 23230 sgd_solver.cpp:138] Iteration 117680, lr = 1e-05
I0722 09:29:50.636555 23230 solver.cpp:243] Iteration 117690, loss = 2.46668
I0722 09:29:50.636796 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.88306 (* 1 = 1.88306 loss)
I0722 09:29:50.636852 23230 sgd_solver.cpp:138] Iteration 117690, lr = 1e-05
I0722 09:31:14.323089 23230 solver.cpp:243] Iteration 117700, loss = 2.45274
I0722 09:31:14.323326 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8008 (* 1 = 2.8008 loss)
I0722 09:31:14.323372 23230 sgd_solver.cpp:138] Iteration 117700, lr = 1e-05
I0722 09:32:40.601544 23230 solver.cpp:243] Iteration 117710, loss = 2.59642
I0722 09:32:40.601817 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03582 (* 1 = 2.03582 loss)
I0722 09:32:40.601861 23230 sgd_solver.cpp:138] Iteration 117710, lr = 1e-05
I0722 09:34:07.192621 23230 solver.cpp:243] Iteration 117720, loss = 2.30152
I0722 09:34:07.192868 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.3966 (* 1 = 3.3966 loss)
I0722 09:34:07.192908 23230 sgd_solver.cpp:138] Iteration 117720, lr = 1e-05
I0722 09:35:31.780349 23230 solver.cpp:243] Iteration 117730, loss = 2.40186
I0722 09:35:31.781281 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4727 (* 1 = 2.4727 loss)
I0722 09:35:31.781327 23230 sgd_solver.cpp:138] Iteration 117730, lr = 1e-05
I0722 09:36:57.911356 23230 solver.cpp:243] Iteration 117740, loss = 2.57348
I0722 09:36:57.912400 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37001 (* 1 = 3.37001 loss)
I0722 09:36:57.912492 23230 sgd_solver.cpp:138] Iteration 117740, lr = 1e-05
I0722 09:38:20.489588 23230 solver.cpp:243] Iteration 117750, loss = 2.63474
I0722 09:38:20.489806 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.63012 (* 1 = 3.63012 loss)
I0722 09:38:20.489863 23230 sgd_solver.cpp:138] Iteration 117750, lr = 1e-05
I0722 09:39:48.155859 23230 solver.cpp:243] Iteration 117760, loss = 2.52212
I0722 09:39:48.156131 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.72358 (* 1 = 1.72358 loss)
I0722 09:39:48.156186 23230 sgd_solver.cpp:138] Iteration 117760, lr = 1e-05
I0722 09:41:13.763862 23230 solver.cpp:243] Iteration 117770, loss = 2.49093
I0722 09:41:13.764097 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3441 (* 1 = 2.3441 loss)
I0722 09:41:13.764145 23230 sgd_solver.cpp:138] Iteration 117770, lr = 1e-05
I0722 09:42:37.416985 23230 solver.cpp:243] Iteration 117780, loss = 2.70306
I0722 09:42:37.417186 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.02638 (* 1 = 1.02638 loss)
I0722 09:42:37.417227 23230 sgd_solver.cpp:138] Iteration 117780, lr = 1e-05
I0722 09:44:01.754096 23230 solver.cpp:243] Iteration 117790, loss = 2.52381
I0722 09:44:01.754328 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46626 (* 1 = 1.46626 loss)
I0722 09:44:01.754371 23230 sgd_solver.cpp:138] Iteration 117790, lr = 1e-05
I0722 09:45:29.793812 23230 solver.cpp:243] Iteration 117800, loss = 2.69974
I0722 09:45:29.794075 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.18928 (* 1 = 3.18928 loss)
I0722 09:45:29.794137 23230 sgd_solver.cpp:138] Iteration 117800, lr = 1e-05
I0722 09:46:56.593420 23230 solver.cpp:243] Iteration 117810, loss = 2.78185
I0722 09:46:56.595686 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0847 (* 1 = 2.0847 loss)
I0722 09:46:56.996315 23230 sgd_solver.cpp:138] Iteration 117810, lr = 1e-05
I0722 09:48:23.779868 23230 solver.cpp:243] Iteration 117820, loss = 2.7744
I0722 09:48:23.780176 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73907 (* 1 = 2.73907 loss)
I0722 09:48:24.757843 23230 sgd_solver.cpp:138] Iteration 117820, lr = 1e-05
I0722 09:49:50.669044 23230 solver.cpp:243] Iteration 117830, loss = 2.7107
I0722 09:49:50.669390 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.14177 (* 1 = 5.14177 loss)
I0722 09:49:51.018868 23230 sgd_solver.cpp:138] Iteration 117830, lr = 1e-05
I0722 09:51:15.484508 23230 solver.cpp:243] Iteration 117840, loss = 2.5006
I0722 09:51:15.484750 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10405 (* 1 = 2.10405 loss)
I0722 09:51:15.484798 23230 sgd_solver.cpp:138] Iteration 117840, lr = 1e-05
I0722 09:52:41.032850 23230 solver.cpp:243] Iteration 117850, loss = 2.48974
I0722 09:52:41.033112 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46781 (* 1 = 1.46781 loss)
I0722 09:52:41.389976 23230 sgd_solver.cpp:138] Iteration 117850, lr = 1e-05
I0722 09:54:05.611892 23230 solver.cpp:243] Iteration 117860, loss = 2.60811
I0722 09:54:05.612123 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.09756 (* 1 = 1.09756 loss)
I0722 09:54:05.612165 23230 sgd_solver.cpp:138] Iteration 117860, lr = 1e-05
I0722 09:55:34.816851 23230 solver.cpp:243] Iteration 117870, loss = 2.57292
I0722 09:55:34.817148 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.52481 (* 1 = 3.52481 loss)
I0722 09:55:34.817220 23230 sgd_solver.cpp:138] Iteration 117870, lr = 1e-05
I0722 09:57:01.640720 23230 solver.cpp:243] Iteration 117880, loss = 2.38532
I0722 09:57:01.640954 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.153 (* 1 = 2.153 loss)
I0722 09:57:01.993089 23230 sgd_solver.cpp:138] Iteration 117880, lr = 1e-05
I0722 09:58:30.085242 23230 solver.cpp:243] Iteration 117890, loss = 2.60291
I0722 09:58:30.085476 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.23836 (* 1 = 1.23836 loss)
I0722 09:58:30.085520 23230 sgd_solver.cpp:138] Iteration 117890, lr = 1e-05
I0722 09:59:57.986245 23230 solver.cpp:243] Iteration 117900, loss = 2.47052
I0722 09:59:57.986515 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.07479 (* 1 = 3.07479 loss)
I0722 09:59:57.986583 23230 sgd_solver.cpp:138] Iteration 117900, lr = 1e-05
I0722 10:01:26.512316 23230 solver.cpp:243] Iteration 117910, loss = 2.56402
I0722 10:01:26.512538 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.48391 (* 1 = 1.48391 loss)
I0722 10:01:26.898456 23230 sgd_solver.cpp:138] Iteration 117910, lr = 1e-05
I0722 10:02:50.885445 23230 solver.cpp:243] Iteration 117920, loss = 2.50834
I0722 10:02:50.885730 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.07808 (* 1 = 2.07808 loss)
I0722 10:02:51.251143 23230 sgd_solver.cpp:138] Iteration 117920, lr = 1e-05
I0722 10:04:16.012426 23230 solver.cpp:243] Iteration 117930, loss = 2.36121
I0722 10:04:16.012687 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25291 (* 1 = 1.25291 loss)
I0722 10:04:16.012732 23230 sgd_solver.cpp:138] Iteration 117930, lr = 1e-05
I0722 10:05:41.354684 23230 solver.cpp:243] Iteration 117940, loss = 2.42797
I0722 10:05:41.355610 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.76965 (* 1 = 2.76965 loss)
I0722 10:05:41.355698 23230 sgd_solver.cpp:138] Iteration 117940, lr = 1e-05
I0722 10:07:07.192508 23230 solver.cpp:243] Iteration 117950, loss = 2.4808
I0722 10:07:07.192811 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35059 (* 1 = 2.35059 loss)
I0722 10:07:07.192890 23230 sgd_solver.cpp:138] Iteration 117950, lr = 1e-05
I0722 10:08:30.641363 23230 solver.cpp:243] Iteration 117960, loss = 2.50234
I0722 10:08:30.641618 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.63714 (* 1 = 1.63714 loss)
I0722 10:08:30.641664 23230 sgd_solver.cpp:138] Iteration 117960, lr = 1e-05
I0722 10:09:55.829320 23230 solver.cpp:243] Iteration 117970, loss = 2.32271
I0722 10:09:55.829530 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.09203 (* 1 = 2.09203 loss)
I0722 10:09:55.829572 23230 sgd_solver.cpp:138] Iteration 117970, lr = 1e-05
I0722 10:11:19.581414 23230 solver.cpp:243] Iteration 117980, loss = 2.57387
I0722 10:11:19.581646 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.53385 (* 1 = 1.53385 loss)
I0722 10:11:19.581691 23230 sgd_solver.cpp:138] Iteration 117980, lr = 1e-05
I0722 10:12:48.464279 23230 solver.cpp:243] Iteration 117990, loss = 2.58866
I0722 10:12:48.464592 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50258 (* 1 = 2.50258 loss)
I0722 10:12:48.464673 23230 sgd_solver.cpp:138] Iteration 117990, lr = 1e-05
I0722 10:14:06.257896 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_118000.caffemodel
I0722 10:14:07.034190 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_118000.solverstate
I0722 10:14:07.210868 23230 solver.cpp:433] Iteration 118000, Testing net (#0)
I0722 10:14:07.211259 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 10:14:10.568483 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.616273
I0722 10:14:19.493232 23230 solver.cpp:243] Iteration 118000, loss = 2.70507
I0722 10:14:19.493311 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.20201 (* 1 = 4.20201 loss)
I0722 10:14:19.493356 23230 sgd_solver.cpp:138] Iteration 118000, lr = 1e-05
I0722 10:15:42.562786 23230 solver.cpp:243] Iteration 118010, loss = 2.41207
I0722 10:15:42.563073 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.53451 (* 1 = 3.53451 loss)
I0722 10:15:43.291287 23230 sgd_solver.cpp:138] Iteration 118010, lr = 1e-05
I0722 10:17:10.741789 23230 solver.cpp:243] Iteration 118020, loss = 2.56472
I0722 10:17:10.742473 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.15194 (* 1 = 1.15194 loss)
I0722 10:17:10.742533 23230 sgd_solver.cpp:138] Iteration 118020, lr = 1e-05
I0722 10:18:36.215076 23230 solver.cpp:243] Iteration 118030, loss = 2.43956
I0722 10:18:36.218220 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.41197 (* 1 = 2.41197 loss)
I0722 10:18:37.628381 23230 sgd_solver.cpp:138] Iteration 118030, lr = 1e-05
I0722 10:20:02.809041 23230 solver.cpp:243] Iteration 118040, loss = 2.58372
I0722 10:20:02.809412 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.94839 (* 1 = 3.94839 loss)
I0722 10:20:03.185675 23230 sgd_solver.cpp:138] Iteration 118040, lr = 1e-05
I0722 10:21:26.402843 23230 solver.cpp:243] Iteration 118050, loss = 2.42669
I0722 10:21:26.403208 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2823 (* 1 = 2.2823 loss)
I0722 10:21:26.403303 23230 sgd_solver.cpp:138] Iteration 118050, lr = 1e-05
I0722 10:22:51.927793 23230 solver.cpp:243] Iteration 118060, loss = 2.71841
I0722 10:22:51.928129 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.53022 (* 1 = 2.53022 loss)
I0722 10:22:52.285214 23230 sgd_solver.cpp:138] Iteration 118060, lr = 1e-05
I0722 10:24:14.370375 23230 solver.cpp:243] Iteration 118070, loss = 2.63742
I0722 10:24:14.370679 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.56043 (* 1 = 2.56043 loss)
I0722 10:24:14.370797 23230 sgd_solver.cpp:138] Iteration 118070, lr = 1e-05
I0722 10:25:37.487413 23230 solver.cpp:243] Iteration 118080, loss = 2.80694
I0722 10:25:37.487649 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.95823 (* 1 = 2.95823 loss)
I0722 10:25:37.487700 23230 sgd_solver.cpp:138] Iteration 118080, lr = 1e-05
I0722 10:27:02.213068 23230 solver.cpp:243] Iteration 118090, loss = 2.56624
I0722 10:27:02.213321 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.36191 (* 1 = 3.36191 loss)
I0722 10:27:02.213371 23230 sgd_solver.cpp:138] Iteration 118090, lr = 1e-05
I0722 10:28:29.230741 23230 solver.cpp:243] Iteration 118100, loss = 2.58084
I0722 10:28:29.230986 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80749 (* 1 = 2.80749 loss)
I0722 10:28:29.231027 23230 sgd_solver.cpp:138] Iteration 118100, lr = 1e-05
I0722 10:29:59.089390 23230 solver.cpp:243] Iteration 118110, loss = 2.4222
I0722 10:29:59.089679 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.9888 (* 1 = 3.9888 loss)
I0722 10:29:59.089725 23230 sgd_solver.cpp:138] Iteration 118110, lr = 1e-05
I0722 10:31:28.798384 23230 solver.cpp:243] Iteration 118120, loss = 2.69914
I0722 10:31:28.798698 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40447 (* 1 = 2.40447 loss)
I0722 10:31:29.157570 23230 sgd_solver.cpp:138] Iteration 118120, lr = 1e-05
I0722 10:32:54.428231 23230 solver.cpp:243] Iteration 118130, loss = 2.50831
I0722 10:32:54.428586 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.63303 (* 1 = 2.63303 loss)
I0722 10:32:55.210728 23230 sgd_solver.cpp:138] Iteration 118130, lr = 1e-05
I0722 10:34:19.848145 23230 solver.cpp:243] Iteration 118140, loss = 2.47569
I0722 10:34:19.848482 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.30072 (* 1 = 1.30072 loss)
I0722 10:34:19.848598 23230 sgd_solver.cpp:138] Iteration 118140, lr = 1e-05
I0722 10:35:45.410356 23230 solver.cpp:243] Iteration 118150, loss = 2.73738
I0722 10:35:45.410688 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.40769 (* 1 = 3.40769 loss)
I0722 10:35:45.410789 23230 sgd_solver.cpp:138] Iteration 118150, lr = 1e-05
I0722 10:37:11.830170 23230 solver.cpp:243] Iteration 118160, loss = 2.50434
I0722 10:37:11.830438 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.00203 (* 1 = 1.00203 loss)
I0722 10:37:12.594652 23230 sgd_solver.cpp:138] Iteration 118160, lr = 1e-05
I0722 10:38:39.562993 23230 solver.cpp:243] Iteration 118170, loss = 2.59186
I0722 10:38:39.563321 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24985 (* 1 = 2.24985 loss)
I0722 10:38:39.563434 23230 sgd_solver.cpp:138] Iteration 118170, lr = 1e-05
I0722 10:40:07.105342 23230 solver.cpp:243] Iteration 118180, loss = 2.72878
I0722 10:40:07.105608 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37129 (* 1 = 3.37129 loss)
I0722 10:40:07.874938 23230 sgd_solver.cpp:138] Iteration 118180, lr = 1e-05
I0722 10:41:34.242208 23230 solver.cpp:243] Iteration 118190, loss = 2.52469
I0722 10:41:34.243050 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.15148 (* 1 = 1.15148 loss)
I0722 10:41:34.243120 23230 sgd_solver.cpp:138] Iteration 118190, lr = 1e-05
I0722 10:43:02.126570 23230 solver.cpp:243] Iteration 118200, loss = 2.3707
I0722 10:43:02.126870 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.79298 (* 1 = 2.79298 loss)
I0722 10:43:02.699363 23230 sgd_solver.cpp:138] Iteration 118200, lr = 1e-05
I0722 10:44:28.549001 23230 solver.cpp:243] Iteration 118210, loss = 2.45941
I0722 10:44:28.549418 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.51561 (* 1 = 1.51561 loss)
I0722 10:44:29.779306 23230 sgd_solver.cpp:138] Iteration 118210, lr = 1e-05
I0722 10:45:55.215872 23230 solver.cpp:243] Iteration 118220, loss = 2.51771
I0722 10:45:55.216161 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.98078 (* 1 = 1.98078 loss)
I0722 10:45:55.576653 23230 sgd_solver.cpp:138] Iteration 118220, lr = 1e-05
I0722 10:47:22.757042 23230 solver.cpp:243] Iteration 118230, loss = 2.8094
I0722 10:47:22.757335 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76891 (* 1 = 3.76891 loss)
I0722 10:47:22.757436 23230 sgd_solver.cpp:138] Iteration 118230, lr = 1e-05
I0722 10:48:51.129186 23230 solver.cpp:243] Iteration 118240, loss = 2.43511
I0722 10:48:51.130421 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.72479 (* 1 = 1.72479 loss)
I0722 10:48:51.130486 23230 sgd_solver.cpp:138] Iteration 118240, lr = 1e-05
I0722 10:50:15.968811 23230 solver.cpp:243] Iteration 118250, loss = 2.39673
I0722 10:50:15.969030 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.30108 (* 1 = 3.30108 loss)
I0722 10:50:16.346907 23230 sgd_solver.cpp:138] Iteration 118250, lr = 1e-05
I0722 10:51:39.949620 23230 solver.cpp:243] Iteration 118260, loss = 2.41964
I0722 10:51:39.949899 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83832 (* 1 = 1.83832 loss)
I0722 10:51:39.950016 23230 sgd_solver.cpp:138] Iteration 118260, lr = 1e-05
I0722 10:53:04.679430 23230 solver.cpp:243] Iteration 118270, loss = 2.57389
I0722 10:53:04.679702 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25363 (* 1 = 1.25363 loss)
I0722 10:53:04.679821 23230 sgd_solver.cpp:138] Iteration 118270, lr = 1e-05
I0722 10:54:30.254715 23230 solver.cpp:243] Iteration 118280, loss = 2.61149
I0722 10:54:30.254958 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.29565 (* 1 = 4.29565 loss)
I0722 10:54:30.255007 23230 sgd_solver.cpp:138] Iteration 118280, lr = 1e-05
I0722 10:55:54.077654 23230 solver.cpp:243] Iteration 118290, loss = 2.66901
I0722 10:55:54.077977 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.40772 (* 1 = 1.40772 loss)
I0722 10:55:54.078104 23230 sgd_solver.cpp:138] Iteration 118290, lr = 1e-05
I0722 10:57:21.643508 23230 solver.cpp:243] Iteration 118300, loss = 2.30223
I0722 10:57:21.643793 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.1727 (* 1 = 2.1727 loss)
I0722 10:57:22.463639 23230 sgd_solver.cpp:138] Iteration 118300, lr = 1e-05
I0722 10:58:49.530503 23230 solver.cpp:243] Iteration 118310, loss = 2.57807
I0722 10:58:49.530797 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67922 (* 1 = 2.67922 loss)
I0722 10:58:49.530881 23230 sgd_solver.cpp:138] Iteration 118310, lr = 1e-05
I0722 11:00:15.253015 23230 solver.cpp:243] Iteration 118320, loss = 2.41222
I0722 11:00:15.253252 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.58698 (* 1 = 2.58698 loss)
I0722 11:00:15.253296 23230 sgd_solver.cpp:138] Iteration 118320, lr = 1e-05
I0722 11:01:43.163389 23230 solver.cpp:243] Iteration 118330, loss = 2.53934
I0722 11:01:43.163671 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60865 (* 1 = 2.60865 loss)
I0722 11:01:43.163743 23230 sgd_solver.cpp:138] Iteration 118330, lr = 1e-05
I0722 11:03:11.167492 23230 solver.cpp:243] Iteration 118340, loss = 2.60927
I0722 11:03:11.167826 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82741 (* 1 = 2.82741 loss)
I0722 11:03:11.846899 23230 sgd_solver.cpp:138] Iteration 118340, lr = 1e-05
I0722 11:04:38.731626 23230 solver.cpp:243] Iteration 118350, loss = 2.51069
I0722 11:04:38.731928 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.59397 (* 1 = 1.59397 loss)
I0722 11:04:38.732054 23230 sgd_solver.cpp:138] Iteration 118350, lr = 1e-05
I0722 11:06:04.081791 23230 solver.cpp:243] Iteration 118360, loss = 2.38637
I0722 11:06:04.082151 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.50678 (* 1 = 1.50678 loss)
I0722 11:06:04.082249 23230 sgd_solver.cpp:138] Iteration 118360, lr = 1e-05
I0722 11:07:30.526352 23230 solver.cpp:243] Iteration 118370, loss = 2.41902
I0722 11:07:30.526661 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.352 (* 1 = 2.352 loss)
I0722 11:07:30.526773 23230 sgd_solver.cpp:138] Iteration 118370, lr = 1e-05
I0722 11:08:57.111696 23230 solver.cpp:243] Iteration 118380, loss = 2.39296
I0722 11:08:57.112012 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.59625 (* 1 = 2.59625 loss)
I0722 11:08:57.112145 23230 sgd_solver.cpp:138] Iteration 118380, lr = 1e-05
I0722 11:10:24.311702 23230 solver.cpp:243] Iteration 118390, loss = 2.46635
I0722 11:10:24.311961 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.22842 (* 1 = 2.22842 loss)
I0722 11:10:24.312005 23230 sgd_solver.cpp:138] Iteration 118390, lr = 1e-05
I0722 11:11:51.719687 23230 solver.cpp:243] Iteration 118400, loss = 2.61368
I0722 11:11:51.719960 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.34566 (* 1 = 3.34566 loss)
I0722 11:11:51.720077 23230 sgd_solver.cpp:138] Iteration 118400, lr = 1e-05
I0722 11:13:16.792357 23230 solver.cpp:243] Iteration 118410, loss = 2.44238
I0722 11:13:16.792611 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.57505 (* 1 = 1.57505 loss)
I0722 11:13:16.792731 23230 sgd_solver.cpp:138] Iteration 118410, lr = 1e-05
I0722 11:14:42.793905 23230 solver.cpp:243] Iteration 118420, loss = 2.37563
I0722 11:14:42.794193 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.59929 (* 1 = 1.59929 loss)
I0722 11:14:42.794267 23230 sgd_solver.cpp:138] Iteration 118420, lr = 1e-05
I0722 11:16:07.505010 23230 solver.cpp:243] Iteration 118430, loss = 2.52158
I0722 11:16:07.505785 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.22015 (* 1 = 2.22015 loss)
I0722 11:16:07.505878 23230 sgd_solver.cpp:138] Iteration 118430, lr = 1e-05
I0722 11:17:33.661298 23230 solver.cpp:243] Iteration 118440, loss = 2.69915
I0722 11:17:33.661600 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.13549 (* 1 = 3.13549 loss)
I0722 11:17:33.661710 23230 sgd_solver.cpp:138] Iteration 118440, lr = 1e-05
I0722 11:19:00.810640 23230 solver.cpp:243] Iteration 118450, loss = 2.53172
I0722 11:19:00.810930 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.24982 (* 1 = 3.24982 loss)
I0722 11:19:01.603729 23230 sgd_solver.cpp:138] Iteration 118450, lr = 1e-05
I0722 11:20:27.591596 23230 solver.cpp:243] Iteration 118460, loss = 2.623
I0722 11:20:27.591823 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.75588 (* 1 = 2.75588 loss)
I0722 11:20:27.591876 23230 sgd_solver.cpp:138] Iteration 118460, lr = 1e-05
I0722 11:21:54.408525 23230 solver.cpp:243] Iteration 118470, loss = 2.51258
I0722 11:21:54.408797 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.30596 (* 1 = 1.30596 loss)
I0722 11:21:54.408861 23230 sgd_solver.cpp:138] Iteration 118470, lr = 1e-05
I0722 11:23:20.677662 23230 solver.cpp:243] Iteration 118480, loss = 2.4349
I0722 11:23:20.677951 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.66146 (* 1 = 1.66146 loss)
I0722 11:23:20.678050 23230 sgd_solver.cpp:138] Iteration 118480, lr = 1e-05
I0722 11:24:47.826900 23230 solver.cpp:243] Iteration 118490, loss = 2.5872
I0722 11:24:47.827144 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0709 (* 1 = 2.0709 loss)
I0722 11:24:47.827203 23230 sgd_solver.cpp:138] Iteration 118490, lr = 1e-05
I0722 11:26:13.546021 23230 solver.cpp:243] Iteration 118500, loss = 2.34937
I0722 11:26:13.546324 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.02847 (* 1 = 3.02847 loss)
I0722 11:26:13.546428 23230 sgd_solver.cpp:138] Iteration 118500, lr = 1e-05
I0722 11:27:40.570636 23230 solver.cpp:243] Iteration 118510, loss = 2.36292
I0722 11:27:40.570930 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.00863 (* 1 = 2.00863 loss)
I0722 11:27:40.571043 23230 sgd_solver.cpp:138] Iteration 118510, lr = 1e-05
I0722 11:29:03.132952 23230 solver.cpp:243] Iteration 118520, loss = 2.50193
I0722 11:29:03.133213 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.69944 (* 1 = 3.69944 loss)
I0722 11:29:03.133260 23230 sgd_solver.cpp:138] Iteration 118520, lr = 1e-05
I0722 11:30:25.114501 23230 solver.cpp:243] Iteration 118530, loss = 2.58393
I0722 11:30:25.114823 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.11867 (* 1 = 3.11867 loss)
I0722 11:30:25.499253 23230 sgd_solver.cpp:138] Iteration 118530, lr = 1e-05
I0722 11:31:50.350528 23230 solver.cpp:243] Iteration 118540, loss = 2.35467
I0722 11:31:50.350781 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85466 (* 1 = 2.85466 loss)
I0722 11:31:50.350836 23230 sgd_solver.cpp:138] Iteration 118540, lr = 1e-05
I0722 11:33:15.797363 23230 solver.cpp:243] Iteration 118550, loss = 2.48257
I0722 11:33:15.797691 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.19656 (* 1 = 3.19656 loss)
I0722 11:33:15.797792 23230 sgd_solver.cpp:138] Iteration 118550, lr = 1e-05
I0722 11:34:42.568209 23230 solver.cpp:243] Iteration 118560, loss = 2.81302
I0722 11:34:42.568433 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82799 (* 1 = 2.82799 loss)
I0722 11:34:42.568481 23230 sgd_solver.cpp:138] Iteration 118560, lr = 1e-05
I0722 11:36:09.192670 23230 solver.cpp:243] Iteration 118570, loss = 2.51139
I0722 11:36:09.192886 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.05595 (* 1 = 1.05595 loss)
I0722 11:36:09.192939 23230 sgd_solver.cpp:138] Iteration 118570, lr = 1e-05
I0722 11:37:37.655838 23230 solver.cpp:243] Iteration 118580, loss = 2.37833
I0722 11:37:37.656766 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 11:37:37.656868 23230 sgd_solver.cpp:138] Iteration 118580, lr = 1e-05
I0722 11:39:05.712376 23230 solver.cpp:243] Iteration 118590, loss = 2.31632
I0722 11:39:05.712630 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01454 (* 1 = 3.01454 loss)
I0722 11:39:05.712684 23230 sgd_solver.cpp:138] Iteration 118590, lr = 1e-05
I0722 11:40:32.767575 23230 solver.cpp:243] Iteration 118600, loss = 2.58275
I0722 11:40:32.767859 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.39017 (* 1 = 1.39017 loss)
I0722 11:40:32.767910 23230 sgd_solver.cpp:138] Iteration 118600, lr = 1e-05
I0722 11:41:59.678598 23230 solver.cpp:243] Iteration 118610, loss = 2.74908
I0722 11:41:59.678858 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.01767 (* 1 = 2.01767 loss)
I0722 11:41:59.678910 23230 sgd_solver.cpp:138] Iteration 118610, lr = 1e-05
I0722 11:43:24.260586 23230 solver.cpp:243] Iteration 118620, loss = 2.45735
I0722 11:43:24.260886 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83565 (* 1 = 1.83565 loss)
I0722 11:43:24.623832 23230 sgd_solver.cpp:138] Iteration 118620, lr = 1e-05
I0722 11:44:50.922925 23230 solver.cpp:243] Iteration 118630, loss = 2.49997
I0722 11:44:50.923219 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3513 (* 1 = 2.3513 loss)
I0722 11:44:50.923318 23230 sgd_solver.cpp:138] Iteration 118630, lr = 1e-05
I0722 11:46:16.845003 23230 solver.cpp:243] Iteration 118640, loss = 2.73892
I0722 11:46:16.845315 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.12891 (* 1 = 2.12891 loss)
I0722 11:46:17.199270 23230 sgd_solver.cpp:138] Iteration 118640, lr = 1e-05
I0722 11:47:43.140429 23230 solver.cpp:243] Iteration 118650, loss = 2.38832
I0722 11:47:43.140671 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.31513 (* 1 = 1.31513 loss)
I0722 11:47:43.140727 23230 sgd_solver.cpp:138] Iteration 118650, lr = 1e-05
I0722 11:49:09.611985 23230 solver.cpp:243] Iteration 118660, loss = 2.58279
I0722 11:49:09.612248 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37697 (* 1 = 2.37697 loss)
I0722 11:49:09.612310 23230 sgd_solver.cpp:138] Iteration 118660, lr = 1e-05
I0722 11:50:34.790415 23230 solver.cpp:243] Iteration 118670, loss = 2.62459
I0722 11:50:34.790738 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.51269 (* 1 = 3.51269 loss)
I0722 11:50:34.790859 23230 sgd_solver.cpp:138] Iteration 118670, lr = 1e-05
I0722 11:52:00.847122 23230 solver.cpp:243] Iteration 118680, loss = 2.40391
I0722 11:52:00.847419 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.67038 (* 1 = 1.67038 loss)
I0722 11:52:00.847518 23230 sgd_solver.cpp:138] Iteration 118680, lr = 1e-05
I0722 11:53:25.213223 23230 solver.cpp:243] Iteration 118690, loss = 2.62843
I0722 11:53:25.213994 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.79621 (* 1 = 2.79621 loss)
I0722 11:53:25.214028 23230 sgd_solver.cpp:138] Iteration 118690, lr = 1e-05
I0722 11:54:49.268967 23230 solver.cpp:243] Iteration 118700, loss = 2.58176
I0722 11:54:49.269202 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.87885 (* 1 = 2.87885 loss)
I0722 11:54:49.269251 23230 sgd_solver.cpp:138] Iteration 118700, lr = 1e-05
I0722 11:56:16.394919 23230 solver.cpp:243] Iteration 118710, loss = 2.68554
I0722 11:56:16.395160 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.65698 (* 1 = 2.65698 loss)
I0722 11:56:16.395242 23230 sgd_solver.cpp:138] Iteration 118710, lr = 1e-05
I0722 11:57:40.839287 23230 solver.cpp:243] Iteration 118720, loss = 2.62799
I0722 11:57:40.839568 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.95485 (* 1 = 2.95485 loss)
I0722 11:57:41.588959 23230 sgd_solver.cpp:138] Iteration 118720, lr = 1e-05
I0722 11:59:08.392628 23230 solver.cpp:243] Iteration 118730, loss = 2.50835
I0722 11:59:08.392904 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.69476 (* 1 = 4.69476 loss)
I0722 11:59:08.393024 23230 sgd_solver.cpp:138] Iteration 118730, lr = 1e-05
I0722 12:00:30.247026 23230 solver.cpp:243] Iteration 118740, loss = 2.43298
I0722 12:00:30.247237 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03892 (* 1 = 2.03892 loss)
I0722 12:00:30.247287 23230 sgd_solver.cpp:138] Iteration 118740, lr = 1e-05
I0722 12:01:56.859534 23230 solver.cpp:243] Iteration 118750, loss = 2.46733
I0722 12:01:56.859916 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73939 (* 1 = 2.73939 loss)
I0722 12:01:57.228317 23230 sgd_solver.cpp:138] Iteration 118750, lr = 1e-05
I0722 12:03:19.305261 23230 solver.cpp:243] Iteration 118760, loss = 2.52499
I0722 12:03:19.305524 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15738 (* 1 = 2.15738 loss)
I0722 12:03:19.305629 23230 sgd_solver.cpp:138] Iteration 118760, lr = 1e-05
I0722 12:04:42.424636 23230 solver.cpp:243] Iteration 118770, loss = 2.44073
I0722 12:04:42.424868 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.51407 (* 1 = 1.51407 loss)
I0722 12:04:42.424921 23230 sgd_solver.cpp:138] Iteration 118770, lr = 1e-05
I0722 12:06:04.783509 23230 solver.cpp:243] Iteration 118780, loss = 2.73151
I0722 12:06:04.783820 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.20031 (* 1 = 2.20031 loss)
I0722 12:06:04.783928 23230 sgd_solver.cpp:138] Iteration 118780, lr = 1e-05
I0722 12:07:32.857359 23230 solver.cpp:243] Iteration 118790, loss = 2.56641
I0722 12:07:32.857647 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.12038 (* 1 = 1.12038 loss)
I0722 12:07:32.857759 23230 sgd_solver.cpp:138] Iteration 118790, lr = 1e-05
I0722 12:08:58.259825 23230 solver.cpp:243] Iteration 118800, loss = 2.72325
I0722 12:08:58.260063 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.90638 (* 1 = 6.90638 loss)
I0722 12:08:58.260115 23230 sgd_solver.cpp:138] Iteration 118800, lr = 1e-05
I0722 12:10:21.393223 23230 solver.cpp:243] Iteration 118810, loss = 2.43955
I0722 12:10:21.394989 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7695 (* 1 = 1.7695 loss)
I0722 12:10:21.395026 23230 sgd_solver.cpp:138] Iteration 118810, lr = 1e-05
I0722 12:11:45.626922 23230 solver.cpp:243] Iteration 118820, loss = 2.65405
I0722 12:11:45.627223 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.77362 (* 1 = 3.77362 loss)
I0722 12:11:45.627338 23230 sgd_solver.cpp:138] Iteration 118820, lr = 1e-05
I0722 12:13:11.900606 23230 solver.cpp:243] Iteration 118830, loss = 2.57928
I0722 12:13:11.900882 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.94646 (* 1 = 2.94646 loss)
I0722 12:13:11.900941 23230 sgd_solver.cpp:138] Iteration 118830, lr = 1e-05
I0722 12:14:36.920042 23230 solver.cpp:243] Iteration 118840, loss = 2.67545
I0722 12:14:36.920933 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.19866 (* 1 = 3.19866 loss)
I0722 12:14:36.921018 23230 sgd_solver.cpp:138] Iteration 118840, lr = 1e-05
I0722 12:16:01.077359 23230 solver.cpp:243] Iteration 118850, loss = 2.74873
I0722 12:16:01.077646 23230 solver.cpp:259]     Train net output #0: mbox_loss = 17.7711 (* 1 = 17.7711 loss)
I0722 12:16:01.873322 23230 sgd_solver.cpp:138] Iteration 118850, lr = 1e-05
I0722 12:17:30.461462 23230 solver.cpp:243] Iteration 118860, loss = 2.47002
I0722 12:17:30.461768 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.73445 (* 1 = 1.73445 loss)
I0722 12:17:30.461880 23230 sgd_solver.cpp:138] Iteration 118860, lr = 1e-05
I0722 12:18:58.335081 23230 solver.cpp:243] Iteration 118870, loss = 2.4466
I0722 12:18:58.335325 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.66786 (* 1 = 1.66786 loss)
I0722 12:18:58.335374 23230 sgd_solver.cpp:138] Iteration 118870, lr = 1e-05
I0722 12:20:22.360036 23230 solver.cpp:243] Iteration 118880, loss = 2.77904
I0722 12:20:22.360347 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.6496 (* 1 = 2.6496 loss)
I0722 12:20:22.360441 23230 sgd_solver.cpp:138] Iteration 118880, lr = 1e-05
I0722 12:21:49.303750 23230 solver.cpp:243] Iteration 118890, loss = 2.48842
I0722 12:21:49.304081 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.94788 (* 1 = 1.94788 loss)
I0722 12:21:49.304213 23230 sgd_solver.cpp:138] Iteration 118890, lr = 1e-05
I0722 12:23:15.840365 23230 solver.cpp:243] Iteration 118900, loss = 2.46795
I0722 12:23:15.840580 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.66749 (* 1 = 3.66749 loss)
I0722 12:23:15.840628 23230 sgd_solver.cpp:138] Iteration 118900, lr = 1e-05
I0722 12:24:40.431131 23230 solver.cpp:243] Iteration 118910, loss = 2.2848
I0722 12:24:40.431361 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.17914 (* 1 = 1.17914 loss)
I0722 12:24:40.431417 23230 sgd_solver.cpp:138] Iteration 118910, lr = 1e-05
I0722 12:26:08.375716 23230 solver.cpp:243] Iteration 118920, loss = 2.53366
I0722 12:26:08.376071 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2117 (* 1 = 2.2117 loss)
I0722 12:26:08.376163 23230 sgd_solver.cpp:138] Iteration 118920, lr = 1e-05
I0722 12:27:34.220695 23230 solver.cpp:243] Iteration 118930, loss = 2.48669
I0722 12:27:34.220986 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.28876 (* 1 = 3.28876 loss)
I0722 12:27:34.221076 23230 sgd_solver.cpp:138] Iteration 118930, lr = 1e-05
I0722 12:29:00.004797 23230 solver.cpp:243] Iteration 118940, loss = 2.74082
I0722 12:29:00.005215 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.66762 (* 1 = 2.66762 loss)
I0722 12:29:00.005265 23230 sgd_solver.cpp:138] Iteration 118940, lr = 1e-05
I0722 12:30:27.262924 23230 solver.cpp:243] Iteration 118950, loss = 2.64196
I0722 12:30:27.263211 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.89967 (* 1 = 2.89967 loss)
I0722 12:30:27.263306 23230 sgd_solver.cpp:138] Iteration 118950, lr = 1e-05
I0722 12:31:51.545634 23230 solver.cpp:243] Iteration 118960, loss = 2.64869
I0722 12:31:51.545917 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.44218 (* 1 = 3.44218 loss)
I0722 12:31:51.545969 23230 sgd_solver.cpp:138] Iteration 118960, lr = 1e-05
I0722 12:33:15.962599 23230 solver.cpp:243] Iteration 118970, loss = 2.40849
I0722 12:33:15.962843 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.77574 (* 1 = 1.77574 loss)
I0722 12:33:15.962895 23230 sgd_solver.cpp:138] Iteration 118970, lr = 1e-05
I0722 12:34:40.146008 23230 solver.cpp:243] Iteration 118980, loss = 2.45623
I0722 12:34:40.146344 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.21899 (* 1 = 2.21899 loss)
I0722 12:34:40.146466 23230 sgd_solver.cpp:138] Iteration 118980, lr = 1e-05
I0722 12:36:06.178516 23230 solver.cpp:243] Iteration 118990, loss = 2.62002
I0722 12:36:06.178779 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.76378 (* 1 = 4.76378 loss)
I0722 12:36:06.178822 23230 sgd_solver.cpp:138] Iteration 118990, lr = 1e-05
I0722 12:37:23.711566 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_119000.caffemodel
I0722 12:37:24.200867 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_119000.solverstate
I0722 12:37:24.399705 23230 solver.cpp:433] Iteration 119000, Testing net (#0)
I0722 12:37:24.399900 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 12:37:27.723273 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.616582
I0722 12:37:35.975456 23230 solver.cpp:243] Iteration 119000, loss = 2.53963
I0722 12:37:35.975553 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08539 (* 1 = 3.08539 loss)
I0722 12:37:35.975589 23230 sgd_solver.cpp:138] Iteration 119000, lr = 1e-05
I0722 12:39:01.204715 23230 solver.cpp:243] Iteration 119010, loss = 2.36789
I0722 12:39:01.204996 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.42838 (* 1 = 2.42838 loss)
I0722 12:39:01.205047 23230 sgd_solver.cpp:138] Iteration 119010, lr = 1e-05
I0722 12:40:26.786651 23230 solver.cpp:243] Iteration 119020, loss = 2.64538
I0722 12:40:26.786962 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.20624 (* 1 = 2.20624 loss)
I0722 12:40:27.147857 23230 sgd_solver.cpp:138] Iteration 119020, lr = 1e-05
I0722 12:41:53.272434 23230 solver.cpp:243] Iteration 119030, loss = 2.66296
I0722 12:41:53.272680 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.01999 (* 1 = 2.01999 loss)
I0722 12:41:53.272729 23230 sgd_solver.cpp:138] Iteration 119030, lr = 1e-05
I0722 12:43:18.139389 23230 solver.cpp:243] Iteration 119040, loss = 2.63685
I0722 12:43:18.139636 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.53583 (* 1 = 1.53583 loss)
I0722 12:43:18.139696 23230 sgd_solver.cpp:138] Iteration 119040, lr = 1e-05
I0722 12:44:43.607689 23230 solver.cpp:243] Iteration 119050, loss = 2.44452
I0722 12:44:43.607936 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.73645 (* 1 = 1.73645 loss)
I0722 12:44:44.428351 23230 sgd_solver.cpp:138] Iteration 119050, lr = 1e-05
I0722 12:46:09.871877 23230 solver.cpp:243] Iteration 119060, loss = 2.39691
I0722 12:46:09.872145 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.06776 (* 1 = 1.06776 loss)
I0722 12:46:10.649564 23230 sgd_solver.cpp:138] Iteration 119060, lr = 1e-05
I0722 12:47:35.464565 23230 solver.cpp:243] Iteration 119070, loss = 2.56021
I0722 12:47:35.464869 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80176 (* 1 = 1.80176 loss)
I0722 12:47:35.464992 23230 sgd_solver.cpp:138] Iteration 119070, lr = 1e-05
I0722 12:49:02.223367 23230 solver.cpp:243] Iteration 119080, loss = 2.5926
I0722 12:49:02.223599 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38497 (* 1 = 2.38497 loss)
I0722 12:49:02.223664 23230 sgd_solver.cpp:138] Iteration 119080, lr = 1e-05
I0722 12:50:28.785718 23230 solver.cpp:243] Iteration 119090, loss = 2.43742
I0722 12:50:28.786830 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.799801 (* 1 = 0.799801 loss)
I0722 12:50:28.786885 23230 sgd_solver.cpp:138] Iteration 119090, lr = 1e-05
I0722 12:51:53.650089 23230 solver.cpp:243] Iteration 119100, loss = 2.45402
I0722 12:51:53.650357 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.88847 (* 1 = 1.88847 loss)
I0722 12:51:53.650442 23230 sgd_solver.cpp:138] Iteration 119100, lr = 1e-05
I0722 12:53:22.037065 23230 solver.cpp:243] Iteration 119110, loss = 2.52957
I0722 12:53:22.037333 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85185 (* 1 = 2.85185 loss)
I0722 12:53:22.037395 23230 sgd_solver.cpp:138] Iteration 119110, lr = 1e-05
I0722 12:54:48.031239 23230 solver.cpp:243] Iteration 119120, loss = 2.60369
I0722 12:54:48.031533 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.09934 (* 1 = 1.09934 loss)
I0722 12:54:48.031632 23230 sgd_solver.cpp:138] Iteration 119120, lr = 1e-05
I0722 12:56:16.581699 23230 solver.cpp:243] Iteration 119130, loss = 2.76639
I0722 12:56:16.581948 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61847 (* 1 = 2.61847 loss)
I0722 12:56:16.582001 23230 sgd_solver.cpp:138] Iteration 119130, lr = 1e-05
I0722 12:57:42.782940 23230 solver.cpp:243] Iteration 119140, loss = 2.3771
I0722 12:57:42.783187 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69299 (* 1 = 2.69299 loss)
I0722 12:57:42.783232 23230 sgd_solver.cpp:138] Iteration 119140, lr = 1e-05
I0722 12:59:07.126252 23230 solver.cpp:243] Iteration 119150, loss = 2.40995
I0722 12:59:07.126538 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.61218 (* 1 = 1.61218 loss)
I0722 12:59:07.126582 23230 sgd_solver.cpp:138] Iteration 119150, lr = 1e-05
I0722 13:00:31.198324 23230 solver.cpp:243] Iteration 119160, loss = 2.52115
I0722 13:00:31.198699 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37741 (* 1 = 2.37741 loss)
I0722 13:00:31.562778 23230 sgd_solver.cpp:138] Iteration 119160, lr = 1e-05
I0722 13:02:00.255393 23230 solver.cpp:243] Iteration 119170, loss = 2.62815
I0722 13:02:00.260020 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.97651 (* 1 = 1.97651 loss)
I0722 13:02:00.260076 23230 sgd_solver.cpp:138] Iteration 119170, lr = 1e-05
I0722 13:03:27.234603 23230 solver.cpp:243] Iteration 119180, loss = 2.57738
I0722 13:03:27.234853 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.55276 (* 1 = 1.55276 loss)
I0722 13:03:27.234907 23230 sgd_solver.cpp:138] Iteration 119180, lr = 1e-05
I0722 13:04:54.601208 23230 solver.cpp:243] Iteration 119190, loss = 2.40917
I0722 13:04:54.601446 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02816 (* 1 = 2.02816 loss)
I0722 13:04:54.601500 23230 sgd_solver.cpp:138] Iteration 119190, lr = 1e-05
I0722 13:06:21.654561 23230 solver.cpp:243] Iteration 119200, loss = 2.59074
I0722 13:06:21.654821 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.06639 (* 1 = 2.06639 loss)
I0722 13:06:21.654873 23230 sgd_solver.cpp:138] Iteration 119200, lr = 1e-05
I0722 13:07:48.727429 23230 solver.cpp:243] Iteration 119210, loss = 2.57672
I0722 13:07:48.727749 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.6033 (* 1 = 2.6033 loss)
I0722 13:07:48.727877 23230 sgd_solver.cpp:138] Iteration 119210, lr = 1e-05
I0722 13:09:11.803076 23230 solver.cpp:243] Iteration 119220, loss = 2.48296
I0722 13:09:11.803400 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.24045 (* 1 = 1.24045 loss)
I0722 13:09:12.171367 23230 sgd_solver.cpp:138] Iteration 119220, lr = 1e-05
I0722 13:10:40.201977 23230 solver.cpp:243] Iteration 119230, loss = 2.66406
I0722 13:10:40.202250 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.35702 (* 1 = 3.35702 loss)
I0722 13:10:40.202329 23230 sgd_solver.cpp:138] Iteration 119230, lr = 1e-05
I0722 13:12:06.620286 23230 solver.cpp:243] Iteration 119240, loss = 2.47121
I0722 13:12:06.621989 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31398 (* 1 = 2.31398 loss)
I0722 13:12:07.387347 23230 sgd_solver.cpp:138] Iteration 119240, lr = 1e-05
I0722 13:13:30.936446 23230 solver.cpp:243] Iteration 119250, loss = 2.5633
I0722 13:13:30.936751 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78539 (* 1 = 2.78539 loss)
I0722 13:13:30.936857 23230 sgd_solver.cpp:138] Iteration 119250, lr = 1e-05
I0722 13:14:59.270177 23230 solver.cpp:243] Iteration 119260, loss = 2.58225
I0722 13:14:59.270481 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05549 (* 1 = 2.05549 loss)
I0722 13:14:59.270584 23230 sgd_solver.cpp:138] Iteration 119260, lr = 1e-05
I0722 13:16:22.294248 23230 solver.cpp:243] Iteration 119270, loss = 2.58975
I0722 13:16:22.294625 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 13:16:23.611968 23230 sgd_solver.cpp:138] Iteration 119270, lr = 1e-05
I0722 13:17:46.944242 23230 solver.cpp:243] Iteration 119280, loss = 2.66782
I0722 13:17:46.944613 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.22032 (* 1 = 4.22032 loss)
I0722 13:17:47.301478 23230 sgd_solver.cpp:138] Iteration 119280, lr = 1e-05
I0722 13:19:12.323781 23230 solver.cpp:243] Iteration 119290, loss = 2.487
I0722 13:19:12.324091 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.15806 (* 1 = 3.15806 loss)
I0722 13:19:12.324203 23230 sgd_solver.cpp:138] Iteration 119290, lr = 1e-05
I0722 13:20:38.302590 23230 solver.cpp:243] Iteration 119300, loss = 2.81795
I0722 13:20:38.302825 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.30699 (* 1 = 3.30699 loss)
I0722 13:20:38.302898 23230 sgd_solver.cpp:138] Iteration 119300, lr = 1e-05
I0722 13:22:07.489034 23230 solver.cpp:243] Iteration 119310, loss = 2.58675
I0722 13:22:07.489327 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.62388 (* 1 = 1.62388 loss)
I0722 13:22:07.489439 23230 sgd_solver.cpp:138] Iteration 119310, lr = 1e-05
I0722 13:23:36.381029 23230 solver.cpp:243] Iteration 119320, loss = 2.45165
I0722 13:23:36.381268 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85393 (* 1 = 2.85393 loss)
I0722 13:23:36.381309 23230 sgd_solver.cpp:138] Iteration 119320, lr = 1e-05
I0722 13:25:03.277575 23230 solver.cpp:243] Iteration 119330, loss = 2.67122
I0722 13:25:03.277794 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.89222 (* 1 = 3.89222 loss)
I0722 13:25:03.277839 23230 sgd_solver.cpp:138] Iteration 119330, lr = 1e-05
I0722 13:26:30.405398 23230 solver.cpp:243] Iteration 119340, loss = 2.83466
I0722 13:26:30.405699 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.76273 (* 1 = 2.76273 loss)
I0722 13:26:30.764585 23230 sgd_solver.cpp:138] Iteration 119340, lr = 1e-05
I0722 13:27:57.707767 23230 solver.cpp:243] Iteration 119350, loss = 2.71746
I0722 13:27:57.708026 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73117 (* 1 = 2.73117 loss)
I0722 13:27:57.708132 23230 sgd_solver.cpp:138] Iteration 119350, lr = 1e-05
I0722 13:29:24.000097 23230 solver.cpp:243] Iteration 119360, loss = 2.36356
I0722 13:29:24.000387 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.28179 (* 1 = 1.28179 loss)
I0722 13:29:24.000500 23230 sgd_solver.cpp:138] Iteration 119360, lr = 1e-05
I0722 13:30:48.988682 23230 solver.cpp:243] Iteration 119370, loss = 2.46106
I0722 13:30:48.988960 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.10243 (* 1 = 1.10243 loss)
I0722 13:30:48.989069 23230 sgd_solver.cpp:138] Iteration 119370, lr = 1e-05
I0722 13:32:15.517479 23230 solver.cpp:243] Iteration 119380, loss = 2.54708
I0722 13:32:15.517694 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.60526 (* 1 = 3.60526 loss)
I0722 13:32:15.517735 23230 sgd_solver.cpp:138] Iteration 119380, lr = 1e-05
I0722 13:33:44.783897 23230 solver.cpp:243] Iteration 119390, loss = 2.53411
I0722 13:33:44.784134 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45755 (* 1 = 1.45755 loss)
I0722 13:33:44.784178 23230 sgd_solver.cpp:138] Iteration 119390, lr = 1e-05
I0722 13:35:08.649092 23230 solver.cpp:243] Iteration 119400, loss = 2.53884
I0722 13:35:08.649348 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.42756 (* 1 = 2.42756 loss)
I0722 13:35:08.649394 23230 sgd_solver.cpp:138] Iteration 119400, lr = 1e-05
I0722 13:36:34.144067 23230 solver.cpp:243] Iteration 119410, loss = 2.51457
I0722 13:36:34.144295 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.50683 (* 1 = 1.50683 loss)
I0722 13:36:34.144345 23230 sgd_solver.cpp:138] Iteration 119410, lr = 1e-05
I0722 13:37:55.381650 23230 solver.cpp:243] Iteration 119420, loss = 2.37259
I0722 13:37:55.381935 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76499 (* 1 = 3.76499 loss)
I0722 13:37:55.382033 23230 sgd_solver.cpp:138] Iteration 119420, lr = 1e-05
I0722 13:39:20.809593 23230 solver.cpp:243] Iteration 119430, loss = 2.50087
I0722 13:39:20.809883 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.66206 (* 1 = 3.66206 loss)
I0722 13:39:20.809936 23230 sgd_solver.cpp:138] Iteration 119430, lr = 1e-05
I0722 13:40:46.336246 23230 solver.cpp:243] Iteration 119440, loss = 2.63701
I0722 13:40:46.336570 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.0114 (* 1 = 4.0114 loss)
I0722 13:40:46.336681 23230 sgd_solver.cpp:138] Iteration 119440, lr = 1e-05
I0722 13:42:12.159243 23230 solver.cpp:243] Iteration 119450, loss = 2.36325
I0722 13:42:12.159497 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8413 (* 1 = 2.8413 loss)
I0722 13:42:12.159545 23230 sgd_solver.cpp:138] Iteration 119450, lr = 1e-05
I0722 13:43:36.725167 23230 solver.cpp:243] Iteration 119460, loss = 2.50666
I0722 13:43:36.725430 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.82559 (* 1 = 3.82559 loss)
I0722 13:43:36.725502 23230 sgd_solver.cpp:138] Iteration 119460, lr = 1e-05
I0722 13:45:03.191634 23230 solver.cpp:243] Iteration 119470, loss = 2.69289
I0722 13:45:03.191946 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.86731 (* 1 = 2.86731 loss)
I0722 13:45:03.544909 23230 sgd_solver.cpp:138] Iteration 119470, lr = 1e-05
I0722 13:46:30.928742 23230 solver.cpp:243] Iteration 119480, loss = 2.59351
I0722 13:46:30.929054 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.06626 (* 1 = 2.06626 loss)
I0722 13:46:30.929157 23230 sgd_solver.cpp:138] Iteration 119480, lr = 1e-05
I0722 13:47:58.522156 23230 solver.cpp:243] Iteration 119490, loss = 2.46081
I0722 13:47:58.522485 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57809 (* 1 = 2.57809 loss)
I0722 13:47:59.312281 23230 sgd_solver.cpp:138] Iteration 119490, lr = 1e-05
I0722 13:49:25.249842 23230 solver.cpp:243] Iteration 119500, loss = 2.49827
I0722 13:49:25.250128 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38403 (* 1 = 2.38403 loss)
I0722 13:49:25.250212 23230 sgd_solver.cpp:138] Iteration 119500, lr = 1e-05
I0722 13:50:51.749084 23230 solver.cpp:243] Iteration 119510, loss = 2.65037
I0722 13:50:51.749387 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.65586 (* 1 = 2.65586 loss)
I0722 13:50:52.115492 23230 sgd_solver.cpp:138] Iteration 119510, lr = 1e-05
I0722 13:52:16.936034 23230 solver.cpp:243] Iteration 119520, loss = 2.5149
I0722 13:52:16.937068 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.25218 (* 1 = 3.25218 loss)
I0722 13:52:17.285571 23230 sgd_solver.cpp:138] Iteration 119520, lr = 1e-05
I0722 13:53:43.803306 23230 solver.cpp:243] Iteration 119530, loss = 2.51663
I0722 13:53:43.803575 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83835 (* 1 = 2.83835 loss)
I0722 13:53:43.803619 23230 sgd_solver.cpp:138] Iteration 119530, lr = 1e-05
I0722 13:55:11.206238 23230 solver.cpp:243] Iteration 119540, loss = 2.51908
I0722 13:55:11.206540 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.05174 (* 1 = 1.05174 loss)
I0722 13:55:11.560674 23230 sgd_solver.cpp:138] Iteration 119540, lr = 1e-05
I0722 13:56:39.327213 23230 solver.cpp:243] Iteration 119550, loss = 2.5431
I0722 13:56:39.327536 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.24916 (* 1 = 3.24916 loss)
I0722 13:56:39.327633 23230 sgd_solver.cpp:138] Iteration 119550, lr = 1e-05
I0722 13:58:06.951447 23230 solver.cpp:243] Iteration 119560, loss = 2.67114
I0722 13:58:06.951725 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.3157 (* 1 = 1.3157 loss)
I0722 13:58:06.951782 23230 sgd_solver.cpp:138] Iteration 119560, lr = 1e-05
I0722 13:59:33.250099 23230 solver.cpp:243] Iteration 119570, loss = 2.505
I0722 13:59:33.250352 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83727 (* 1 = 1.83727 loss)
I0722 13:59:33.605072 23230 sgd_solver.cpp:138] Iteration 119570, lr = 1e-05
I0722 14:00:59.736434 23230 solver.cpp:243] Iteration 119580, loss = 2.76397
I0722 14:00:59.736758 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01888 (* 1 = 3.01888 loss)
I0722 14:00:59.736860 23230 sgd_solver.cpp:138] Iteration 119580, lr = 1e-05
I0722 14:02:24.719509 23230 solver.cpp:243] Iteration 119590, loss = 2.30513
I0722 14:02:24.719776 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.91296 (* 1 = 3.91296 loss)
I0722 14:02:24.719821 23230 sgd_solver.cpp:138] Iteration 119590, lr = 1e-05
I0722 14:03:50.668767 23230 solver.cpp:243] Iteration 119600, loss = 2.4821
I0722 14:03:50.669098 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.0166 (* 1 = 1.0166 loss)
I0722 14:03:51.048804 23230 sgd_solver.cpp:138] Iteration 119600, lr = 1e-05
I0722 14:05:15.097728 23230 solver.cpp:243] Iteration 119610, loss = 2.37686
I0722 14:05:15.097962 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.76314 (* 1 = 5.76314 loss)
I0722 14:05:16.104413 23230 sgd_solver.cpp:138] Iteration 119610, lr = 1e-05
I0722 14:06:43.266286 23230 solver.cpp:243] Iteration 119620, loss = 2.51197
I0722 14:06:43.266537 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.97369 (* 1 = 1.97369 loss)
I0722 14:06:43.266597 23230 sgd_solver.cpp:138] Iteration 119620, lr = 1e-05
I0722 14:08:09.474774 23230 solver.cpp:243] Iteration 119630, loss = 2.57521
I0722 14:08:09.475085 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26445 (* 1 = 2.26445 loss)
I0722 14:08:09.475200 23230 sgd_solver.cpp:138] Iteration 119630, lr = 1e-05
I0722 14:09:33.255692 23230 solver.cpp:243] Iteration 119640, loss = 2.6038
I0722 14:09:33.256001 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20434 (* 1 = 1.20434 loss)
I0722 14:09:33.256098 23230 sgd_solver.cpp:138] Iteration 119640, lr = 1e-05
I0722 14:10:56.403702 23230 solver.cpp:243] Iteration 119650, loss = 2.44531
I0722 14:10:56.403926 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.60294 (* 1 = 1.60294 loss)
I0722 14:10:56.403973 23230 sgd_solver.cpp:138] Iteration 119650, lr = 1e-05
I0722 14:12:21.637642 23230 solver.cpp:243] Iteration 119660, loss = 2.56107
I0722 14:12:21.637907 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.0733 (* 1 = 3.0733 loss)
I0722 14:12:21.638018 23230 sgd_solver.cpp:138] Iteration 119660, lr = 1e-05
I0722 14:13:46.636544 23230 solver.cpp:243] Iteration 119670, loss = 2.57485
I0722 14:13:46.637675 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.13976 (* 1 = 1.13976 loss)
I0722 14:13:46.637732 23230 sgd_solver.cpp:138] Iteration 119670, lr = 1e-05
I0722 14:15:12.307392 23230 solver.cpp:243] Iteration 119680, loss = 2.4995
I0722 14:15:12.307653 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.28099 (* 1 = 3.28099 loss)
I0722 14:15:12.307695 23230 sgd_solver.cpp:138] Iteration 119680, lr = 1e-05
I0722 14:16:38.091498 23230 solver.cpp:243] Iteration 119690, loss = 2.47326
I0722 14:16:38.091749 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.39386 (* 1 = 1.39386 loss)
I0722 14:16:38.091790 23230 sgd_solver.cpp:138] Iteration 119690, lr = 1e-05
I0722 14:18:02.193152 23230 solver.cpp:243] Iteration 119700, loss = 2.83865
I0722 14:18:02.193409 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.88549 (* 1 = 1.88549 loss)
I0722 14:18:02.193457 23230 sgd_solver.cpp:138] Iteration 119700, lr = 1e-05
I0722 14:19:26.540474 23230 solver.cpp:243] Iteration 119710, loss = 2.45283
I0722 14:19:26.540733 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.65464 (* 1 = 1.65464 loss)
I0722 14:19:26.540777 23230 sgd_solver.cpp:138] Iteration 119710, lr = 1e-05
I0722 14:20:53.191782 23230 solver.cpp:243] Iteration 119720, loss = 2.49311
I0722 14:20:53.192101 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17168 (* 1 = 3.17168 loss)
I0722 14:20:53.192200 23230 sgd_solver.cpp:138] Iteration 119720, lr = 1e-05
I0722 14:22:21.452600 23230 solver.cpp:243] Iteration 119730, loss = 2.47868
I0722 14:22:21.452924 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32283 (* 1 = 1.32283 loss)
I0722 14:22:21.453058 23230 sgd_solver.cpp:138] Iteration 119730, lr = 1e-05
I0722 14:23:49.076213 23230 solver.cpp:243] Iteration 119740, loss = 2.58166
I0722 14:23:49.076529 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.65846 (* 1 = 3.65846 loss)
I0722 14:23:49.076643 23230 sgd_solver.cpp:138] Iteration 119740, lr = 1e-05
I0722 14:25:14.956286 23230 solver.cpp:243] Iteration 119750, loss = 2.58962
I0722 14:25:14.956535 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.01865 (* 1 = 2.01865 loss)
I0722 14:25:14.956583 23230 sgd_solver.cpp:138] Iteration 119750, lr = 1e-05
I0722 14:26:41.464196 23230 solver.cpp:243] Iteration 119760, loss = 2.58763
I0722 14:26:41.464495 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.4912 (* 1 = 1.4912 loss)
I0722 14:26:42.612299 23230 sgd_solver.cpp:138] Iteration 119760, lr = 1e-05
I0722 14:28:07.348482 23230 solver.cpp:243] Iteration 119770, loss = 2.74217
I0722 14:28:07.348786 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24256 (* 1 = 2.24256 loss)
I0722 14:28:07.708832 23230 sgd_solver.cpp:138] Iteration 119770, lr = 1e-05
I0722 14:29:32.068029 23230 solver.cpp:243] Iteration 119780, loss = 2.19852
I0722 14:29:32.068528 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.05234 (* 1 = 3.05234 loss)
I0722 14:29:33.437897 23230 sgd_solver.cpp:138] Iteration 119780, lr = 1e-05
I0722 14:30:57.709887 23230 solver.cpp:243] Iteration 119790, loss = 2.5148
I0722 14:30:57.710153 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.01808 (* 1 = 5.01808 loss)
I0722 14:30:59.245297 23230 sgd_solver.cpp:138] Iteration 119790, lr = 1e-05
I0722 14:32:27.080595 23230 solver.cpp:243] Iteration 119800, loss = 2.659
I0722 14:32:27.080926 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.26919 (* 1 = 1.26919 loss)
I0722 14:32:27.081038 23230 sgd_solver.cpp:138] Iteration 119800, lr = 1e-05
I0722 14:33:53.278571 23230 solver.cpp:243] Iteration 119810, loss = 2.60014
I0722 14:33:53.278892 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27654 (* 1 = 3.27654 loss)
I0722 14:33:53.278981 23230 sgd_solver.cpp:138] Iteration 119810, lr = 1e-05
I0722 14:35:17.133410 23230 solver.cpp:243] Iteration 119820, loss = 2.32413
I0722 14:35:17.133666 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.14892 (* 1 = 4.14892 loss)
I0722 14:35:17.133718 23230 sgd_solver.cpp:138] Iteration 119820, lr = 1e-05
I0722 14:36:46.947445 23230 solver.cpp:243] Iteration 119830, loss = 2.86912
I0722 14:36:46.947779 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.43789 (* 1 = 2.43789 loss)
I0722 14:36:46.947875 23230 sgd_solver.cpp:138] Iteration 119830, lr = 1e-05
I0722 14:38:15.603298 23230 solver.cpp:243] Iteration 119840, loss = 2.73199
I0722 14:38:15.603572 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.9065 (* 1 = 2.9065 loss)
I0722 14:38:16.008246 23230 sgd_solver.cpp:138] Iteration 119840, lr = 1e-05
I0722 14:39:41.905408 23230 solver.cpp:243] Iteration 119850, loss = 2.58964
I0722 14:39:41.905768 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.75937 (* 1 = 2.75937 loss)
I0722 14:39:42.277374 23230 sgd_solver.cpp:138] Iteration 119850, lr = 1e-05
I0722 14:41:08.351989 23230 solver.cpp:243] Iteration 119860, loss = 2.29592
I0722 14:41:08.352236 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7097 (* 1 = 1.7097 loss)
I0722 14:41:08.352286 23230 sgd_solver.cpp:138] Iteration 119860, lr = 1e-05
I0722 14:42:33.975244 23230 solver.cpp:243] Iteration 119870, loss = 2.41519
I0722 14:42:33.975528 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.3022 (* 1 = 3.3022 loss)
I0722 14:42:34.760321 23230 sgd_solver.cpp:138] Iteration 119870, lr = 1e-05
I0722 14:43:59.183689 23230 solver.cpp:243] Iteration 119880, loss = 2.56358
I0722 14:43:59.183961 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.42917 (* 1 = 2.42917 loss)
I0722 14:43:59.184031 23230 sgd_solver.cpp:138] Iteration 119880, lr = 1e-05
I0722 14:45:23.826186 23230 solver.cpp:243] Iteration 119890, loss = 2.41505
I0722 14:45:23.826530 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.15169 (* 1 = 1.15169 loss)
I0722 14:45:24.189671 23230 sgd_solver.cpp:138] Iteration 119890, lr = 1e-05
I0722 14:46:47.209182 23230 solver.cpp:243] Iteration 119900, loss = 2.4425
I0722 14:46:47.209550 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.22112 (* 1 = 1.22112 loss)
I0722 14:46:48.661398 23230 sgd_solver.cpp:138] Iteration 119900, lr = 1e-05
I0722 14:48:14.343240 23230 solver.cpp:243] Iteration 119910, loss = 2.57457
I0722 14:48:14.343482 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02087 (* 1 = 2.02087 loss)
I0722 14:48:14.343523 23230 sgd_solver.cpp:138] Iteration 119910, lr = 1e-05
I0722 14:49:41.631780 23230 solver.cpp:243] Iteration 119920, loss = 2.5389
I0722 14:49:41.632072 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.5496 (* 1 = 3.5496 loss)
I0722 14:49:42.425623 23230 sgd_solver.cpp:138] Iteration 119920, lr = 1e-05
I0722 14:51:07.869858 23230 solver.cpp:243] Iteration 119930, loss = 2.63195
I0722 14:51:07.870136 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.06715 (* 1 = 4.06715 loss)
I0722 14:51:07.870189 23230 sgd_solver.cpp:138] Iteration 119930, lr = 1e-05
I0722 14:52:33.907217 23230 solver.cpp:243] Iteration 119940, loss = 2.5864
I0722 14:52:33.907562 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.39657 (* 1 = 3.39657 loss)
I0722 14:52:33.907681 23230 sgd_solver.cpp:138] Iteration 119940, lr = 1e-05
I0722 14:53:57.794175 23230 solver.cpp:243] Iteration 119950, loss = 2.32437
I0722 14:53:57.794441 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.2979 (* 1 = 4.2979 loss)
I0722 14:53:57.794504 23230 sgd_solver.cpp:138] Iteration 119950, lr = 1e-05
I0722 14:55:22.895846 23230 solver.cpp:243] Iteration 119960, loss = 2.51572
I0722 14:55:22.896064 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 14:55:22.896138 23230 sgd_solver.cpp:138] Iteration 119960, lr = 1e-05
I0722 14:56:51.431744 23230 solver.cpp:243] Iteration 119970, loss = 2.58861
I0722 14:56:51.432009 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.42013 (* 1 = 1.42013 loss)
I0722 14:56:51.432059 23230 sgd_solver.cpp:138] Iteration 119970, lr = 1e-05
I0722 14:58:20.271412 23230 solver.cpp:243] Iteration 119980, loss = 2.30393
I0722 14:58:20.271737 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.38304 (* 1 = 3.38304 loss)
I0722 14:58:20.271857 23230 sgd_solver.cpp:138] Iteration 119980, lr = 1e-05
I0722 14:59:46.702273 23230 solver.cpp:243] Iteration 119990, loss = 2.62174
I0722 14:59:46.702579 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.04162 (* 1 = 1.04162 loss)
I0722 14:59:46.702682 23230 sgd_solver.cpp:138] Iteration 119990, lr = 1e-05
I0722 15:01:05.350111 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_120000.caffemodel
I0722 15:01:05.835806 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_120000.solverstate
I0722 15:01:06.036892 23230 solver.cpp:433] Iteration 120000, Testing net (#0)
I0722 15:01:06.037196 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 15:01:09.354331 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.614409
I0722 15:01:16.613214 23230 solver.cpp:243] Iteration 120000, loss = 2.42984
I0722 15:01:16.613312 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.21031 (* 1 = 2.21031 loss)
I0722 15:01:16.970284 23230 sgd_solver.cpp:47] MultiStep Status: Iteration 120000, step = 3
I0722 15:01:16.970320 23230 sgd_solver.cpp:138] Iteration 120000, lr = 1e-06
I0722 15:02:45.654697 23230 solver.cpp:243] Iteration 120010, loss = 2.58984
I0722 15:02:45.654937 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.00843 (* 1 = 2.00843 loss)
I0722 15:02:45.654990 23230 sgd_solver.cpp:138] Iteration 120010, lr = 1e-06
I0722 15:04:15.314013 23230 solver.cpp:243] Iteration 120020, loss = 2.54548
I0722 15:04:15.314359 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02017 (* 1 = 2.02017 loss)
I0722 15:04:15.314450 23230 sgd_solver.cpp:138] Iteration 120020, lr = 1e-06
I0722 15:05:40.428076 23230 solver.cpp:243] Iteration 120030, loss = 2.33282
I0722 15:05:40.428367 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78863 (* 1 = 2.78863 loss)
I0722 15:05:40.428480 23230 sgd_solver.cpp:138] Iteration 120030, lr = 1e-06
I0722 15:07:08.750392 23230 solver.cpp:243] Iteration 120040, loss = 2.5935
I0722 15:07:08.750672 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.71166 (* 1 = 1.71166 loss)
I0722 15:07:08.750753 23230 sgd_solver.cpp:138] Iteration 120040, lr = 1e-06
I0722 15:08:35.181972 23230 solver.cpp:243] Iteration 120050, loss = 2.50137
I0722 15:08:35.182323 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20933 (* 1 = 1.20933 loss)
I0722 15:08:35.182456 23230 sgd_solver.cpp:138] Iteration 120050, lr = 1e-06
I0722 15:09:58.929283 23230 solver.cpp:243] Iteration 120060, loss = 2.59492
I0722 15:09:58.929626 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.09096 (* 1 = 2.09096 loss)
I0722 15:09:58.929735 23230 sgd_solver.cpp:138] Iteration 120060, lr = 1e-06
I0722 15:11:24.900192 23230 solver.cpp:243] Iteration 120070, loss = 2.49915
I0722 15:11:24.900444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.65917 (* 1 = 2.65917 loss)
I0722 15:11:24.900488 23230 sgd_solver.cpp:138] Iteration 120070, lr = 1e-06
I0722 15:12:53.298611 23230 solver.cpp:243] Iteration 120080, loss = 2.83309
I0722 15:12:53.298861 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.26343 (* 1 = 4.26343 loss)
I0722 15:12:54.161494 23230 sgd_solver.cpp:138] Iteration 120080, lr = 1e-06
I0722 15:14:20.178984 23230 solver.cpp:243] Iteration 120090, loss = 2.51338
I0722 15:14:20.179258 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82492 (* 1 = 1.82492 loss)
I0722 15:14:20.179361 23230 sgd_solver.cpp:138] Iteration 120090, lr = 1e-06
I0722 15:15:46.558439 23230 solver.cpp:243] Iteration 120100, loss = 2.48361
I0722 15:15:46.558758 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.23687 (* 1 = 1.23687 loss)
I0722 15:15:47.658246 23230 sgd_solver.cpp:138] Iteration 120100, lr = 1e-06
I0722 15:17:14.603499 23230 solver.cpp:243] Iteration 120110, loss = 2.49853
I0722 15:17:14.603724 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.49126 (* 1 = 2.49126 loss)
I0722 15:17:14.603770 23230 sgd_solver.cpp:138] Iteration 120110, lr = 1e-06
I0722 15:18:42.470479 23230 solver.cpp:243] Iteration 120120, loss = 2.48141
I0722 15:18:42.470738 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.51462 (* 1 = 3.51462 loss)
I0722 15:18:43.809538 23230 sgd_solver.cpp:138] Iteration 120120, lr = 1e-06
I0722 15:20:10.460485 23230 solver.cpp:243] Iteration 120130, loss = 2.62746
I0722 15:20:10.460750 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8711 (* 1 = 2.8711 loss)
I0722 15:20:10.851220 23230 sgd_solver.cpp:138] Iteration 120130, lr = 1e-06
I0722 15:21:39.702311 23230 solver.cpp:243] Iteration 120140, loss = 2.40554
I0722 15:21:39.702551 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93787 (* 1 = 2.93787 loss)
I0722 15:21:39.702595 23230 sgd_solver.cpp:138] Iteration 120140, lr = 1e-06
I0722 15:23:08.503412 23230 solver.cpp:243] Iteration 120150, loss = 2.43557
I0722 15:23:08.503662 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20578 (* 1 = 1.20578 loss)
I0722 15:23:08.503707 23230 sgd_solver.cpp:138] Iteration 120150, lr = 1e-06
I0722 15:24:32.841861 23230 solver.cpp:243] Iteration 120160, loss = 2.62701
I0722 15:24:32.842164 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73759 (* 1 = 2.73759 loss)
I0722 15:24:33.252439 23230 sgd_solver.cpp:138] Iteration 120160, lr = 1e-06
I0722 15:25:59.099907 23230 solver.cpp:243] Iteration 120170, loss = 2.64104
I0722 15:25:59.100164 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.09379 (* 1 = 2.09379 loss)
I0722 15:25:59.469832 23230 sgd_solver.cpp:138] Iteration 120170, lr = 1e-06
I0722 15:27:23.216884 23230 solver.cpp:243] Iteration 120180, loss = 2.75663
I0722 15:27:23.217255 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.28656 (* 1 = 3.28656 loss)
I0722 15:27:23.217348 23230 sgd_solver.cpp:138] Iteration 120180, lr = 1e-06
I0722 15:28:49.842356 23230 solver.cpp:243] Iteration 120190, loss = 2.46771
I0722 15:28:49.842592 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.20939 (* 1 = 1.20939 loss)
I0722 15:28:49.842643 23230 sgd_solver.cpp:138] Iteration 120190, lr = 1e-06
I0722 15:30:11.154814 23230 solver.cpp:243] Iteration 120200, loss = 2.50203
I0722 15:30:11.155138 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.62495 (* 1 = 2.62495 loss)
I0722 15:30:11.526185 23230 sgd_solver.cpp:138] Iteration 120200, lr = 1e-06
I0722 15:31:37.298234 23230 solver.cpp:243] Iteration 120210, loss = 2.47078
I0722 15:31:37.298573 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35095 (* 1 = 2.35095 loss)
I0722 15:31:38.117046 23230 sgd_solver.cpp:138] Iteration 120210, lr = 1e-06
I0722 15:33:02.032994 23230 solver.cpp:243] Iteration 120220, loss = 2.41411
I0722 15:33:02.033311 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85041 (* 1 = 2.85041 loss)
I0722 15:33:02.033397 23230 sgd_solver.cpp:138] Iteration 120220, lr = 1e-06
I0722 15:34:26.880882 23230 solver.cpp:243] Iteration 120230, loss = 2.58768
I0722 15:34:26.881216 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0681 (* 1 = 2.0681 loss)
I0722 15:34:26.881319 23230 sgd_solver.cpp:138] Iteration 120230, lr = 1e-06
I0722 15:35:51.718119 23230 solver.cpp:243] Iteration 120240, loss = 2.58104
I0722 15:35:51.718420 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10982 (* 1 = 2.10982 loss)
I0722 15:35:51.718516 23230 sgd_solver.cpp:138] Iteration 120240, lr = 1e-06
I0722 15:37:20.076921 23230 solver.cpp:243] Iteration 120250, loss = 2.44619
I0722 15:37:20.077148 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.89567 (* 1 = 3.89567 loss)
I0722 15:37:20.450683 23230 sgd_solver.cpp:138] Iteration 120250, lr = 1e-06
I0722 15:38:47.590602 23230 solver.cpp:243] Iteration 120260, loss = 2.57578
I0722 15:38:47.590869 23230 solver.cpp:259]     Train net output #0: mbox_loss = 8.04147 (* 1 = 8.04147 loss)
I0722 15:38:47.590930 23230 sgd_solver.cpp:138] Iteration 120260, lr = 1e-06
I0722 15:40:14.343080 23230 solver.cpp:243] Iteration 120270, loss = 2.58256
I0722 15:40:14.343379 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.57363 (* 1 = 4.57363 loss)
I0722 15:40:14.343466 23230 sgd_solver.cpp:138] Iteration 120270, lr = 1e-06
I0722 15:41:38.506275 23230 solver.cpp:243] Iteration 120280, loss = 2.55676
I0722 15:41:38.506533 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.92439 (* 1 = 3.92439 loss)
I0722 15:41:39.251313 23230 sgd_solver.cpp:138] Iteration 120280, lr = 1e-06
I0722 15:43:02.500102 23230 solver.cpp:243] Iteration 120290, loss = 2.52237
I0722 15:43:02.500308 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.6959 (* 1 = 1.6959 loss)
I0722 15:43:02.500365 23230 sgd_solver.cpp:138] Iteration 120290, lr = 1e-06
I0722 15:44:28.931409 23230 solver.cpp:243] Iteration 120300, loss = 2.33085
I0722 15:44:28.931648 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.69222 (* 1 = 3.69222 loss)
I0722 15:44:28.931689 23230 sgd_solver.cpp:138] Iteration 120300, lr = 1e-06
I0722 15:45:53.350106 23230 solver.cpp:243] Iteration 120310, loss = 2.74024
I0722 15:45:53.350406 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76855 (* 1 = 3.76855 loss)
I0722 15:45:53.350502 23230 sgd_solver.cpp:138] Iteration 120310, lr = 1e-06
I0722 15:47:14.950518 23230 solver.cpp:243] Iteration 120320, loss = 2.88496
I0722 15:47:14.950784 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73562 (* 1 = 2.73562 loss)
I0722 15:47:14.950825 23230 sgd_solver.cpp:138] Iteration 120320, lr = 1e-06
I0722 15:48:37.352571 23230 solver.cpp:243] Iteration 120330, loss = 2.6827
I0722 15:48:37.352895 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27902 (* 1 = 2.27902 loss)
I0722 15:48:37.352982 23230 sgd_solver.cpp:138] Iteration 120330, lr = 1e-06
I0722 15:50:05.776973 23230 solver.cpp:243] Iteration 120340, loss = 2.30605
I0722 15:50:05.777282 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15631 (* 1 = 2.15631 loss)
I0722 15:50:05.777390 23230 sgd_solver.cpp:138] Iteration 120340, lr = 1e-06
I0722 15:51:27.969075 23230 solver.cpp:243] Iteration 120350, loss = 2.40935
I0722 15:51:27.969411 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35165 (* 1 = 2.35165 loss)
I0722 15:51:27.969517 23230 sgd_solver.cpp:138] Iteration 120350, lr = 1e-06
I0722 15:52:52.005035 23230 solver.cpp:243] Iteration 120360, loss = 2.69222
I0722 15:52:52.005347 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05439 (* 1 = 2.05439 loss)
I0722 15:52:52.005422 23230 sgd_solver.cpp:138] Iteration 120360, lr = 1e-06
I0722 15:54:17.808465 23230 solver.cpp:243] Iteration 120370, loss = 2.58519
I0722 15:54:17.808703 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.75813 (* 1 = 1.75813 loss)
I0722 15:54:17.808748 23230 sgd_solver.cpp:138] Iteration 120370, lr = 1e-06
I0722 15:55:45.011915 23230 solver.cpp:243] Iteration 120380, loss = 2.37988
I0722 15:55:45.012141 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9271 (* 1 = 1.9271 loss)
I0722 15:55:45.012213 23230 sgd_solver.cpp:138] Iteration 120380, lr = 1e-06
I0722 15:57:11.734314 23230 solver.cpp:243] Iteration 120390, loss = 2.52641
I0722 15:57:11.734622 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80054 (* 1 = 2.80054 loss)
I0722 15:57:11.734740 23230 sgd_solver.cpp:138] Iteration 120390, lr = 1e-06
I0722 15:58:35.658732 23230 solver.cpp:243] Iteration 120400, loss = 2.58486
I0722 15:58:35.658951 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.39813 (* 1 = 3.39813 loss)
I0722 15:58:35.658994 23230 sgd_solver.cpp:138] Iteration 120400, lr = 1e-06
I0722 16:00:00.728400 23230 solver.cpp:243] Iteration 120410, loss = 2.29813
I0722 16:00:00.728720 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.28504 (* 1 = 2.28504 loss)
I0722 16:00:00.728842 23230 sgd_solver.cpp:138] Iteration 120410, lr = 1e-06
I0722 16:01:25.064472 23230 solver.cpp:243] Iteration 120420, loss = 2.58696
I0722 16:01:25.064749 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.1252 (* 1 = 1.1252 loss)
I0722 16:01:25.064846 23230 sgd_solver.cpp:138] Iteration 120420, lr = 1e-06
I0722 16:02:52.702219 23230 solver.cpp:243] Iteration 120430, loss = 2.5512
I0722 16:02:52.702453 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04499 (* 1 = 3.04499 loss)
I0722 16:02:52.702502 23230 sgd_solver.cpp:138] Iteration 120430, lr = 1e-06
I0722 16:04:18.873167 23230 solver.cpp:243] Iteration 120440, loss = 2.70026
I0722 16:04:18.873451 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.18984 (* 1 = 3.18984 loss)
I0722 16:04:18.873562 23230 sgd_solver.cpp:138] Iteration 120440, lr = 1e-06
I0722 16:05:44.206545 23230 solver.cpp:243] Iteration 120450, loss = 2.56978
I0722 16:05:44.206822 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69528 (* 1 = 1.69528 loss)
I0722 16:05:45.047847 23230 sgd_solver.cpp:138] Iteration 120450, lr = 1e-06
I0722 16:07:07.751920 23230 solver.cpp:243] Iteration 120460, loss = 2.69092
I0722 16:07:07.752208 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.43774 (* 1 = 2.43774 loss)
I0722 16:07:07.752262 23230 sgd_solver.cpp:138] Iteration 120460, lr = 1e-06
I0722 16:08:32.726702 23230 solver.cpp:243] Iteration 120470, loss = 2.61002
I0722 16:08:32.726955 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.04218 (* 1 = 2.04218 loss)
I0722 16:08:32.726995 23230 sgd_solver.cpp:138] Iteration 120470, lr = 1e-06
I0722 16:09:56.348358 23230 solver.cpp:243] Iteration 120480, loss = 2.6659
I0722 16:09:56.348654 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37817 (* 1 = 3.37817 loss)
I0722 16:09:56.348759 23230 sgd_solver.cpp:138] Iteration 120480, lr = 1e-06
I0722 16:11:25.364766 23230 solver.cpp:243] Iteration 120490, loss = 2.56944
I0722 16:11:25.365087 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.97214 (* 1 = 2.97214 loss)
I0722 16:11:25.365134 23230 sgd_solver.cpp:138] Iteration 120490, lr = 1e-06
I0722 16:12:51.278857 23230 solver.cpp:243] Iteration 120500, loss = 2.4802
I0722 16:12:51.280040 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50598 (* 1 = 2.50598 loss)
I0722 16:12:51.280095 23230 sgd_solver.cpp:138] Iteration 120500, lr = 1e-06
I0722 16:14:18.797917 23230 solver.cpp:243] Iteration 120510, loss = 2.70286
I0722 16:14:18.798249 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7149 (* 1 = 2.7149 loss)
I0722 16:14:18.798362 23230 sgd_solver.cpp:138] Iteration 120510, lr = 1e-06
I0722 16:15:46.181711 23230 solver.cpp:243] Iteration 120520, loss = 2.37502
I0722 16:15:46.182718 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.33829 (* 1 = 5.33829 loss)
I0722 16:15:46.182763 23230 sgd_solver.cpp:138] Iteration 120520, lr = 1e-06
I0722 16:17:14.084482 23230 solver.cpp:243] Iteration 120530, loss = 2.59049
I0722 16:17:14.084750 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.81391 (* 1 = 3.81391 loss)
I0722 16:17:14.561501 23230 sgd_solver.cpp:138] Iteration 120530, lr = 1e-06
I0722 16:18:41.457547 23230 solver.cpp:243] Iteration 120540, loss = 2.40874
I0722 16:18:41.457854 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.36581 (* 1 = 3.36581 loss)
I0722 16:18:41.457937 23230 sgd_solver.cpp:138] Iteration 120540, lr = 1e-06
I0722 16:20:02.029001 23230 solver.cpp:243] Iteration 120550, loss = 2.78141
I0722 16:20:02.029279 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.54502 (* 1 = 1.54502 loss)
I0722 16:20:02.029357 23230 sgd_solver.cpp:138] Iteration 120550, lr = 1e-06
I0722 16:21:29.786428 23230 solver.cpp:243] Iteration 120560, loss = 2.47849
I0722 16:21:29.786700 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.05461 (* 1 = 4.05461 loss)
I0722 16:21:29.786809 23230 sgd_solver.cpp:138] Iteration 120560, lr = 1e-06
I0722 16:22:56.775043 23230 solver.cpp:243] Iteration 120570, loss = 2.44939
I0722 16:22:56.775310 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.54824 (* 1 = 2.54824 loss)
I0722 16:22:56.775354 23230 sgd_solver.cpp:138] Iteration 120570, lr = 1e-06
I0722 16:24:23.067258 23230 solver.cpp:243] Iteration 120580, loss = 2.74513
I0722 16:24:23.067489 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02239 (* 1 = 2.02239 loss)
I0722 16:24:23.441052 23230 sgd_solver.cpp:138] Iteration 120580, lr = 1e-06
I0722 16:25:46.893791 23230 solver.cpp:243] Iteration 120590, loss = 2.74576
I0722 16:25:46.894028 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.07423 (* 1 = 3.07423 loss)
I0722 16:25:46.894078 23230 sgd_solver.cpp:138] Iteration 120590, lr = 1e-06
I0722 16:27:12.716945 23230 solver.cpp:243] Iteration 120600, loss = 2.74992
I0722 16:27:12.717231 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15462 (* 1 = 2.15462 loss)
I0722 16:27:13.082420 23230 sgd_solver.cpp:138] Iteration 120600, lr = 1e-06
I0722 16:28:36.405491 23230 solver.cpp:243] Iteration 120610, loss = 2.47162
I0722 16:28:36.405802 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.51073 (* 1 = 3.51073 loss)
I0722 16:28:36.405877 23230 sgd_solver.cpp:138] Iteration 120610, lr = 1e-06
I0722 16:30:01.188552 23230 solver.cpp:243] Iteration 120620, loss = 2.49673
I0722 16:30:01.191370 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.857482 (* 1 = 0.857482 loss)
I0722 16:30:01.191476 23230 sgd_solver.cpp:138] Iteration 120620, lr = 1e-06
I0722 16:31:26.282254 23230 solver.cpp:243] Iteration 120630, loss = 2.5741
I0722 16:31:26.283532 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10947 (* 1 = 2.10947 loss)
I0722 16:31:26.283586 23230 sgd_solver.cpp:138] Iteration 120630, lr = 1e-06
I0722 16:32:48.820984 23230 solver.cpp:243] Iteration 120640, loss = 2.4721
I0722 16:32:48.821297 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.38015 (* 1 = 1.38015 loss)
I0722 16:32:48.821346 23230 sgd_solver.cpp:138] Iteration 120640, lr = 1e-06
I0722 16:34:15.066797 23230 solver.cpp:243] Iteration 120650, loss = 2.4051
I0722 16:34:15.067090 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.02409 (* 1 = 3.02409 loss)
I0722 16:34:15.423211 23230 sgd_solver.cpp:138] Iteration 120650, lr = 1e-06
I0722 16:35:42.871193 23230 solver.cpp:243] Iteration 120660, loss = 2.5852
I0722 16:35:42.871467 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.1515 (* 1 = 3.1515 loss)
I0722 16:35:42.871577 23230 sgd_solver.cpp:138] Iteration 120660, lr = 1e-06
I0722 16:37:09.153673 23230 solver.cpp:243] Iteration 120670, loss = 2.57242
I0722 16:37:09.153954 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.30525 (* 1 = 1.30525 loss)
I0722 16:37:09.154004 23230 sgd_solver.cpp:138] Iteration 120670, lr = 1e-06
I0722 16:38:35.602450 23230 solver.cpp:243] Iteration 120680, loss = 2.37437
I0722 16:38:35.602689 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.63458 (* 1 = 1.63458 loss)
I0722 16:38:35.602726 23230 sgd_solver.cpp:138] Iteration 120680, lr = 1e-06
I0722 16:39:59.603348 23230 solver.cpp:243] Iteration 120690, loss = 2.53559
I0722 16:39:59.603606 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08534 (* 1 = 3.08534 loss)
I0722 16:40:00.009176 23230 sgd_solver.cpp:138] Iteration 120690, lr = 1e-06
I0722 16:41:24.556380 23230 solver.cpp:243] Iteration 120700, loss = 2.77769
I0722 16:41:24.556612 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26872 (* 1 = 2.26872 loss)
I0722 16:41:24.556659 23230 sgd_solver.cpp:138] Iteration 120700, lr = 1e-06
I0722 16:42:50.472369 23230 solver.cpp:243] Iteration 120710, loss = 2.42265
I0722 16:42:50.472666 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.21065 (* 1 = 4.21065 loss)
I0722 16:42:50.472740 23230 sgd_solver.cpp:138] Iteration 120710, lr = 1e-06
I0722 16:44:18.115407 23230 solver.cpp:243] Iteration 120720, loss = 2.38052
I0722 16:44:18.115713 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.978495 (* 1 = 0.978495 loss)
I0722 16:44:18.115803 23230 sgd_solver.cpp:138] Iteration 120720, lr = 1e-06
I0722 16:45:43.110380 23230 solver.cpp:243] Iteration 120730, loss = 2.50444
I0722 16:45:43.110661 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.55717 (* 1 = 1.55717 loss)
I0722 16:45:43.110769 23230 sgd_solver.cpp:138] Iteration 120730, lr = 1e-06
I0722 16:47:08.603163 23230 solver.cpp:243] Iteration 120740, loss = 2.7958
I0722 16:47:08.603447 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.59152 (* 1 = 4.59152 loss)
I0722 16:47:09.357334 23230 sgd_solver.cpp:138] Iteration 120740, lr = 1e-06
I0722 16:48:35.369732 23230 solver.cpp:243] Iteration 120750, loss = 2.4795
I0722 16:48:35.369966 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2765 (* 1 = 2.2765 loss)
I0722 16:48:35.370009 23230 sgd_solver.cpp:138] Iteration 120750, lr = 1e-06
I0722 16:50:01.191952 23230 solver.cpp:243] Iteration 120760, loss = 2.49591
I0722 16:50:01.192193 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.56575 (* 1 = 2.56575 loss)
I0722 16:50:01.192235 23230 sgd_solver.cpp:138] Iteration 120760, lr = 1e-06
I0722 16:51:27.092502 23230 solver.cpp:243] Iteration 120770, loss = 2.65846
I0722 16:51:27.092749 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.72223 (* 1 = 3.72223 loss)
I0722 16:51:27.092788 23230 sgd_solver.cpp:138] Iteration 120770, lr = 1e-06
I0722 16:52:51.532033 23230 solver.cpp:243] Iteration 120780, loss = 2.63198
I0722 16:52:51.532340 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.89143 (* 1 = 1.89143 loss)
I0722 16:52:51.891542 23230 sgd_solver.cpp:138] Iteration 120780, lr = 1e-06
I0722 16:54:19.888015 23230 solver.cpp:243] Iteration 120790, loss = 2.50881
I0722 16:54:19.888252 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85371 (* 1 = 1.85371 loss)
I0722 16:54:19.888301 23230 sgd_solver.cpp:138] Iteration 120790, lr = 1e-06
I0722 16:55:47.440488 23230 solver.cpp:243] Iteration 120800, loss = 2.55866
I0722 16:55:47.440860 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.52163 (* 1 = 1.52163 loss)
I0722 16:55:47.804814 23230 sgd_solver.cpp:138] Iteration 120800, lr = 1e-06
I0722 16:57:15.303622 23230 solver.cpp:243] Iteration 120810, loss = 2.79809
I0722 16:57:15.303874 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93885 (* 1 = 2.93885 loss)
I0722 16:57:15.303921 23230 sgd_solver.cpp:138] Iteration 120810, lr = 1e-06
I0722 16:58:41.704571 23230 solver.cpp:243] Iteration 120820, loss = 2.69036
I0722 16:58:41.704780 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35134 (* 1 = 2.35134 loss)
I0722 16:58:41.704828 23230 sgd_solver.cpp:138] Iteration 120820, lr = 1e-06
I0722 17:00:08.486914 23230 solver.cpp:243] Iteration 120830, loss = 2.29854
I0722 17:00:08.487231 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.73586 (* 1 = 1.73586 loss)
I0722 17:00:08.487326 23230 sgd_solver.cpp:138] Iteration 120830, lr = 1e-06
I0722 17:01:33.399802 23230 solver.cpp:243] Iteration 120840, loss = 2.55988
I0722 17:01:33.400060 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.90251 (* 1 = 3.90251 loss)
I0722 17:01:34.478448 23230 sgd_solver.cpp:138] Iteration 120840, lr = 1e-06
I0722 17:02:59.444500 23230 solver.cpp:243] Iteration 120850, loss = 2.49323
I0722 17:02:59.444756 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.76994 (* 1 = 1.76994 loss)
I0722 17:03:00.178649 23230 sgd_solver.cpp:138] Iteration 120850, lr = 1e-06
I0722 17:04:28.925137 23230 solver.cpp:243] Iteration 120860, loss = 2.65285
I0722 17:04:28.925365 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.6282 (* 1 = 3.6282 loss)
I0722 17:04:28.925407 23230 sgd_solver.cpp:138] Iteration 120860, lr = 1e-06
I0722 17:05:54.776480 23230 solver.cpp:243] Iteration 120870, loss = 2.43274
I0722 17:05:54.777012 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.92618 (* 1 = 1.92618 loss)
I0722 17:05:55.134093 23230 sgd_solver.cpp:138] Iteration 120870, lr = 1e-06
I0722 17:07:20.409309 23230 solver.cpp:243] Iteration 120880, loss = 2.52993
I0722 17:07:20.409610 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.03989 (* 1 = 1.03989 loss)
I0722 17:07:20.409749 23230 sgd_solver.cpp:138] Iteration 120880, lr = 1e-06
I0722 17:08:47.602071 23230 solver.cpp:243] Iteration 120890, loss = 2.59988
I0722 17:08:47.602367 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.17557 (* 1 = 1.17557 loss)
I0722 17:08:47.602468 23230 sgd_solver.cpp:138] Iteration 120890, lr = 1e-06
I0722 17:10:13.167356 23230 solver.cpp:243] Iteration 120900, loss = 2.70265
I0722 17:10:13.167661 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.54638 (* 1 = 3.54638 loss)
I0722 17:10:13.526011 23230 sgd_solver.cpp:138] Iteration 120900, lr = 1e-06
I0722 17:11:38.310640 23230 solver.cpp:243] Iteration 120910, loss = 2.36541
I0722 17:11:38.310938 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.74822 (* 1 = 1.74822 loss)
I0722 17:11:38.311055 23230 sgd_solver.cpp:138] Iteration 120910, lr = 1e-06
I0722 17:13:02.265141 23230 solver.cpp:243] Iteration 120920, loss = 2.40045
I0722 17:13:02.265460 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.67691 (* 1 = 1.67691 loss)
I0722 17:13:03.071815 23230 sgd_solver.cpp:138] Iteration 120920, lr = 1e-06
I0722 17:14:28.644327 23230 solver.cpp:243] Iteration 120930, loss = 2.62949
I0722 17:14:28.644680 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.68894 (* 1 = 1.68894 loss)
I0722 17:14:29.602761 23230 sgd_solver.cpp:138] Iteration 120930, lr = 1e-06
I0722 17:15:56.109740 23230 solver.cpp:243] Iteration 120940, loss = 2.76843
I0722 17:15:56.110078 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.51626 (* 1 = 2.51626 loss)
I0722 17:15:56.110179 23230 sgd_solver.cpp:138] Iteration 120940, lr = 1e-06
I0722 17:17:20.415701 23230 solver.cpp:243] Iteration 120950, loss = 2.41787
I0722 17:17:20.415969 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.22934 (* 1 = 1.22934 loss)
I0722 17:17:20.416013 23230 sgd_solver.cpp:138] Iteration 120950, lr = 1e-06
I0722 17:18:42.891224 23230 solver.cpp:243] Iteration 120960, loss = 2.64845
I0722 17:18:42.891468 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.62933 (* 1 = 4.62933 loss)
I0722 17:18:43.332594 23230 sgd_solver.cpp:138] Iteration 120960, lr = 1e-06
I0722 17:20:10.492542 23230 solver.cpp:243] Iteration 120970, loss = 2.46661
I0722 17:20:10.492854 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.84527 (* 1 = 1.84527 loss)
I0722 17:20:10.492940 23230 sgd_solver.cpp:138] Iteration 120970, lr = 1e-06
I0722 17:21:33.767604 23230 solver.cpp:243] Iteration 120980, loss = 2.4176
I0722 17:21:33.767927 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.47313 (* 1 = 3.47313 loss)
I0722 17:21:33.768038 23230 sgd_solver.cpp:138] Iteration 120980, lr = 1e-06
I0722 17:23:01.564939 23230 solver.cpp:243] Iteration 120990, loss = 2.4985
I0722 17:23:01.565253 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.66805 (* 1 = 2.66805 loss)
I0722 17:23:01.565347 23230 sgd_solver.cpp:138] Iteration 120990, lr = 1e-06
I0722 17:24:20.175467 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_121000.caffemodel
I0722 17:24:20.646497 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_121000.solverstate
I0722 17:24:20.843894 23230 solver.cpp:433] Iteration 121000, Testing net (#0)
I0722 17:24:20.844084 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 17:24:24.153892 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.623669
I0722 17:24:32.098188 23230 solver.cpp:243] Iteration 121000, loss = 2.61205
I0722 17:24:32.098301 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.56056 (* 1 = 1.56056 loss)
I0722 17:24:32.855584 23230 sgd_solver.cpp:138] Iteration 121000, lr = 1e-06
I0722 17:25:58.125989 23230 solver.cpp:243] Iteration 121010, loss = 2.44676
I0722 17:25:58.126291 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.18337 (* 1 = 4.18337 loss)
I0722 17:25:58.126353 23230 sgd_solver.cpp:138] Iteration 121010, lr = 1e-06
I0722 17:27:24.204960 23230 solver.cpp:243] Iteration 121020, loss = 2.58341
I0722 17:27:24.205267 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38501 (* 1 = 2.38501 loss)
I0722 17:27:24.205363 23230 sgd_solver.cpp:138] Iteration 121020, lr = 1e-06
I0722 17:28:47.940542 23230 solver.cpp:243] Iteration 121030, loss = 2.75665
I0722 17:28:47.940811 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69675 (* 1 = 1.69675 loss)
I0722 17:28:47.940913 23230 sgd_solver.cpp:138] Iteration 121030, lr = 1e-06
I0722 17:30:14.614858 23230 solver.cpp:243] Iteration 121040, loss = 2.789
I0722 17:30:14.615124 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.17159 (* 1 = 1.17159 loss)
I0722 17:30:14.615206 23230 sgd_solver.cpp:138] Iteration 121040, lr = 1e-06
I0722 17:31:41.910832 23230 solver.cpp:243] Iteration 121050, loss = 2.57138
I0722 17:31:41.911093 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27443 (* 1 = 3.27443 loss)
I0722 17:31:42.891297 23230 sgd_solver.cpp:138] Iteration 121050, lr = 1e-06
I0722 17:33:10.154732 23230 solver.cpp:243] Iteration 121060, loss = 2.62756
I0722 17:33:10.155050 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 17:33:10.155149 23230 sgd_solver.cpp:138] Iteration 121060, lr = 1e-06
I0722 17:34:34.596771 23230 solver.cpp:243] Iteration 121070, loss = 2.67195
I0722 17:34:34.597017 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46317 (* 1 = 1.46317 loss)
I0722 17:34:34.597061 23230 sgd_solver.cpp:138] Iteration 121070, lr = 1e-06
I0722 17:35:57.803884 23230 solver.cpp:243] Iteration 121080, loss = 2.62875
I0722 17:35:57.804157 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.30942 (* 1 = 1.30942 loss)
I0722 17:35:57.804203 23230 sgd_solver.cpp:138] Iteration 121080, lr = 1e-06
I0722 17:37:24.952493 23230 solver.cpp:243] Iteration 121090, loss = 2.48408
I0722 17:37:24.952860 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25225 (* 1 = 1.25225 loss)
I0722 17:37:24.952962 23230 sgd_solver.cpp:138] Iteration 121090, lr = 1e-06
I0722 17:38:49.843619 23230 solver.cpp:243] Iteration 121100, loss = 2.55814
I0722 17:38:49.843870 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.79093 (* 1 = 3.79093 loss)
I0722 17:38:50.212591 23230 sgd_solver.cpp:138] Iteration 121100, lr = 1e-06
I0722 17:40:15.280992 23230 solver.cpp:243] Iteration 121110, loss = 2.76551
I0722 17:40:15.281213 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27426 (* 1 = 2.27426 loss)
I0722 17:40:15.281263 23230 sgd_solver.cpp:138] Iteration 121110, lr = 1e-06
I0722 17:41:42.045104 23230 solver.cpp:243] Iteration 121120, loss = 2.80136
I0722 17:41:42.045416 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.09041 (* 1 = 3.09041 loss)
I0722 17:41:42.045506 23230 sgd_solver.cpp:138] Iteration 121120, lr = 1e-06
I0722 17:43:07.360016 23230 solver.cpp:243] Iteration 121130, loss = 2.41205
I0722 17:43:07.360260 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61555 (* 1 = 2.61555 loss)
I0722 17:43:07.360298 23230 sgd_solver.cpp:138] Iteration 121130, lr = 1e-06
I0722 17:44:32.997787 23230 solver.cpp:243] Iteration 121140, loss = 2.48378
I0722 17:44:32.998021 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.35401 (* 1 = 4.35401 loss)
I0722 17:44:32.998075 23230 sgd_solver.cpp:138] Iteration 121140, lr = 1e-06
I0722 17:45:59.706349 23230 solver.cpp:243] Iteration 121150, loss = 2.59979
I0722 17:45:59.706749 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.07647 (* 1 = 1.07647 loss)
I0722 17:46:00.786689 23230 sgd_solver.cpp:138] Iteration 121150, lr = 1e-06
I0722 17:47:27.584026 23230 solver.cpp:243] Iteration 121160, loss = 2.57162
I0722 17:47:27.584307 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.92618 (* 1 = 1.92618 loss)
I0722 17:47:27.584414 23230 sgd_solver.cpp:138] Iteration 121160, lr = 1e-06
I0722 17:48:56.076107 23230 solver.cpp:243] Iteration 121170, loss = 2.38611
I0722 17:48:56.076439 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82717 (* 1 = 1.82717 loss)
I0722 17:48:56.076565 23230 sgd_solver.cpp:138] Iteration 121170, lr = 1e-06
I0722 17:50:19.136785 23230 solver.cpp:243] Iteration 121180, loss = 2.50853
I0722 17:50:19.137154 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.35535 (* 1 = 1.35535 loss)
I0722 17:50:19.882105 23230 sgd_solver.cpp:138] Iteration 121180, lr = 1e-06
I0722 17:51:48.555706 23230 solver.cpp:243] Iteration 121190, loss = 2.55056
I0722 17:51:48.556030 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46842 (* 1 = 1.46842 loss)
I0722 17:51:48.556154 23230 sgd_solver.cpp:138] Iteration 121190, lr = 1e-06
I0722 17:53:13.944422 23230 solver.cpp:243] Iteration 121200, loss = 2.60953
I0722 17:53:13.944723 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57841 (* 1 = 2.57841 loss)
I0722 17:53:13.944823 23230 sgd_solver.cpp:138] Iteration 121200, lr = 1e-06
I0722 17:54:42.516824 23230 solver.cpp:243] Iteration 121210, loss = 2.78766
I0722 17:54:42.517076 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.17018 (* 1 = 4.17018 loss)
I0722 17:54:42.517112 23230 sgd_solver.cpp:138] Iteration 121210, lr = 1e-06
I0722 17:56:10.423697 23230 solver.cpp:243] Iteration 121220, loss = 2.70358
I0722 17:56:10.423943 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45778 (* 1 = 1.45778 loss)
I0722 17:56:10.424000 23230 sgd_solver.cpp:138] Iteration 121220, lr = 1e-06
I0722 17:57:35.781985 23230 solver.cpp:243] Iteration 121230, loss = 2.47055
I0722 17:57:35.782236 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.06625 (* 1 = 2.06625 loss)
I0722 17:57:36.784502 23230 sgd_solver.cpp:138] Iteration 121230, lr = 1e-06
I0722 17:59:04.451159 23230 solver.cpp:243] Iteration 121240, loss = 2.7372
I0722 17:59:04.451452 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.28735 (* 1 = 2.28735 loss)
I0722 17:59:04.451503 23230 sgd_solver.cpp:138] Iteration 121240, lr = 1e-06
I0722 18:00:31.688140 23230 solver.cpp:243] Iteration 121250, loss = 2.38623
I0722 18:00:31.688431 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3136 (* 1 = 2.3136 loss)
I0722 18:00:31.688521 23230 sgd_solver.cpp:138] Iteration 121250, lr = 1e-06
I0722 18:01:55.885995 23230 solver.cpp:243] Iteration 121260, loss = 2.64325
I0722 18:01:55.886307 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08856 (* 1 = 3.08856 loss)
I0722 18:01:55.886411 23230 sgd_solver.cpp:138] Iteration 121260, lr = 1e-06
I0722 18:03:26.627686 23230 solver.cpp:243] Iteration 121270, loss = 2.66699
I0722 18:03:26.628038 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.61839 (* 1 = 1.61839 loss)
I0722 18:03:26.628132 23230 sgd_solver.cpp:138] Iteration 121270, lr = 1e-06
I0722 18:04:52.262928 23230 solver.cpp:243] Iteration 121280, loss = 2.46479
I0722 18:04:52.263195 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.77259 (* 1 = 2.77259 loss)
I0722 18:04:52.263245 23230 sgd_solver.cpp:138] Iteration 121280, lr = 1e-06
I0722 18:06:19.811007 23230 solver.cpp:243] Iteration 121290, loss = 2.67241
I0722 18:06:19.811305 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.32934 (* 1 = 2.32934 loss)
I0722 18:06:19.811413 23230 sgd_solver.cpp:138] Iteration 121290, lr = 1e-06
I0722 18:07:45.897282 23230 solver.cpp:243] Iteration 121300, loss = 2.46369
I0722 18:07:45.897498 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.75094 (* 1 = 1.75094 loss)
I0722 18:07:45.897541 23230 sgd_solver.cpp:138] Iteration 121300, lr = 1e-06
I0722 18:09:13.981163 23230 solver.cpp:243] Iteration 121310, loss = 2.39334
I0722 18:09:13.981438 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.51636 (* 1 = 3.51636 loss)
I0722 18:09:13.981513 23230 sgd_solver.cpp:138] Iteration 121310, lr = 1e-06
I0722 18:10:42.590412 23230 solver.cpp:243] Iteration 121320, loss = 2.47844
I0722 18:10:42.590757 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0703 (* 1 = 2.0703 loss)
I0722 18:10:42.590859 23230 sgd_solver.cpp:138] Iteration 121320, lr = 1e-06
I0722 18:12:10.057618 23230 solver.cpp:243] Iteration 121330, loss = 2.37322
I0722 18:12:10.057888 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0956 (* 1 = 2.0956 loss)
I0722 18:12:10.829298 23230 sgd_solver.cpp:138] Iteration 121330, lr = 1e-06
I0722 18:13:38.123966 23230 solver.cpp:243] Iteration 121340, loss = 2.47899
I0722 18:13:38.124296 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.7132 (* 1 = 3.7132 loss)
I0722 18:13:38.877343 23230 sgd_solver.cpp:138] Iteration 121340, lr = 1e-06
I0722 18:15:01.725062 23230 solver.cpp:243] Iteration 121350, loss = 2.6568
I0722 18:15:01.725294 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40712 (* 1 = 2.40712 loss)
I0722 18:15:03.408861 23230 sgd_solver.cpp:138] Iteration 121350, lr = 1e-06
I0722 18:16:33.174826 23230 solver.cpp:243] Iteration 121360, loss = 2.59237
I0722 18:16:33.175142 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.40126 (* 1 = 3.40126 loss)
I0722 18:16:33.175237 23230 sgd_solver.cpp:138] Iteration 121360, lr = 1e-06
I0722 18:17:59.497210 23230 solver.cpp:243] Iteration 121370, loss = 2.5623
I0722 18:17:59.497545 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47556 (* 1 = 2.47556 loss)
I0722 18:17:59.497642 23230 sgd_solver.cpp:138] Iteration 121370, lr = 1e-06
I0722 18:19:22.236327 23230 solver.cpp:243] Iteration 121380, loss = 2.59223
I0722 18:19:22.236660 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82734 (* 1 = 1.82734 loss)
I0722 18:19:22.236769 23230 sgd_solver.cpp:138] Iteration 121380, lr = 1e-06
I0722 18:20:49.920413 23230 solver.cpp:243] Iteration 121390, loss = 2.53208
I0722 18:20:49.920702 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.00627 (* 1 = 3.00627 loss)
I0722 18:20:49.920759 23230 sgd_solver.cpp:138] Iteration 121390, lr = 1e-06
I0722 18:22:18.295476 23230 solver.cpp:243] Iteration 121400, loss = 2.55215
I0722 18:22:18.295859 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.05104 (* 1 = 6.05104 loss)
I0722 18:22:19.058929 23230 sgd_solver.cpp:138] Iteration 121400, lr = 1e-06
I0722 18:23:44.720566 23230 solver.cpp:243] Iteration 121410, loss = 2.5946
I0722 18:23:44.720819 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.8649 (* 1 = 1.8649 loss)
I0722 18:23:46.047109 23230 sgd_solver.cpp:138] Iteration 121410, lr = 1e-06
I0722 18:25:10.833256 23230 solver.cpp:243] Iteration 121420, loss = 2.59527
I0722 18:25:10.833495 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69178 (* 1 = 2.69178 loss)
I0722 18:25:10.833533 23230 sgd_solver.cpp:138] Iteration 121420, lr = 1e-06
I0722 18:26:36.773675 23230 solver.cpp:243] Iteration 121430, loss = 2.53881
I0722 18:26:36.776135 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.05088 (* 1 = 1.05088 loss)
I0722 18:26:36.776185 23230 sgd_solver.cpp:138] Iteration 121430, lr = 1e-06
I0722 18:28:03.024708 23230 solver.cpp:243] Iteration 121440, loss = 2.46108
I0722 18:28:03.025002 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.56709 (* 1 = 3.56709 loss)
I0722 18:28:03.025097 23230 sgd_solver.cpp:138] Iteration 121440, lr = 1e-06
I0722 18:29:28.325422 23230 solver.cpp:243] Iteration 121450, loss = 2.58737
I0722 18:29:28.325706 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.11726 (* 1 = 2.11726 loss)
I0722 18:29:28.325770 23230 sgd_solver.cpp:138] Iteration 121450, lr = 1e-06
I0722 18:30:55.466852 23230 solver.cpp:243] Iteration 121460, loss = 2.70986
I0722 18:30:55.467070 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.63576 (* 1 = 1.63576 loss)
I0722 18:30:55.467108 23230 sgd_solver.cpp:138] Iteration 121460, lr = 1e-06
I0722 18:32:19.598315 23230 solver.cpp:243] Iteration 121470, loss = 2.30266
I0722 18:32:19.598654 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 18:32:20.483608 23230 sgd_solver.cpp:138] Iteration 121470, lr = 1e-06
I0722 18:33:45.264721 23230 solver.cpp:243] Iteration 121480, loss = 2.44159
I0722 18:33:45.265020 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.46541 (* 1 = 2.46541 loss)
I0722 18:33:45.265142 23230 sgd_solver.cpp:138] Iteration 121480, lr = 1e-06
I0722 18:35:10.416200 23230 solver.cpp:243] Iteration 121490, loss = 2.52612
I0722 18:35:10.416424 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 18:35:10.416476 23230 sgd_solver.cpp:138] Iteration 121490, lr = 1e-06
I0722 18:36:36.300416 23230 solver.cpp:243] Iteration 121500, loss = 2.55324
I0722 18:36:36.300674 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27299 (* 1 = 2.27299 loss)
I0722 18:36:36.668974 23230 sgd_solver.cpp:138] Iteration 121500, lr = 1e-06
I0722 18:38:03.098239 23230 solver.cpp:243] Iteration 121510, loss = 2.54663
I0722 18:38:03.098513 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.38614 (* 1 = 3.38614 loss)
I0722 18:38:03.909332 23230 sgd_solver.cpp:138] Iteration 121510, lr = 1e-06
I0722 18:39:31.143478 23230 solver.cpp:243] Iteration 121520, loss = 2.65118
I0722 18:39:31.143702 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31206 (* 1 = 2.31206 loss)
I0722 18:39:31.143746 23230 sgd_solver.cpp:138] Iteration 121520, lr = 1e-06
I0722 18:40:55.101510 23230 solver.cpp:243] Iteration 121530, loss = 2.26115
I0722 18:40:55.101794 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.28417 (* 1 = 2.28417 loss)
I0722 18:40:55.460841 23230 sgd_solver.cpp:138] Iteration 121530, lr = 1e-06
I0722 18:42:20.948858 23230 solver.cpp:243] Iteration 121540, loss = 2.59167
I0722 18:42:20.949152 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02005 (* 1 = 2.02005 loss)
I0722 18:42:20.949285 23230 sgd_solver.cpp:138] Iteration 121540, lr = 1e-06
I0722 18:43:47.964435 23230 solver.cpp:243] Iteration 121550, loss = 2.58587
I0722 18:43:47.964766 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.00094 (* 1 = 1.00094 loss)
I0722 18:43:47.964871 23230 sgd_solver.cpp:138] Iteration 121550, lr = 1e-06
I0722 18:45:14.703404 23230 solver.cpp:243] Iteration 121560, loss = 2.56731
I0722 18:45:14.703618 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.25794 (* 1 = 3.25794 loss)
I0722 18:45:14.703701 23230 sgd_solver.cpp:138] Iteration 121560, lr = 1e-06
I0722 18:46:42.027623 23230 solver.cpp:243] Iteration 121570, loss = 2.69935
I0722 18:46:42.027971 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.954219 (* 1 = 0.954219 loss)
I0722 18:46:43.464108 23230 sgd_solver.cpp:138] Iteration 121570, lr = 1e-06
I0722 18:48:06.030921 23230 solver.cpp:243] Iteration 121580, loss = 2.27941
I0722 18:48:06.031224 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.77648 (* 1 = 1.77648 loss)
I0722 18:48:06.031298 23230 sgd_solver.cpp:138] Iteration 121580, lr = 1e-06
I0722 18:49:33.562996 23230 solver.cpp:243] Iteration 121590, loss = 2.75034
I0722 18:49:33.563371 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.96002 (* 1 = 1.96002 loss)
I0722 18:49:33.950325 23230 sgd_solver.cpp:138] Iteration 121590, lr = 1e-06
I0722 18:51:00.089756 23230 solver.cpp:243] Iteration 121600, loss = 2.45357
I0722 18:51:00.090551 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.67666 (* 1 = 3.67666 loss)
I0722 18:51:00.090627 23230 sgd_solver.cpp:138] Iteration 121600, lr = 1e-06
I0722 18:52:25.208420 23230 solver.cpp:243] Iteration 121610, loss = 2.49675
I0722 18:52:25.208684 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08706 (* 1 = 3.08706 loss)
I0722 18:52:25.558001 23230 sgd_solver.cpp:138] Iteration 121610, lr = 1e-06
I0722 18:53:50.469305 23230 solver.cpp:243] Iteration 121620, loss = 2.60866
I0722 18:53:50.469599 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.11108 (* 1 = 2.11108 loss)
I0722 18:53:50.469700 23230 sgd_solver.cpp:138] Iteration 121620, lr = 1e-06
I0722 18:55:18.586549 23230 solver.cpp:243] Iteration 121630, loss = 2.43745
I0722 18:55:18.586804 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.14572 (* 1 = 1.14572 loss)
I0722 18:55:19.603883 23230 sgd_solver.cpp:138] Iteration 121630, lr = 1e-06
I0722 18:56:44.288246 23230 solver.cpp:243] Iteration 121640, loss = 2.59956
I0722 18:56:44.288549 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74377 (* 1 = 2.74377 loss)
I0722 18:56:44.288647 23230 sgd_solver.cpp:138] Iteration 121640, lr = 1e-06
I0722 18:58:11.612848 23230 solver.cpp:243] Iteration 121650, loss = 2.52954
I0722 18:58:11.613073 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.16265 (* 1 = 4.16265 loss)
I0722 18:58:11.613116 23230 sgd_solver.cpp:138] Iteration 121650, lr = 1e-06
I0722 18:59:40.183135 23230 solver.cpp:243] Iteration 121660, loss = 2.48354
I0722 18:59:40.183423 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.59458 (* 1 = 1.59458 loss)
I0722 18:59:40.183550 23230 sgd_solver.cpp:138] Iteration 121660, lr = 1e-06
I0722 19:01:08.716989 23230 solver.cpp:243] Iteration 121670, loss = 2.76693
I0722 19:01:08.717245 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.16354 (* 1 = 2.16354 loss)
I0722 19:01:08.717309 23230 sgd_solver.cpp:138] Iteration 121670, lr = 1e-06
I0722 19:02:37.862561 23230 solver.cpp:243] Iteration 121680, loss = 2.54001
I0722 19:02:37.862814 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.01009 (* 1 = 4.01009 loss)
I0722 19:02:37.862874 23230 sgd_solver.cpp:138] Iteration 121680, lr = 1e-06
I0722 19:04:03.841506 23230 solver.cpp:243] Iteration 121690, loss = 2.31188
I0722 19:04:03.841735 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.70716 (* 1 = 3.70716 loss)
I0722 19:04:04.574635 23230 sgd_solver.cpp:138] Iteration 121690, lr = 1e-06
I0722 19:05:32.363859 23230 solver.cpp:243] Iteration 121700, loss = 2.68261
I0722 19:05:32.364087 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.83704 (* 1 = 2.83704 loss)
I0722 19:05:32.364132 23230 sgd_solver.cpp:138] Iteration 121700, lr = 1e-06
I0722 19:07:00.585057 23230 solver.cpp:243] Iteration 121710, loss = 2.51677
I0722 19:07:00.585388 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.04618 (* 1 = 2.04618 loss)
I0722 19:07:00.585441 23230 sgd_solver.cpp:138] Iteration 121710, lr = 1e-06
I0722 19:08:26.358995 23230 solver.cpp:243] Iteration 121720, loss = 2.58132
I0722 19:08:26.359252 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.885 (* 1 = 1.885 loss)
I0722 19:08:26.359292 23230 sgd_solver.cpp:138] Iteration 121720, lr = 1e-06
I0722 19:09:52.455914 23230 solver.cpp:243] Iteration 121730, loss = 2.6376
I0722 19:09:52.456220 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.25208 (* 1 = 2.25208 loss)
I0722 19:09:52.456336 23230 sgd_solver.cpp:138] Iteration 121730, lr = 1e-06
I0722 19:11:18.926546 23230 solver.cpp:243] Iteration 121740, loss = 2.51945
I0722 19:11:18.926862 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.23676 (* 1 = 1.23676 loss)
I0722 19:11:18.926987 23230 sgd_solver.cpp:138] Iteration 121740, lr = 1e-06
I0722 19:12:43.353454 23230 solver.cpp:243] Iteration 121750, loss = 2.63491
I0722 19:12:43.353734 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47504 (* 1 = 2.47504 loss)
I0722 19:12:43.353842 23230 sgd_solver.cpp:138] Iteration 121750, lr = 1e-06
I0722 19:14:09.954576 23230 solver.cpp:243] Iteration 121760, loss = 2.61305
I0722 19:14:09.954757 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.83987 (* 1 = 3.83987 loss)
I0722 19:14:10.316395 23230 sgd_solver.cpp:138] Iteration 121760, lr = 1e-06
I0722 19:15:37.652106 23230 solver.cpp:243] Iteration 121770, loss = 2.44809
I0722 19:15:37.652354 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.54345 (* 1 = 2.54345 loss)
I0722 19:15:37.652395 23230 sgd_solver.cpp:138] Iteration 121770, lr = 1e-06
I0722 19:17:03.975594 23230 solver.cpp:243] Iteration 121780, loss = 2.56348
I0722 19:17:03.975886 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.24742 (* 1 = 3.24742 loss)
I0722 19:17:03.975999 23230 sgd_solver.cpp:138] Iteration 121780, lr = 1e-06
I0722 19:18:29.337602 23230 solver.cpp:243] Iteration 121790, loss = 2.3317
I0722 19:18:29.338459 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2929 (* 1 = 2.2929 loss)
I0722 19:18:29.338513 23230 sgd_solver.cpp:138] Iteration 121790, lr = 1e-06
I0722 19:19:54.816687 23230 solver.cpp:243] Iteration 121800, loss = 2.63353
I0722 19:19:54.816925 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.68658 (* 1 = 2.68658 loss)
I0722 19:19:54.816975 23230 sgd_solver.cpp:138] Iteration 121800, lr = 1e-06
I0722 19:21:24.474591 23230 solver.cpp:243] Iteration 121810, loss = 2.83368
I0722 19:21:24.474927 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.31911 (* 1 = 1.31911 loss)
I0722 19:21:24.475028 23230 sgd_solver.cpp:138] Iteration 121810, lr = 1e-06
I0722 19:22:50.142877 23230 solver.cpp:243] Iteration 121820, loss = 2.58676
I0722 19:22:50.143131 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.49219 (* 1 = 1.49219 loss)
I0722 19:22:50.910938 23230 sgd_solver.cpp:138] Iteration 121820, lr = 1e-06
I0722 19:24:16.492741 23230 solver.cpp:243] Iteration 121830, loss = 2.56349
I0722 19:24:16.493027 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80273 (* 1 = 1.80273 loss)
I0722 19:24:16.493086 23230 sgd_solver.cpp:138] Iteration 121830, lr = 1e-06
I0722 19:25:42.930030 23230 solver.cpp:243] Iteration 121840, loss = 2.4121
I0722 19:25:42.930271 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.99871 (* 1 = 2.99871 loss)
I0722 19:25:42.930311 23230 sgd_solver.cpp:138] Iteration 121840, lr = 1e-06
I0722 19:27:09.440964 23230 solver.cpp:243] Iteration 121850, loss = 2.44655
I0722 19:27:09.441217 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7688 (* 1 = 2.7688 loss)
I0722 19:27:09.441282 23230 sgd_solver.cpp:138] Iteration 121850, lr = 1e-06
I0722 19:28:37.616854 23230 solver.cpp:243] Iteration 121860, loss = 2.50983
I0722 19:28:37.617162 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08801 (* 1 = 3.08801 loss)
I0722 19:28:37.617239 23230 sgd_solver.cpp:138] Iteration 121860, lr = 1e-06
I0722 19:30:02.377971 23230 solver.cpp:243] Iteration 121870, loss = 2.37984
I0722 19:30:02.378283 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32426 (* 1 = 1.32426 loss)
I0722 19:30:02.378340 23230 sgd_solver.cpp:138] Iteration 121870, lr = 1e-06
I0722 19:31:30.865592 23230 solver.cpp:243] Iteration 121880, loss = 2.62358
I0722 19:31:30.865895 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.26852 (* 1 = 3.26852 loss)
I0722 19:31:30.865968 23230 sgd_solver.cpp:138] Iteration 121880, lr = 1e-06
I0722 19:32:55.154834 23230 solver.cpp:243] Iteration 121890, loss = 2.34019
I0722 19:32:55.155140 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64988 (* 1 = 1.64988 loss)
I0722 19:32:55.155249 23230 sgd_solver.cpp:138] Iteration 121890, lr = 1e-06
I0722 19:34:22.500313 23230 solver.cpp:243] Iteration 121900, loss = 2.51108
I0722 19:34:22.500599 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.33082 (* 1 = 1.33082 loss)
I0722 19:34:22.500715 23230 sgd_solver.cpp:138] Iteration 121900, lr = 1e-06
I0722 19:35:49.989902 23230 solver.cpp:243] Iteration 121910, loss = 2.46933
I0722 19:35:49.990186 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.45402 (* 1 = 3.45402 loss)
I0722 19:35:49.990232 23230 sgd_solver.cpp:138] Iteration 121910, lr = 1e-06
I0722 19:37:18.385841 23230 solver.cpp:243] Iteration 121920, loss = 2.54353
I0722 19:37:18.386142 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.10269 (* 1 = 4.10269 loss)
I0722 19:37:18.386242 23230 sgd_solver.cpp:138] Iteration 121920, lr = 1e-06
I0722 19:38:44.520596 23230 solver.cpp:243] Iteration 121930, loss = 2.82074
I0722 19:38:44.520917 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.50016 (* 1 = 3.50016 loss)
I0722 19:38:44.521016 23230 sgd_solver.cpp:138] Iteration 121930, lr = 1e-06
I0722 19:40:10.893244 23230 solver.cpp:243] Iteration 121940, loss = 2.77525
I0722 19:40:10.893514 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61339 (* 1 = 2.61339 loss)
I0722 19:40:10.893573 23230 sgd_solver.cpp:138] Iteration 121940, lr = 1e-06
I0722 19:41:36.514853 23230 solver.cpp:243] Iteration 121950, loss = 2.61098
I0722 19:41:36.516863 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.85364 (* 1 = 3.85364 loss)
I0722 19:41:37.261961 23230 sgd_solver.cpp:138] Iteration 121950, lr = 1e-06
I0722 19:43:04.325451 23230 solver.cpp:243] Iteration 121960, loss = 2.31055
I0722 19:43:04.325754 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.15458 (* 1 = 3.15458 loss)
I0722 19:43:04.325851 23230 sgd_solver.cpp:138] Iteration 121960, lr = 1e-06
I0722 19:44:30.893837 23230 solver.cpp:243] Iteration 121970, loss = 2.38792
I0722 19:44:30.894125 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.45769 (* 1 = 2.45769 loss)
I0722 19:44:30.894212 23230 sgd_solver.cpp:138] Iteration 121970, lr = 1e-06
I0722 19:45:58.204401 23230 solver.cpp:243] Iteration 121980, loss = 2.4724
I0722 19:45:58.204674 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.48509 (* 1 = 5.48509 loss)
I0722 19:45:58.566568 23230 sgd_solver.cpp:138] Iteration 121980, lr = 1e-06
I0722 19:47:27.010299 23230 solver.cpp:243] Iteration 121990, loss = 2.42355
I0722 19:47:27.010586 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.861964 (* 1 = 0.861964 loss)
I0722 19:47:27.010697 23230 sgd_solver.cpp:138] Iteration 121990, lr = 1e-06
I0722 19:48:46.530769 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_122000.caffemodel
I0722 19:48:47.368278 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_122000.solverstate
I0722 19:48:47.578987 23230 solver.cpp:433] Iteration 122000, Testing net (#0)
I0722 19:48:47.579185 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 19:48:50.895504 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.629021
I0722 19:48:58.689971 23230 solver.cpp:243] Iteration 122000, loss = 2.51299
I0722 19:48:58.690135 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.52581 (* 1 = 2.52581 loss)
I0722 19:48:58.690213 23230 sgd_solver.cpp:138] Iteration 122000, lr = 1e-06
I0722 19:50:26.241555 23230 solver.cpp:243] Iteration 122010, loss = 2.4202
I0722 19:50:26.241907 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.98419 (* 1 = 2.98419 loss)
I0722 19:50:26.242012 23230 sgd_solver.cpp:138] Iteration 122010, lr = 1e-06
I0722 19:51:53.662503 23230 solver.cpp:243] Iteration 122020, loss = 2.51093
I0722 19:51:53.662756 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.59804 (* 1 = 1.59804 loss)
I0722 19:51:54.446789 23230 sgd_solver.cpp:138] Iteration 122020, lr = 1e-06
I0722 19:53:21.783773 23230 solver.cpp:243] Iteration 122030, loss = 2.65854
I0722 19:53:21.784103 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50207 (* 1 = 2.50207 loss)
I0722 19:53:21.784209 23230 sgd_solver.cpp:138] Iteration 122030, lr = 1e-06
I0722 19:54:49.404062 23230 solver.cpp:243] Iteration 122040, loss = 2.4925
I0722 19:54:49.404372 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04851 (* 1 = 3.04851 loss)
I0722 19:54:49.404481 23230 sgd_solver.cpp:138] Iteration 122040, lr = 1e-06
I0722 19:56:16.740933 23230 solver.cpp:243] Iteration 122050, loss = 2.37541
I0722 19:56:16.741221 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.10318 (* 1 = 3.10318 loss)
I0722 19:56:16.741330 23230 sgd_solver.cpp:138] Iteration 122050, lr = 1e-06
I0722 19:57:42.800323 23230 solver.cpp:243] Iteration 122060, loss = 2.73277
I0722 19:57:42.800573 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80474 (* 1 = 2.80474 loss)
I0722 19:57:42.800639 23230 sgd_solver.cpp:138] Iteration 122060, lr = 1e-06
I0722 19:59:06.900528 23230 solver.cpp:243] Iteration 122070, loss = 2.41809
I0722 19:59:06.900758 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69592 (* 1 = 2.69592 loss)
I0722 19:59:06.900812 23230 sgd_solver.cpp:138] Iteration 122070, lr = 1e-06
I0722 20:00:33.167834 23230 solver.cpp:243] Iteration 122080, loss = 2.62196
I0722 20:00:33.168103 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47779 (* 1 = 2.47779 loss)
I0722 20:00:33.168155 23230 sgd_solver.cpp:138] Iteration 122080, lr = 1e-06
I0722 20:01:59.037390 23230 solver.cpp:243] Iteration 122090, loss = 2.53587
I0722 20:01:59.037691 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.54897 (* 1 = 3.54897 loss)
I0722 20:01:59.037799 23230 sgd_solver.cpp:138] Iteration 122090, lr = 1e-06
I0722 20:03:24.817302 23230 solver.cpp:243] Iteration 122100, loss = 2.53257
I0722 20:03:24.817519 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.14113 (* 1 = 4.14113 loss)
I0722 20:03:24.817564 23230 sgd_solver.cpp:138] Iteration 122100, lr = 1e-06
I0722 20:04:54.271600 23230 solver.cpp:243] Iteration 122110, loss = 2.51264
I0722 20:04:54.271876 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.879193 (* 1 = 0.879193 loss)
I0722 20:04:54.271951 23230 sgd_solver.cpp:138] Iteration 122110, lr = 1e-06
I0722 20:06:20.363279 23230 solver.cpp:243] Iteration 122120, loss = 2.60961
I0722 20:06:20.363601 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 20:06:20.759788 23230 sgd_solver.cpp:138] Iteration 122120, lr = 1e-06
I0722 20:07:47.798151 23230 solver.cpp:243] Iteration 122130, loss = 2.52756
I0722 20:07:47.798403 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.51856 (* 1 = 1.51856 loss)
I0722 20:07:47.798450 23230 sgd_solver.cpp:138] Iteration 122130, lr = 1e-06
I0722 20:09:14.799787 23230 solver.cpp:243] Iteration 122140, loss = 2.41582
I0722 20:09:14.800086 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.94454 (* 1 = 3.94454 loss)
I0722 20:09:15.157073 23230 sgd_solver.cpp:138] Iteration 122140, lr = 1e-06
I0722 20:10:41.129647 23230 solver.cpp:243] Iteration 122150, loss = 2.68844
I0722 20:10:41.129977 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.53722 (* 1 = 3.53722 loss)
I0722 20:10:41.903633 23230 sgd_solver.cpp:138] Iteration 122150, lr = 1e-06
I0722 20:12:09.979730 23230 solver.cpp:243] Iteration 122160, loss = 2.57722
I0722 20:12:09.980003 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.30681 (* 1 = 2.30681 loss)
I0722 20:12:09.980070 23230 sgd_solver.cpp:138] Iteration 122160, lr = 1e-06
I0722 20:13:35.033982 23230 solver.cpp:243] Iteration 122170, loss = 2.63207
I0722 20:13:35.034296 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.07533 (* 1 = 2.07533 loss)
I0722 20:13:35.034404 23230 sgd_solver.cpp:138] Iteration 122170, lr = 1e-06
I0722 20:14:58.995018 23230 solver.cpp:243] Iteration 122180, loss = 2.35895
I0722 20:14:58.995278 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.84427 (* 1 = 1.84427 loss)
I0722 20:14:58.995340 23230 sgd_solver.cpp:138] Iteration 122180, lr = 1e-06
I0722 20:16:25.736353 23230 solver.cpp:243] Iteration 122190, loss = 2.45163
I0722 20:16:25.736623 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10699 (* 1 = 2.10699 loss)
I0722 20:16:25.736676 23230 sgd_solver.cpp:138] Iteration 122190, lr = 1e-06
I0722 20:17:54.454370 23230 solver.cpp:243] Iteration 122200, loss = 2.67114
I0722 20:17:54.454699 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60731 (* 1 = 2.60731 loss)
I0722 20:17:54.454804 23230 sgd_solver.cpp:138] Iteration 122200, lr = 1e-06
I0722 20:19:22.310690 23230 solver.cpp:243] Iteration 122210, loss = 2.51304
I0722 20:19:22.310948 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64237 (* 1 = 1.64237 loss)
I0722 20:19:22.699154 23230 sgd_solver.cpp:138] Iteration 122210, lr = 1e-06
I0722 20:20:51.083254 23230 solver.cpp:243] Iteration 122220, loss = 2.40729
I0722 20:20:51.083556 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.97099 (* 1 = 1.97099 loss)
I0722 20:20:51.083664 23230 sgd_solver.cpp:138] Iteration 122220, lr = 1e-06
I0722 20:22:17.844105 23230 solver.cpp:243] Iteration 122230, loss = 2.73925
I0722 20:22:17.844393 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.39394 (* 1 = 3.39394 loss)
I0722 20:22:17.844491 23230 sgd_solver.cpp:138] Iteration 122230, lr = 1e-06
I0722 20:23:45.755075 23230 solver.cpp:243] Iteration 122240, loss = 2.72028
I0722 20:23:45.755324 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.65093 (* 1 = 1.65093 loss)
I0722 20:23:45.755373 23230 sgd_solver.cpp:138] Iteration 122240, lr = 1e-06
I0722 20:25:11.500911 23230 solver.cpp:243] Iteration 122250, loss = 2.62233
I0722 20:25:11.501166 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.09191 (* 1 = 1.09191 loss)
I0722 20:25:11.501225 23230 sgd_solver.cpp:138] Iteration 122250, lr = 1e-06
I0722 20:26:37.643295 23230 solver.cpp:243] Iteration 122260, loss = 2.861
I0722 20:26:37.643709 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.10869 (* 1 = 3.10869 loss)
I0722 20:26:38.007046 23230 sgd_solver.cpp:138] Iteration 122260, lr = 1e-06
I0722 20:28:01.919212 23230 solver.cpp:243] Iteration 122270, loss = 2.53783
I0722 20:28:01.919622 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50967 (* 1 = 2.50967 loss)
I0722 20:28:02.682700 23230 sgd_solver.cpp:138] Iteration 122270, lr = 1e-06
I0722 20:29:28.703194 23230 solver.cpp:243] Iteration 122280, loss = 2.53226
I0722 20:29:28.703444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.86087 (* 1 = 2.86087 loss)
I0722 20:29:29.128135 23230 sgd_solver.cpp:138] Iteration 122280, lr = 1e-06
I0722 20:30:57.711125 23230 solver.cpp:243] Iteration 122290, loss = 2.49135
I0722 20:30:57.711421 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.75968 (* 1 = 2.75968 loss)
I0722 20:30:57.711537 23230 sgd_solver.cpp:138] Iteration 122290, lr = 1e-06
I0722 20:32:21.624254 23230 solver.cpp:243] Iteration 122300, loss = 2.30419
I0722 20:32:21.624568 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.952749 (* 1 = 0.952749 loss)
I0722 20:32:22.329839 23230 sgd_solver.cpp:138] Iteration 122300, lr = 1e-06
I0722 20:33:48.259104 23230 solver.cpp:243] Iteration 122310, loss = 2.41379
I0722 20:33:48.259402 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.17989 (* 1 = 1.17989 loss)
I0722 20:33:48.259506 23230 sgd_solver.cpp:138] Iteration 122310, lr = 1e-06
I0722 20:35:13.001261 23230 solver.cpp:243] Iteration 122320, loss = 2.64377
I0722 20:35:13.001533 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.41566 (* 1 = 2.41566 loss)
I0722 20:35:13.001657 23230 sgd_solver.cpp:138] Iteration 122320, lr = 1e-06
I0722 20:36:36.290657 23230 solver.cpp:243] Iteration 122330, loss = 2.65428
I0722 20:36:36.290912 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.5532 (* 1 = 1.5532 loss)
I0722 20:36:36.290964 23230 sgd_solver.cpp:138] Iteration 122330, lr = 1e-06
I0722 20:38:02.249455 23230 solver.cpp:243] Iteration 122340, loss = 2.53649
I0722 20:38:02.249740 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80642 (* 1 = 1.80642 loss)
I0722 20:38:02.249861 23230 sgd_solver.cpp:138] Iteration 122340, lr = 1e-06
I0722 20:39:26.503207 23230 solver.cpp:243] Iteration 122350, loss = 2.60848
I0722 20:39:26.503477 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82765 (* 1 = 2.82765 loss)
I0722 20:39:26.867228 23230 sgd_solver.cpp:138] Iteration 122350, lr = 1e-06
I0722 20:40:51.119138 23230 solver.cpp:243] Iteration 122360, loss = 2.43014
I0722 20:40:51.119436 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69709 (* 1 = 1.69709 loss)
I0722 20:40:51.756479 23230 sgd_solver.cpp:138] Iteration 122360, lr = 1e-06
I0722 20:42:18.665201 23230 solver.cpp:243] Iteration 122370, loss = 2.41935
I0722 20:42:18.665463 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37511 (* 1 = 3.37511 loss)
I0722 20:42:19.355980 23230 sgd_solver.cpp:138] Iteration 122370, lr = 1e-06
I0722 20:43:45.694135 23230 solver.cpp:243] Iteration 122380, loss = 2.72847
I0722 20:43:45.694422 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.7482 (* 1 = 3.7482 loss)
I0722 20:43:45.694524 23230 sgd_solver.cpp:138] Iteration 122380, lr = 1e-06
I0722 20:45:11.095829 23230 solver.cpp:243] Iteration 122390, loss = 2.60522
I0722 20:45:11.096062 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.36185 (* 1 = 2.36185 loss)
I0722 20:45:11.464825 23230 sgd_solver.cpp:138] Iteration 122390, lr = 1e-06
I0722 20:46:38.174402 23230 solver.cpp:243] Iteration 122400, loss = 2.6647
I0722 20:46:38.174710 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.64439 (* 1 = 2.64439 loss)
I0722 20:46:38.174818 23230 sgd_solver.cpp:138] Iteration 122400, lr = 1e-06
I0722 20:48:01.117764 23230 solver.cpp:243] Iteration 122410, loss = 2.28967
I0722 20:48:01.118044 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05032 (* 1 = 2.05032 loss)
I0722 20:48:01.118170 23230 sgd_solver.cpp:138] Iteration 122410, lr = 1e-06
I0722 20:49:24.126418 23230 solver.cpp:243] Iteration 122420, loss = 2.48559
I0722 20:49:24.126741 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85501 (* 1 = 2.85501 loss)
I0722 20:49:24.126842 23230 sgd_solver.cpp:138] Iteration 122420, lr = 1e-06
I0722 20:50:49.810477 23230 solver.cpp:243] Iteration 122430, loss = 2.43175
I0722 20:50:49.810807 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.43285 (* 1 = 2.43285 loss)
I0722 20:50:49.810912 23230 sgd_solver.cpp:138] Iteration 122430, lr = 1e-06
I0722 20:52:15.683058 23230 solver.cpp:243] Iteration 122440, loss = 2.65229
I0722 20:52:15.683300 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.20332 (* 1 = 2.20332 loss)
I0722 20:52:15.683356 23230 sgd_solver.cpp:138] Iteration 122440, lr = 1e-06
I0722 20:53:41.779402 23230 solver.cpp:243] Iteration 122450, loss = 2.46755
I0722 20:53:41.779714 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.07378 (* 1 = 4.07378 loss)
I0722 20:53:41.779850 23230 sgd_solver.cpp:138] Iteration 122450, lr = 1e-06
I0722 20:55:08.674417 23230 solver.cpp:243] Iteration 122460, loss = 2.59804
I0722 20:55:08.674695 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15224 (* 1 = 2.15224 loss)
I0722 20:55:08.674763 23230 sgd_solver.cpp:138] Iteration 122460, lr = 1e-06
I0722 20:56:33.423235 23230 solver.cpp:243] Iteration 122470, loss = 2.56624
I0722 20:56:33.423446 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76054 (* 1 = 3.76054 loss)
I0722 20:56:33.423487 23230 sgd_solver.cpp:138] Iteration 122470, lr = 1e-06
I0722 20:57:59.990453 23230 solver.cpp:243] Iteration 122480, loss = 2.46082
I0722 20:57:59.991271 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.90073 (* 1 = 1.90073 loss)
I0722 20:57:59.991324 23230 sgd_solver.cpp:138] Iteration 122480, lr = 1e-06
I0722 20:59:27.360678 23230 solver.cpp:243] Iteration 122490, loss = 2.48671
I0722 20:59:27.360997 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.59942 (* 1 = 2.59942 loss)
I0722 20:59:27.361050 23230 sgd_solver.cpp:138] Iteration 122490, lr = 1e-06
I0722 21:00:53.061630 23230 solver.cpp:243] Iteration 122500, loss = 2.54548
I0722 21:00:53.061947 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.52297 (* 1 = 3.52297 loss)
I0722 21:00:53.423420 23230 sgd_solver.cpp:138] Iteration 122500, lr = 1e-06
I0722 21:02:17.966387 23230 solver.cpp:243] Iteration 122510, loss = 2.6922
I0722 21:02:17.966617 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57407 (* 1 = 2.57407 loss)
I0722 21:02:17.966668 23230 sgd_solver.cpp:138] Iteration 122510, lr = 1e-06
I0722 21:03:42.717674 23230 solver.cpp:243] Iteration 122520, loss = 2.42169
I0722 21:03:42.717893 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 21:03:43.161392 23230 sgd_solver.cpp:138] Iteration 122520, lr = 1e-06
I0722 21:05:10.330977 23230 solver.cpp:243] Iteration 122530, loss = 2.49092
I0722 21:05:10.331254 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9566 (* 1 = 1.9566 loss)
I0722 21:05:10.331377 23230 sgd_solver.cpp:138] Iteration 122530, lr = 1e-06
I0722 21:06:36.703795 23230 solver.cpp:243] Iteration 122540, loss = 2.54869
I0722 21:06:36.704083 23230 solver.cpp:259]     Train net output #0: mbox_loss = 9.12636 (* 1 = 9.12636 loss)
I0722 21:06:37.678587 23230 sgd_solver.cpp:138] Iteration 122540, lr = 1e-06
I0722 21:08:01.203927 23230 solver.cpp:243] Iteration 122550, loss = 2.12681
I0722 21:08:01.204218 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.086 (* 1 = 2.086 loss)
I0722 21:08:01.971499 23230 sgd_solver.cpp:138] Iteration 122550, lr = 1e-06
I0722 21:09:26.386627 23230 solver.cpp:243] Iteration 122560, loss = 2.54678
I0722 21:09:26.386847 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83079 (* 1 = 1.83079 loss)
I0722 21:09:26.386885 23230 sgd_solver.cpp:138] Iteration 122560, lr = 1e-06
I0722 21:10:52.755375 23230 solver.cpp:243] Iteration 122570, loss = 2.51637
I0722 21:10:52.755669 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.1924 (* 1 = 3.1924 loss)
I0722 21:10:52.755790 23230 sgd_solver.cpp:138] Iteration 122570, lr = 1e-06
I0722 21:12:20.079682 23230 solver.cpp:243] Iteration 122580, loss = 2.46049
I0722 21:12:20.079900 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.0578 (* 1 = 2.0578 loss)
I0722 21:12:20.502784 23230 sgd_solver.cpp:138] Iteration 122580, lr = 1e-06
I0722 21:13:44.888566 23230 solver.cpp:243] Iteration 122590, loss = 2.43786
I0722 21:13:44.888875 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.30056 (* 1 = 4.30056 loss)
I0722 21:13:44.888984 23230 sgd_solver.cpp:138] Iteration 122590, lr = 1e-06
I0722 21:15:11.814383 23230 solver.cpp:243] Iteration 122600, loss = 2.41222
I0722 21:15:11.814605 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.25633 (* 1 = 2.25633 loss)
I0722 21:15:11.814643 23230 sgd_solver.cpp:138] Iteration 122600, lr = 1e-06
I0722 21:16:38.701203 23230 solver.cpp:243] Iteration 122610, loss = 2.48318
I0722 21:16:38.701519 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.00667 (* 1 = 1.00667 loss)
I0722 21:16:38.701620 23230 sgd_solver.cpp:138] Iteration 122610, lr = 1e-06
I0722 21:18:06.062536 23230 solver.cpp:243] Iteration 122620, loss = 2.73904
I0722 21:18:06.062798 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67421 (* 1 = 2.67421 loss)
I0722 21:18:06.062861 23230 sgd_solver.cpp:138] Iteration 122620, lr = 1e-06
I0722 21:19:34.098775 23230 solver.cpp:243] Iteration 122630, loss = 2.65962
I0722 21:19:34.099068 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03282 (* 1 = 2.03282 loss)
I0722 21:19:34.099180 23230 sgd_solver.cpp:138] Iteration 122630, lr = 1e-06
I0722 21:21:01.840309 23230 solver.cpp:243] Iteration 122640, loss = 2.75002
I0722 21:21:01.840564 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2061 (* 1 = 2.2061 loss)
I0722 21:21:01.840615 23230 sgd_solver.cpp:138] Iteration 122640, lr = 1e-06
I0722 21:22:29.995550 23230 solver.cpp:243] Iteration 122650, loss = 2.54992
I0722 21:22:29.995837 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.47032 (* 1 = 4.47032 loss)
I0722 21:22:29.995954 23230 sgd_solver.cpp:138] Iteration 122650, lr = 1e-06
I0722 21:23:56.609527 23230 solver.cpp:243] Iteration 122660, loss = 2.59102
I0722 21:23:56.609747 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04466 (* 1 = 3.04466 loss)
I0722 21:23:56.609786 23230 sgd_solver.cpp:138] Iteration 122660, lr = 1e-06
I0722 21:25:23.866910 23230 solver.cpp:243] Iteration 122670, loss = 2.65585
I0722 21:25:23.867194 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.03852 (* 1 = 1.03852 loss)
I0722 21:25:23.867305 23230 sgd_solver.cpp:138] Iteration 122670, lr = 1e-06
I0722 21:26:49.374953 23230 solver.cpp:243] Iteration 122680, loss = 2.5119
I0722 21:26:49.375254 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61792 (* 1 = 2.61792 loss)
I0722 21:26:49.375326 23230 sgd_solver.cpp:138] Iteration 122680, lr = 1e-06
I0722 21:28:16.053118 23230 solver.cpp:243] Iteration 122690, loss = 2.68331
I0722 21:28:16.053351 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.31341 (* 1 = 3.31341 loss)
I0722 21:28:16.053396 23230 sgd_solver.cpp:138] Iteration 122690, lr = 1e-06
I0722 21:29:42.425048 23230 solver.cpp:243] Iteration 122700, loss = 2.45312
I0722 21:29:42.425335 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64913 (* 1 = 1.64913 loss)
I0722 21:29:42.425454 23230 sgd_solver.cpp:138] Iteration 122700, lr = 1e-06
I0722 21:31:06.824375 23230 solver.cpp:243] Iteration 122710, loss = 2.48417
I0722 21:31:06.824615 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7201 (* 1 = 2.7201 loss)
I0722 21:31:06.824687 23230 sgd_solver.cpp:138] Iteration 122710, lr = 1e-06
I0722 21:32:32.087847 23230 solver.cpp:243] Iteration 122720, loss = 2.60162
I0722 21:32:32.088075 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.13517 (* 1 = 2.13517 loss)
I0722 21:32:32.088117 23230 sgd_solver.cpp:138] Iteration 122720, lr = 1e-06
I0722 21:34:00.929405 23230 solver.cpp:243] Iteration 122730, loss = 2.5003
I0722 21:34:00.929693 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.76773 (* 1 = 1.76773 loss)
I0722 21:34:00.929790 23230 sgd_solver.cpp:138] Iteration 122730, lr = 1e-06
I0722 21:35:26.598312 23230 solver.cpp:243] Iteration 122740, loss = 2.44407
I0722 21:35:26.598567 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.30037 (* 1 = 2.30037 loss)
I0722 21:35:26.598609 23230 sgd_solver.cpp:138] Iteration 122740, lr = 1e-06
I0722 21:36:51.688139 23230 solver.cpp:243] Iteration 122750, loss = 2.55577
I0722 21:36:51.688405 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.76869 (* 1 = 3.76869 loss)
I0722 21:36:52.438349 23230 sgd_solver.cpp:138] Iteration 122750, lr = 1e-06
I0722 21:38:18.911947 23230 solver.cpp:243] Iteration 122760, loss = 2.50242
I0722 21:38:18.912226 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83677 (* 1 = 1.83677 loss)
I0722 21:38:18.912333 23230 sgd_solver.cpp:138] Iteration 122760, lr = 1e-06
I0722 21:39:44.632699 23230 solver.cpp:243] Iteration 122770, loss = 2.64929
I0722 21:39:44.632947 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.4419 (* 1 = 3.4419 loss)
I0722 21:39:44.632990 23230 sgd_solver.cpp:138] Iteration 122770, lr = 1e-06
I0722 21:41:10.040463 23230 solver.cpp:243] Iteration 122780, loss = 2.54171
I0722 21:41:10.040735 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60126 (* 1 = 2.60126 loss)
I0722 21:41:10.040774 23230 sgd_solver.cpp:138] Iteration 122780, lr = 1e-06
I0722 21:42:35.275485 23230 solver.cpp:243] Iteration 122790, loss = 2.51462
I0722 21:42:35.275729 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.4802 (* 1 = 4.4802 loss)
I0722 21:42:35.275770 23230 sgd_solver.cpp:138] Iteration 122790, lr = 1e-06
I0722 21:44:01.769987 23230 solver.cpp:243] Iteration 122800, loss = 2.41363
I0722 21:44:01.770232 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 21:44:02.194571 23230 sgd_solver.cpp:138] Iteration 122800, lr = 1e-06
I0722 21:45:28.977718 23230 solver.cpp:243] Iteration 122810, loss = 2.59133
I0722 21:45:28.978004 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.68761 (* 1 = 2.68761 loss)
I0722 21:45:29.381086 23230 sgd_solver.cpp:138] Iteration 122810, lr = 1e-06
I0722 21:46:56.555814 23230 solver.cpp:243] Iteration 122820, loss = 2.5497
I0722 21:46:56.556223 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.179 (* 1 = 3.179 loss)
I0722 21:46:56.556306 23230 sgd_solver.cpp:138] Iteration 122820, lr = 1e-06
I0722 21:48:24.152843 23230 solver.cpp:243] Iteration 122830, loss = 2.36203
I0722 21:48:24.153152 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67611 (* 1 = 2.67611 loss)
I0722 21:48:24.153251 23230 sgd_solver.cpp:138] Iteration 122830, lr = 1e-06
I0722 21:49:48.846592 23230 solver.cpp:243] Iteration 122840, loss = 2.68331
I0722 21:49:48.846830 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.00137 (* 1 = 3.00137 loss)
I0722 21:49:48.846873 23230 sgd_solver.cpp:138] Iteration 122840, lr = 1e-06
I0722 21:51:15.382249 23230 solver.cpp:243] Iteration 122850, loss = 2.48922
I0722 21:51:15.382511 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.53423 (* 1 = 2.53423 loss)
I0722 21:51:15.782011 23230 sgd_solver.cpp:138] Iteration 122850, lr = 1e-06
I0722 21:52:42.168318 23230 solver.cpp:243] Iteration 122860, loss = 2.34306
I0722 21:52:42.168613 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.36825 (* 1 = 3.36825 loss)
I0722 21:52:42.168715 23230 sgd_solver.cpp:138] Iteration 122860, lr = 1e-06
I0722 21:54:06.824079 23230 solver.cpp:243] Iteration 122870, loss = 2.75079
I0722 21:54:06.824297 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.59222 (* 1 = 4.59222 loss)
I0722 21:54:06.824342 23230 sgd_solver.cpp:138] Iteration 122870, lr = 1e-06
I0722 21:55:29.788275 23230 solver.cpp:243] Iteration 122880, loss = 2.39434
I0722 21:55:29.788512 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.33404 (* 1 = 3.33404 loss)
I0722 21:55:29.788556 23230 sgd_solver.cpp:138] Iteration 122880, lr = 1e-06
I0722 21:56:57.310995 23230 solver.cpp:243] Iteration 122890, loss = 2.44593
I0722 21:56:57.311334 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32967 (* 1 = 1.32967 loss)
I0722 21:56:57.311448 23230 sgd_solver.cpp:138] Iteration 122890, lr = 1e-06
I0722 21:58:19.284442 23230 solver.cpp:243] Iteration 122900, loss = 2.44379
I0722 21:58:19.284750 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17288 (* 1 = 2.17288 loss)
I0722 21:58:19.650471 23230 sgd_solver.cpp:138] Iteration 122900, lr = 1e-06
I0722 21:59:44.241698 23230 solver.cpp:243] Iteration 122910, loss = 2.72161
I0722 21:59:44.241927 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96644 (* 1 = 2.96644 loss)
I0722 21:59:44.241964 23230 sgd_solver.cpp:138] Iteration 122910, lr = 1e-06
I0722 22:01:10.584352 23230 solver.cpp:243] Iteration 122920, loss = 2.46836
I0722 22:01:10.584960 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.07092 (* 1 = 2.07092 loss)
I0722 22:01:11.346971 23230 sgd_solver.cpp:138] Iteration 122920, lr = 1e-06
I0722 22:02:40.344076 23230 solver.cpp:243] Iteration 122930, loss = 2.52909
I0722 22:02:40.344405 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.8919 (* 1 = 1.8919 loss)
I0722 22:02:40.344524 23230 sgd_solver.cpp:138] Iteration 122930, lr = 1e-06
I0722 22:04:07.585033 23230 solver.cpp:243] Iteration 122940, loss = 2.47187
I0722 22:04:07.585322 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82128 (* 1 = 1.82128 loss)
I0722 22:04:07.585371 23230 sgd_solver.cpp:138] Iteration 122940, lr = 1e-06
I0722 22:05:31.534453 23230 solver.cpp:243] Iteration 122950, loss = 2.61759
I0722 22:05:31.534761 23230 solver.cpp:259]     Train net output #0: mbox_loss = 8.35621 (* 1 = 8.35621 loss)
I0722 22:05:31.953924 23230 sgd_solver.cpp:138] Iteration 122950, lr = 1e-06
I0722 22:06:58.065325 23230 solver.cpp:243] Iteration 122960, loss = 2.68275
I0722 22:06:58.065582 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.25762 (* 1 = 3.25762 loss)
I0722 22:06:58.426390 23230 sgd_solver.cpp:138] Iteration 122960, lr = 1e-06
I0722 22:08:22.121109 23230 solver.cpp:243] Iteration 122970, loss = 2.53775
I0722 22:08:22.121351 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.92876 (* 1 = 3.92876 loss)
I0722 22:08:22.121398 23230 sgd_solver.cpp:138] Iteration 122970, lr = 1e-06
I0722 22:09:45.543051 23230 solver.cpp:243] Iteration 122980, loss = 2.52539
I0722 22:09:45.543318 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.689 (* 1 = 3.689 loss)
I0722 22:09:45.543365 23230 sgd_solver.cpp:138] Iteration 122980, lr = 1e-06
I0722 22:11:14.708248 23230 solver.cpp:243] Iteration 122990, loss = 2.65523
I0722 22:11:14.708566 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.56354 (* 1 = 3.56354 loss)
I0722 22:11:15.068338 23230 sgd_solver.cpp:138] Iteration 122990, lr = 1e-06
I0722 22:12:33.529533 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_123000.caffemodel
I0722 22:12:34.391712 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_123000.solverstate
I0722 22:12:34.591975 23230 solver.cpp:433] Iteration 123000, Testing net (#0)
I0722 22:12:34.592177 23230 net.cpp:693] Ignoring source layer mbox_loss
I0722 22:12:37.915727 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.615511
I0722 22:12:45.708559 23230 solver.cpp:243] Iteration 123000, loss = 2.66333
I0722 22:12:45.708678 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24054 (* 1 = 2.24054 loss)
I0722 22:12:47.083206 23230 sgd_solver.cpp:138] Iteration 123000, lr = 1e-06
I0722 22:14:15.059751 23230 solver.cpp:243] Iteration 123010, loss = 2.65566
I0722 22:14:15.060014 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.45954 (* 1 = 4.45954 loss)
I0722 22:14:15.477453 23230 sgd_solver.cpp:138] Iteration 123010, lr = 1e-06
I0722 22:15:42.925367 23230 solver.cpp:243] Iteration 123020, loss = 2.59951
I0722 22:15:42.925606 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.41192 (* 1 = 1.41192 loss)
I0722 22:15:42.925652 23230 sgd_solver.cpp:138] Iteration 123020, lr = 1e-06
I0722 22:17:12.948132 23230 solver.cpp:243] Iteration 123030, loss = 2.50146
I0722 22:17:12.948520 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.44804 (* 1 = 2.44804 loss)
I0722 22:17:13.300544 23230 sgd_solver.cpp:138] Iteration 123030, lr = 1e-06
I0722 22:18:39.316494 23230 solver.cpp:243] Iteration 123040, loss = 2.53632
I0722 22:18:39.316848 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.71739 (* 1 = 4.71739 loss)
I0722 22:18:39.316965 23230 sgd_solver.cpp:138] Iteration 123040, lr = 1e-06
I0722 22:20:09.536912 23230 solver.cpp:243] Iteration 123050, loss = 2.39629
I0722 22:20:09.537210 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46705 (* 1 = 1.46705 loss)
I0722 22:20:09.537359 23230 sgd_solver.cpp:138] Iteration 123050, lr = 1e-06
I0722 22:21:37.813151 23230 solver.cpp:243] Iteration 123060, loss = 2.79453
I0722 22:21:37.813462 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.41349 (* 1 = 1.41349 loss)
I0722 22:21:37.813563 23230 sgd_solver.cpp:138] Iteration 123060, lr = 1e-06
I0722 22:23:01.683149 23230 solver.cpp:243] Iteration 123070, loss = 2.72702
I0722 22:23:01.683702 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74272 (* 1 = 2.74272 loss)
I0722 22:23:01.683754 23230 sgd_solver.cpp:138] Iteration 123070, lr = 1e-06
I0722 22:24:27.677806 23230 solver.cpp:243] Iteration 123080, loss = 2.73461
I0722 22:24:27.678031 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.32286 (* 1 = 2.32286 loss)
I0722 22:24:28.078500 23230 sgd_solver.cpp:138] Iteration 123080, lr = 1e-06
I0722 22:25:54.986344 23230 solver.cpp:243] Iteration 123090, loss = 2.4629
I0722 22:25:54.986625 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32148 (* 1 = 3.32148 loss)
I0722 22:25:54.986754 23230 sgd_solver.cpp:138] Iteration 123090, lr = 1e-06
I0722 22:27:21.725100 23230 solver.cpp:243] Iteration 123100, loss = 2.49804
I0722 22:27:21.725363 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60295 (* 1 = 2.60295 loss)
I0722 22:27:21.725461 23230 sgd_solver.cpp:138] Iteration 123100, lr = 1e-06
I0722 22:28:49.724197 23230 solver.cpp:243] Iteration 123110, loss = 2.42265
I0722 22:28:49.724503 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.94264 (* 1 = 2.94264 loss)
I0722 22:28:49.724614 23230 sgd_solver.cpp:138] Iteration 123110, lr = 1e-06
I0722 22:30:18.710835 23230 solver.cpp:243] Iteration 123120, loss = 2.59209
I0722 22:30:18.711097 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85263 (* 1 = 2.85263 loss)
I0722 22:30:18.711164 23230 sgd_solver.cpp:138] Iteration 123120, lr = 1e-06
I0722 22:31:45.784037 23230 solver.cpp:243] Iteration 123130, loss = 2.54374
I0722 22:31:45.784343 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.20025 (* 1 = 3.20025 loss)
I0722 22:31:47.070870 23230 sgd_solver.cpp:138] Iteration 123130, lr = 1e-06
I0722 22:33:14.591940 23230 solver.cpp:243] Iteration 123140, loss = 2.63439
I0722 22:33:14.592228 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.6906 (* 1 = 1.6906 loss)
I0722 22:33:14.592289 23230 sgd_solver.cpp:138] Iteration 123140, lr = 1e-06
I0722 22:34:41.620208 23230 solver.cpp:243] Iteration 123150, loss = 2.54621
I0722 22:34:41.620502 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.91087 (* 1 = 2.91087 loss)
I0722 22:34:41.620611 23230 sgd_solver.cpp:138] Iteration 123150, lr = 1e-06
I0722 22:36:09.062191 23230 solver.cpp:243] Iteration 123160, loss = 2.84062
I0722 22:36:09.062396 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40111 (* 1 = 2.40111 loss)
I0722 22:36:09.062430 23230 sgd_solver.cpp:138] Iteration 123160, lr = 1e-06
I0722 22:37:37.467141 23230 solver.cpp:243] Iteration 123170, loss = 2.58247
I0722 22:37:37.467381 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7295 (* 1 = 1.7295 loss)
I0722 22:37:37.467425 23230 sgd_solver.cpp:138] Iteration 123170, lr = 1e-06
I0722 22:39:03.541419 23230 solver.cpp:243] Iteration 123180, loss = 2.52765
I0722 22:39:03.541682 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.20114 (* 1 = 2.20114 loss)
I0722 22:39:03.541796 23230 sgd_solver.cpp:138] Iteration 123180, lr = 1e-06
I0722 22:40:30.889544 23230 solver.cpp:243] Iteration 123190, loss = 2.51268
I0722 22:40:30.889767 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.62239 (* 1 = 2.62239 loss)
I0722 22:40:31.244737 23230 sgd_solver.cpp:138] Iteration 123190, lr = 1e-06
I0722 22:41:58.131561 23230 solver.cpp:243] Iteration 123200, loss = 2.42446
I0722 22:41:58.131857 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.58886 (* 1 = 3.58886 loss)
I0722 22:41:58.131960 23230 sgd_solver.cpp:138] Iteration 123200, lr = 1e-06
I0722 22:43:25.251107 23230 solver.cpp:243] Iteration 123210, loss = 2.59265
I0722 22:43:25.251358 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61316 (* 1 = 2.61316 loss)
I0722 22:43:25.251399 23230 sgd_solver.cpp:138] Iteration 123210, lr = 1e-06
I0722 22:44:47.897917 23230 solver.cpp:243] Iteration 123220, loss = 2.38929
I0722 22:44:47.898180 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.02675 (* 1 = 3.02675 loss)
I0722 22:44:47.898222 23230 sgd_solver.cpp:138] Iteration 123220, lr = 1e-06
I0722 22:46:15.082856 23230 solver.cpp:243] Iteration 123230, loss = 2.77174
I0722 22:46:15.083117 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.71314 (* 1 = 2.71314 loss)
I0722 22:46:15.083243 23230 sgd_solver.cpp:138] Iteration 123230, lr = 1e-06
I0722 22:47:38.487685 23230 solver.cpp:243] Iteration 123240, loss = 2.61142
I0722 22:47:38.487969 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.06139 (* 1 = 3.06139 loss)
I0722 22:47:39.307826 23230 sgd_solver.cpp:138] Iteration 123240, lr = 1e-06
I0722 22:49:05.527015 23230 solver.cpp:243] Iteration 123250, loss = 2.68189
I0722 22:49:05.527256 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.55948 (* 1 = 2.55948 loss)
I0722 22:49:05.933115 23230 sgd_solver.cpp:138] Iteration 123250, lr = 1e-06
I0722 22:50:33.183465 23230 solver.cpp:243] Iteration 123260, loss = 2.27067
I0722 22:50:33.183778 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.03293 (* 1 = 2.03293 loss)
I0722 22:50:33.857547 23230 sgd_solver.cpp:138] Iteration 123260, lr = 1e-06
I0722 22:52:02.749956 23230 solver.cpp:243] Iteration 123270, loss = 2.71155
I0722 22:52:02.750300 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.2117 (* 1 = 1.2117 loss)
I0722 22:52:02.750370 23230 sgd_solver.cpp:138] Iteration 123270, lr = 1e-06
I0722 22:53:28.822664 23230 solver.cpp:243] Iteration 123280, loss = 2.43735
I0722 22:53:28.822901 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83449 (* 1 = 1.83449 loss)
I0722 22:53:29.231956 23230 sgd_solver.cpp:138] Iteration 123280, lr = 1e-06
I0722 22:54:54.423079 23230 solver.cpp:243] Iteration 123290, loss = 2.75525
I0722 22:54:54.423357 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31399 (* 1 = 2.31399 loss)
I0722 22:54:54.773224 23230 sgd_solver.cpp:138] Iteration 123290, lr = 1e-06
I0722 22:56:22.015749 23230 solver.cpp:243] Iteration 123300, loss = 2.50017
I0722 22:56:22.016016 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.68832 (* 1 = 2.68832 loss)
I0722 22:56:22.778800 23230 sgd_solver.cpp:138] Iteration 123300, lr = 1e-06
I0722 22:57:46.073264 23230 solver.cpp:243] Iteration 123310, loss = 2.78282
I0722 22:57:46.073581 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.52049 (* 1 = 5.52049 loss)
I0722 22:57:46.759017 23230 sgd_solver.cpp:138] Iteration 123310, lr = 1e-06
I0722 22:59:14.482435 23230 solver.cpp:243] Iteration 123320, loss = 2.53091
I0722 22:59:14.482692 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80412 (* 1 = 2.80412 loss)
I0722 22:59:14.842675 23230 sgd_solver.cpp:138] Iteration 123320, lr = 1e-06
I0722 23:00:38.729362 23230 solver.cpp:243] Iteration 123330, loss = 2.44512
I0722 23:00:38.729583 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.68003 (* 1 = 1.68003 loss)
I0722 23:00:38.729626 23230 sgd_solver.cpp:138] Iteration 123330, lr = 1e-06
I0722 23:02:05.407977 23230 solver.cpp:243] Iteration 123340, loss = 2.40422
I0722 23:02:05.408241 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24493 (* 1 = 2.24493 loss)
I0722 23:02:05.765000 23230 sgd_solver.cpp:138] Iteration 123340, lr = 1e-06
I0722 23:03:30.833093 23230 solver.cpp:243] Iteration 123350, loss = 2.49183
I0722 23:03:30.833310 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.95438 (* 1 = 3.95438 loss)
I0722 23:03:30.833351 23230 sgd_solver.cpp:138] Iteration 123350, lr = 1e-06
I0722 23:04:55.413102 23230 solver.cpp:243] Iteration 123360, loss = 2.66607
I0722 23:04:55.413380 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25252 (* 1 = 1.25252 loss)
I0722 23:04:55.413512 23230 sgd_solver.cpp:138] Iteration 123360, lr = 1e-06
I0722 23:06:20.066344 23230 solver.cpp:243] Iteration 123370, loss = 2.4818
I0722 23:06:20.066579 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0722 23:06:20.473829 23230 sgd_solver.cpp:138] Iteration 123370, lr = 1e-06
I0722 23:07:45.450249 23230 solver.cpp:243] Iteration 123380, loss = 2.40255
I0722 23:07:45.450516 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.86343 (* 1 = 1.86343 loss)
I0722 23:07:45.450562 23230 sgd_solver.cpp:138] Iteration 123380, lr = 1e-06
I0722 23:09:14.468060 23230 solver.cpp:243] Iteration 123390, loss = 2.3899
I0722 23:09:14.468305 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.14272 (* 1 = 4.14272 loss)
I0722 23:09:14.468348 23230 sgd_solver.cpp:138] Iteration 123390, lr = 1e-06
I0722 23:10:41.047168 23230 solver.cpp:243] Iteration 123400, loss = 2.61598
I0722 23:10:41.047451 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.18738 (* 1 = 3.18738 loss)
I0722 23:10:41.047562 23230 sgd_solver.cpp:138] Iteration 123400, lr = 1e-06
I0722 23:12:07.095090 23230 solver.cpp:243] Iteration 123410, loss = 2.55113
I0722 23:12:07.095363 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.39971 (* 1 = 1.39971 loss)
I0722 23:12:07.095500 23230 sgd_solver.cpp:138] Iteration 123410, lr = 1e-06
I0722 23:13:33.803398 23230 solver.cpp:243] Iteration 123420, loss = 2.52268
I0722 23:13:33.803661 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04741 (* 1 = 3.04741 loss)
I0722 23:13:34.165004 23230 sgd_solver.cpp:138] Iteration 123420, lr = 1e-06
I0722 23:15:01.905273 23230 solver.cpp:243] Iteration 123430, loss = 2.53553
I0722 23:15:01.905555 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.20901 (* 1 = 3.20901 loss)
I0722 23:15:01.905629 23230 sgd_solver.cpp:138] Iteration 123430, lr = 1e-06
I0722 23:16:28.716179 23230 solver.cpp:243] Iteration 123440, loss = 2.5487
I0722 23:16:28.716485 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.61556 (* 1 = 3.61556 loss)
I0722 23:16:28.716600 23230 sgd_solver.cpp:138] Iteration 123440, lr = 1e-06
I0722 23:17:54.416905 23230 solver.cpp:243] Iteration 123450, loss = 2.48332
I0722 23:17:54.417204 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04424 (* 1 = 3.04424 loss)
I0722 23:17:54.417285 23230 sgd_solver.cpp:138] Iteration 123450, lr = 1e-06
I0722 23:19:18.022768 23230 solver.cpp:243] Iteration 123460, loss = 2.51737
I0722 23:19:18.023006 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.89068 (* 1 = 1.89068 loss)
I0722 23:19:18.023056 23230 sgd_solver.cpp:138] Iteration 123460, lr = 1e-06
I0722 23:20:42.095831 23230 solver.cpp:243] Iteration 123470, loss = 2.60277
I0722 23:20:42.096089 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.37121 (* 1 = 1.37121 loss)
I0722 23:20:42.096195 23230 sgd_solver.cpp:138] Iteration 123470, lr = 1e-06
I0722 23:22:07.489204 23230 solver.cpp:243] Iteration 123480, loss = 2.59178
I0722 23:22:07.489473 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.968534 (* 1 = 0.968534 loss)
I0722 23:22:07.489589 23230 sgd_solver.cpp:138] Iteration 123480, lr = 1e-06
I0722 23:23:34.552940 23230 solver.cpp:243] Iteration 123490, loss = 2.58706
I0722 23:23:34.553179 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.71854 (* 1 = 1.71854 loss)
I0722 23:23:34.553220 23230 sgd_solver.cpp:138] Iteration 123490, lr = 1e-06
I0722 23:25:03.537297 23230 solver.cpp:243] Iteration 123500, loss = 2.42308
I0722 23:25:03.537544 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.52299 (* 1 = 1.52299 loss)
I0722 23:25:04.309717 23230 sgd_solver.cpp:138] Iteration 123500, lr = 1e-06
I0722 23:26:29.484441 23230 solver.cpp:243] Iteration 123510, loss = 2.6106
I0722 23:26:29.484788 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.11035 (* 1 = 4.11035 loss)
I0722 23:26:29.848805 23230 sgd_solver.cpp:138] Iteration 123510, lr = 1e-06
I0722 23:27:56.734594 23230 solver.cpp:243] Iteration 123520, loss = 2.48231
I0722 23:27:56.734912 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.02945 (* 1 = 2.02945 loss)
I0722 23:27:57.089078 23230 sgd_solver.cpp:138] Iteration 123520, lr = 1e-06
I0722 23:29:22.794467 23230 solver.cpp:243] Iteration 123530, loss = 2.45648
I0722 23:29:22.794811 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96444 (* 1 = 2.96444 loss)
I0722 23:29:22.794919 23230 sgd_solver.cpp:138] Iteration 123530, lr = 1e-06
I0722 23:30:49.580996 23230 solver.cpp:243] Iteration 123540, loss = 2.44748
I0722 23:30:49.581259 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.80731 (* 1 = 1.80731 loss)
I0722 23:30:49.581338 23230 sgd_solver.cpp:138] Iteration 123540, lr = 1e-06
I0722 23:32:13.934355 23230 solver.cpp:243] Iteration 123550, loss = 2.37078
I0722 23:32:13.934593 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.89346 (* 1 = 3.89346 loss)
I0722 23:32:13.934633 23230 sgd_solver.cpp:138] Iteration 123550, lr = 1e-06
I0722 23:33:41.317271 23230 solver.cpp:243] Iteration 123560, loss = 2.53239
I0722 23:33:41.317576 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27766 (* 1 = 2.27766 loss)
I0722 23:33:41.317708 23230 sgd_solver.cpp:138] Iteration 123560, lr = 1e-06
I0722 23:35:06.210486 23230 solver.cpp:243] Iteration 123570, loss = 2.368
I0722 23:35:06.210769 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47814 (* 1 = 2.47814 loss)
I0722 23:35:06.210860 23230 sgd_solver.cpp:138] Iteration 123570, lr = 1e-06
I0722 23:36:32.394311 23230 solver.cpp:243] Iteration 123580, loss = 2.50955
I0722 23:36:32.394613 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.41828 (* 1 = 4.41828 loss)
I0722 23:36:32.394670 23230 sgd_solver.cpp:138] Iteration 123580, lr = 1e-06
I0722 23:37:59.486588 23230 solver.cpp:243] Iteration 123590, loss = 2.59949
I0722 23:37:59.486886 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31991 (* 1 = 2.31991 loss)
I0722 23:37:59.487002 23230 sgd_solver.cpp:138] Iteration 123590, lr = 1e-06
I0722 23:39:27.364060 23230 solver.cpp:243] Iteration 123600, loss = 2.5381
I0722 23:39:27.364281 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.66927 (* 1 = 2.66927 loss)
I0722 23:39:27.364326 23230 sgd_solver.cpp:138] Iteration 123600, lr = 1e-06
I0722 23:40:50.516883 23230 solver.cpp:243] Iteration 123610, loss = 2.39878
I0722 23:40:50.517130 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.8898 (* 1 = 3.8898 loss)
I0722 23:40:50.517195 23230 sgd_solver.cpp:138] Iteration 123610, lr = 1e-06
I0722 23:42:17.164067 23230 solver.cpp:243] Iteration 123620, loss = 2.64065
I0722 23:42:17.164330 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26327 (* 1 = 2.26327 loss)
I0722 23:42:17.164397 23230 sgd_solver.cpp:138] Iteration 123620, lr = 1e-06
I0722 23:43:43.019896 23230 solver.cpp:243] Iteration 123630, loss = 2.47897
I0722 23:43:43.020190 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.60814 (* 1 = 1.60814 loss)
I0722 23:43:43.382230 23230 sgd_solver.cpp:138] Iteration 123630, lr = 1e-06
I0722 23:45:10.234259 23230 solver.cpp:243] Iteration 123640, loss = 2.57554
I0722 23:45:10.234521 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.14323 (* 1 = 2.14323 loss)
I0722 23:45:10.234645 23230 sgd_solver.cpp:138] Iteration 123640, lr = 1e-06
I0722 23:46:36.857141 23230 solver.cpp:243] Iteration 123650, loss = 2.48969
I0722 23:46:36.857390 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.25957 (* 1 = 3.25957 loss)
I0722 23:46:37.209611 23230 sgd_solver.cpp:138] Iteration 123650, lr = 1e-06
I0722 23:48:01.005264 23230 solver.cpp:243] Iteration 123660, loss = 2.55254
I0722 23:48:01.005508 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.34144 (* 1 = 1.34144 loss)
I0722 23:48:01.005549 23230 sgd_solver.cpp:138] Iteration 123660, lr = 1e-06
I0722 23:49:24.777384 23230 solver.cpp:243] Iteration 123670, loss = 2.54805
I0722 23:49:24.777593 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8348 (* 1 = 2.8348 loss)
I0722 23:49:24.777642 23230 sgd_solver.cpp:138] Iteration 123670, lr = 1e-06
I0722 23:50:45.441977 23230 solver.cpp:243] Iteration 123680, loss = 2.5899
I0722 23:50:45.442278 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.88283 (* 1 = 0.88283 loss)
I0722 23:50:45.442390 23230 sgd_solver.cpp:138] Iteration 123680, lr = 1e-06
I0722 23:52:10.365942 23230 solver.cpp:243] Iteration 123690, loss = 2.33527
I0722 23:52:10.366255 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.47476 (* 1 = 1.47476 loss)
I0722 23:52:11.159427 23230 sgd_solver.cpp:138] Iteration 123690, lr = 1e-06
I0722 23:53:36.494784 23230 solver.cpp:243] Iteration 123700, loss = 2.62919
I0722 23:53:36.495085 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74456 (* 1 = 2.74456 loss)
I0722 23:53:36.495127 23230 sgd_solver.cpp:138] Iteration 123700, lr = 1e-06
I0722 23:55:05.076838 23230 solver.cpp:243] Iteration 123710, loss = 2.30793
I0722 23:55:05.077164 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.23291 (* 1 = 3.23291 loss)
I0722 23:55:05.077294 23230 sgd_solver.cpp:138] Iteration 123710, lr = 1e-06
I0722 23:56:33.395642 23230 solver.cpp:243] Iteration 123720, loss = 2.60628
I0722 23:56:33.395931 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31681 (* 1 = 2.31681 loss)
I0722 23:56:33.396044 23230 sgd_solver.cpp:138] Iteration 123720, lr = 1e-06
I0722 23:58:01.642057 23230 solver.cpp:243] Iteration 123730, loss = 2.69692
I0722 23:58:01.642369 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.67243 (* 1 = 2.67243 loss)
I0722 23:58:01.642501 23230 sgd_solver.cpp:138] Iteration 123730, lr = 1e-06
I0722 23:59:27.885200 23230 solver.cpp:243] Iteration 123740, loss = 2.74756
I0722 23:59:27.885452 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82509 (* 1 = 1.82509 loss)
I0722 23:59:27.885536 23230 sgd_solver.cpp:138] Iteration 123740, lr = 1e-06
I0723 00:00:54.261328 23230 solver.cpp:243] Iteration 123750, loss = 2.52626
I0723 00:00:54.261588 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.64836 (* 1 = 3.64836 loss)
I0723 00:00:54.261644 23230 sgd_solver.cpp:138] Iteration 123750, lr = 1e-06
I0723 00:02:21.361459 23230 solver.cpp:243] Iteration 123760, loss = 2.35436
I0723 00:02:21.361698 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.33351 (* 1 = 2.33351 loss)
I0723 00:02:21.361742 23230 sgd_solver.cpp:138] Iteration 123760, lr = 1e-06
I0723 00:03:48.431042 23230 solver.cpp:243] Iteration 123770, loss = 2.5059
I0723 00:03:48.431320 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.66197 (* 1 = 1.66197 loss)
I0723 00:03:48.431421 23230 sgd_solver.cpp:138] Iteration 123770, lr = 1e-06
I0723 00:05:15.182418 23230 solver.cpp:243] Iteration 123780, loss = 2.62594
I0723 00:05:15.182713 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.45281 (* 1 = 2.45281 loss)
I0723 00:05:15.182813 23230 sgd_solver.cpp:138] Iteration 123780, lr = 1e-06
I0723 00:06:41.481938 23230 solver.cpp:243] Iteration 123790, loss = 2.41714
I0723 00:06:41.482272 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.32282 (* 1 = 2.32282 loss)
I0723 00:06:41.482395 23230 sgd_solver.cpp:138] Iteration 123790, lr = 1e-06
I0723 00:08:07.385008 23230 solver.cpp:243] Iteration 123800, loss = 2.33428
I0723 00:08:07.385234 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.08419 (* 1 = 3.08419 loss)
I0723 00:08:07.385277 23230 sgd_solver.cpp:138] Iteration 123800, lr = 1e-06
I0723 00:09:35.495561 23230 solver.cpp:243] Iteration 123810, loss = 2.69589
I0723 00:09:35.495801 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.11965 (* 1 = 2.11965 loss)
I0723 00:09:35.495848 23230 sgd_solver.cpp:138] Iteration 123810, lr = 1e-06
I0723 00:11:03.773406 23230 solver.cpp:243] Iteration 123820, loss = 2.55507
I0723 00:11:03.773711 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.50865 (* 1 = 1.50865 loss)
I0723 00:11:03.773813 23230 sgd_solver.cpp:138] Iteration 123820, lr = 1e-06
I0723 00:12:30.225525 23230 solver.cpp:243] Iteration 123830, loss = 2.6341
I0723 00:12:30.225812 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.11925 (* 1 = 3.11925 loss)
I0723 00:12:30.225934 23230 sgd_solver.cpp:138] Iteration 123830, lr = 1e-06
I0723 00:13:56.038290 23230 solver.cpp:243] Iteration 123840, loss = 2.506
I0723 00:13:56.038592 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.16781 (* 1 = 2.16781 loss)
I0723 00:13:56.038640 23230 sgd_solver.cpp:138] Iteration 123840, lr = 1e-06
I0723 00:15:20.778666 23230 solver.cpp:243] Iteration 123850, loss = 2.5649
I0723 00:15:20.778930 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.85431 (* 1 = 1.85431 loss)
I0723 00:15:20.779042 23230 sgd_solver.cpp:138] Iteration 123850, lr = 1e-06
I0723 00:16:46.393076 23230 solver.cpp:243] Iteration 123860, loss = 2.86298
I0723 00:16:46.393357 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.52826 (* 1 = 3.52826 loss)
I0723 00:16:46.393452 23230 sgd_solver.cpp:138] Iteration 123860, lr = 1e-06
I0723 00:18:13.368589 23230 solver.cpp:243] Iteration 123870, loss = 2.61666
I0723 00:18:13.368902 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.40753 (* 1 = 1.40753 loss)
I0723 00:18:13.369020 23230 sgd_solver.cpp:138] Iteration 123870, lr = 1e-06
I0723 00:19:40.507005 23230 solver.cpp:243] Iteration 123880, loss = 2.67933
I0723 00:19:40.507292 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.59723 (* 1 = 4.59723 loss)
I0723 00:19:40.860527 23230 sgd_solver.cpp:138] Iteration 123880, lr = 1e-06
I0723 00:21:04.496048 23230 solver.cpp:243] Iteration 123890, loss = 2.57325
I0723 00:21:04.496317 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57489 (* 1 = 2.57489 loss)
I0723 00:21:05.864135 23230 sgd_solver.cpp:138] Iteration 123890, lr = 1e-06
I0723 00:22:30.456991 23230 solver.cpp:243] Iteration 123900, loss = 2.61516
I0723 00:22:30.457207 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7228 (* 1 = 2.7228 loss)
I0723 00:22:30.457248 23230 sgd_solver.cpp:138] Iteration 123900, lr = 1e-06
I0723 00:23:54.517457 23230 solver.cpp:243] Iteration 123910, loss = 2.45202
I0723 00:23:54.517722 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.79254 (* 1 = 3.79254 loss)
I0723 00:23:54.517829 23230 sgd_solver.cpp:138] Iteration 123910, lr = 1e-06
I0723 00:25:18.723268 23230 solver.cpp:243] Iteration 123920, loss = 2.45391
I0723 00:25:18.723551 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.68459 (* 1 = 1.68459 loss)
I0723 00:25:19.986835 23230 sgd_solver.cpp:138] Iteration 123920, lr = 1e-06
I0723 00:26:42.207891 23230 solver.cpp:243] Iteration 123930, loss = 2.63831
I0723 00:26:42.208137 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.79028 (* 1 = 2.79028 loss)
I0723 00:26:42.603889 23230 sgd_solver.cpp:138] Iteration 123930, lr = 1e-06
I0723 00:28:07.228140 23230 solver.cpp:243] Iteration 123940, loss = 2.5058
I0723 00:28:07.228431 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.13052 (* 1 = 3.13052 loss)
I0723 00:28:07.228531 23230 sgd_solver.cpp:138] Iteration 123940, lr = 1e-06
I0723 00:29:32.900151 23230 solver.cpp:243] Iteration 123950, loss = 2.28658
I0723 00:29:32.900393 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.37288 (* 1 = 1.37288 loss)
I0723 00:29:32.900446 23230 sgd_solver.cpp:138] Iteration 123950, lr = 1e-06
I0723 00:30:57.023856 23230 solver.cpp:243] Iteration 123960, loss = 2.59539
I0723 00:30:57.024076 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17487 (* 1 = 2.17487 loss)
I0723 00:30:57.024118 23230 sgd_solver.cpp:138] Iteration 123960, lr = 1e-06
I0723 00:32:19.360906 23230 solver.cpp:243] Iteration 123970, loss = 2.79214
I0723 00:32:19.361151 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.91657 (* 1 = 1.91657 loss)
I0723 00:32:19.361193 23230 sgd_solver.cpp:138] Iteration 123970, lr = 1e-06
I0723 00:33:44.278357 23230 solver.cpp:243] Iteration 123980, loss = 2.48284
I0723 00:33:44.278620 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.15797 (* 1 = 3.15797 loss)
I0723 00:33:44.278739 23230 sgd_solver.cpp:138] Iteration 123980, lr = 1e-06
I0723 00:35:07.160815 23230 solver.cpp:243] Iteration 123990, loss = 2.60184
I0723 00:35:07.161026 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.58109 (* 1 = 1.58109 loss)
I0723 00:35:07.906620 23230 sgd_solver.cpp:138] Iteration 123990, lr = 1e-06
I0723 00:36:22.907847 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_124000.caffemodel
I0723 00:36:23.597822 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_124000.solverstate
I0723 00:36:23.748713 23230 solver.cpp:433] Iteration 124000, Testing net (#0)
I0723 00:36:23.748898 23230 net.cpp:693] Ignoring source layer mbox_loss
I0723 00:36:27.053730 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.61905
I0723 00:36:35.660961 23230 solver.cpp:243] Iteration 124000, loss = 2.42663
I0723 00:36:35.661039 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.7883 (* 1 = 3.7883 loss)
I0723 00:36:35.661073 23230 sgd_solver.cpp:138] Iteration 124000, lr = 1e-06
I0723 00:38:01.257771 23230 solver.cpp:243] Iteration 124010, loss = 2.50038
I0723 00:38:01.258134 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.91289 (* 1 = 2.91289 loss)
I0723 00:38:01.258241 23230 sgd_solver.cpp:138] Iteration 124010, lr = 1e-06
I0723 00:39:25.410795 23230 solver.cpp:243] Iteration 124020, loss = 2.6592
I0723 00:39:25.411037 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.29993 (* 1 = 2.29993 loss)
I0723 00:39:25.411084 23230 sgd_solver.cpp:138] Iteration 124020, lr = 1e-06
I0723 00:40:48.804935 23230 solver.cpp:243] Iteration 124030, loss = 2.56987
I0723 00:40:48.805191 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2221 (* 1 = 2.2221 loss)
I0723 00:40:48.805249 23230 sgd_solver.cpp:138] Iteration 124030, lr = 1e-06
I0723 00:42:13.089933 23230 solver.cpp:243] Iteration 124040, loss = 2.74392
I0723 00:42:13.090181 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.63892 (* 1 = 1.63892 loss)
I0723 00:42:13.090234 23230 sgd_solver.cpp:138] Iteration 124040, lr = 1e-06
I0723 00:43:37.715194 23230 solver.cpp:243] Iteration 124050, loss = 2.37362
I0723 00:43:37.715458 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.98355 (* 1 = 1.98355 loss)
I0723 00:43:37.715551 23230 sgd_solver.cpp:138] Iteration 124050, lr = 1e-06
I0723 00:45:02.373814 23230 solver.cpp:243] Iteration 124060, loss = 2.48921
I0723 00:45:02.374029 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.27274 (* 1 = 2.27274 loss)
I0723 00:45:02.374083 23230 sgd_solver.cpp:138] Iteration 124060, lr = 1e-06
I0723 00:46:31.370240 23230 solver.cpp:243] Iteration 124070, loss = 2.5161
I0723 00:46:31.370524 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.47452 (* 1 = 3.47452 loss)
I0723 00:46:31.370648 23230 sgd_solver.cpp:138] Iteration 124070, lr = 1e-06
I0723 00:48:00.165997 23230 solver.cpp:243] Iteration 124080, loss = 2.58497
I0723 00:48:00.166321 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.15828 (* 1 = 3.15828 loss)
I0723 00:48:00.166446 23230 sgd_solver.cpp:138] Iteration 124080, lr = 1e-06
I0723 00:49:29.128746 23230 solver.cpp:243] Iteration 124090, loss = 2.44187
I0723 00:49:29.129103 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.977217 (* 1 = 0.977217 loss)
I0723 00:49:29.129194 23230 sgd_solver.cpp:138] Iteration 124090, lr = 1e-06
I0723 00:50:56.088762 23230 solver.cpp:243] Iteration 124100, loss = 2.42377
I0723 00:50:56.089002 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.49513 (* 1 = 2.49513 loss)
I0723 00:50:56.089047 23230 sgd_solver.cpp:138] Iteration 124100, lr = 1e-06
I0723 00:52:24.856125 23230 solver.cpp:243] Iteration 124110, loss = 2.44345
I0723 00:52:24.856410 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.66639 (* 1 = 3.66639 loss)
I0723 00:52:24.856509 23230 sgd_solver.cpp:138] Iteration 124110, lr = 1e-06
I0723 00:53:52.488551 23230 solver.cpp:243] Iteration 124120, loss = 2.48972
I0723 00:53:52.488826 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.64662 (* 1 = 2.64662 loss)
I0723 00:53:52.842802 23230 sgd_solver.cpp:138] Iteration 124120, lr = 1e-06
I0723 00:55:18.733528 23230 solver.cpp:243] Iteration 124130, loss = 2.63521
I0723 00:55:18.733858 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17526 (* 1 = 3.17526 loss)
I0723 00:55:18.733968 23230 sgd_solver.cpp:138] Iteration 124130, lr = 1e-06
I0723 00:56:46.752432 23230 solver.cpp:243] Iteration 124140, loss = 2.36787
I0723 00:56:46.752660 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8536 (* 1 = 2.8536 loss)
I0723 00:56:46.752704 23230 sgd_solver.cpp:138] Iteration 124140, lr = 1e-06
I0723 00:58:13.570207 23230 solver.cpp:243] Iteration 124150, loss = 2.91579
I0723 00:58:13.570451 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31905 (* 1 = 2.31905 loss)
I0723 00:58:14.282698 23230 sgd_solver.cpp:138] Iteration 124150, lr = 1e-06
I0723 00:59:41.424449 23230 solver.cpp:243] Iteration 124160, loss = 2.36031
I0723 00:59:41.424707 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.3839 (* 1 = 2.3839 loss)
I0723 00:59:41.424775 23230 sgd_solver.cpp:138] Iteration 124160, lr = 1e-06
I0723 01:01:09.733960 23230 solver.cpp:243] Iteration 124170, loss = 2.57744
I0723 01:01:09.734251 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.37664 (* 1 = 1.37664 loss)
I0723 01:01:10.158358 23230 sgd_solver.cpp:138] Iteration 124170, lr = 1e-06
I0723 01:02:36.937680 23230 solver.cpp:243] Iteration 124180, loss = 2.57338
I0723 01:02:36.937949 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7 (* 1 = 2.7 loss)
I0723 01:02:36.938050 23230 sgd_solver.cpp:138] Iteration 124180, lr = 1e-06
I0723 01:04:01.658287 23230 solver.cpp:243] Iteration 124190, loss = 2.62114
I0723 01:04:01.658545 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.7978 (* 1 = 2.7978 loss)
I0723 01:04:01.658623 23230 sgd_solver.cpp:138] Iteration 124190, lr = 1e-06
I0723 01:05:26.578006 23230 solver.cpp:243] Iteration 124200, loss = 2.66507
I0723 01:05:26.578299 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9308 (* 1 = 1.9308 loss)
I0723 01:05:26.578339 23230 sgd_solver.cpp:138] Iteration 124200, lr = 1e-06
I0723 01:06:47.674893 23230 solver.cpp:243] Iteration 124210, loss = 2.63803
I0723 01:06:47.675192 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.8538 (* 1 = 3.8538 loss)
I0723 01:06:47.675302 23230 sgd_solver.cpp:138] Iteration 124210, lr = 1e-06
I0723 01:08:10.645179 23230 solver.cpp:243] Iteration 124220, loss = 2.41193
I0723 01:08:10.645473 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.48745 (* 1 = 3.48745 loss)
I0723 01:08:10.645565 23230 sgd_solver.cpp:138] Iteration 124220, lr = 1e-06
I0723 01:09:36.272660 23230 solver.cpp:243] Iteration 124230, loss = 2.71545
I0723 01:09:36.272895 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.28545 (* 1 = 1.28545 loss)
I0723 01:09:36.272940 23230 sgd_solver.cpp:138] Iteration 124230, lr = 1e-06
I0723 01:11:01.974980 23230 solver.cpp:243] Iteration 124240, loss = 2.42058
I0723 01:11:01.975281 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.95271 (* 1 = 3.95271 loss)
I0723 01:11:01.975381 23230 sgd_solver.cpp:138] Iteration 124240, lr = 1e-06
I0723 01:12:27.611798 23230 solver.cpp:243] Iteration 124250, loss = 2.72969
I0723 01:12:27.612025 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.44785 (* 1 = 3.44785 loss)
I0723 01:12:27.612074 23230 sgd_solver.cpp:138] Iteration 124250, lr = 1e-06
I0723 01:13:52.659863 23230 solver.cpp:243] Iteration 124260, loss = 2.67955
I0723 01:13:52.660161 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.46817 (* 1 = 4.46817 loss)
I0723 01:13:53.762142 23230 sgd_solver.cpp:138] Iteration 124260, lr = 1e-06
I0723 01:15:21.838618 23230 solver.cpp:243] Iteration 124270, loss = 2.42696
I0723 01:15:21.838906 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38223 (* 1 = 2.38223 loss)
I0723 01:15:21.838995 23230 sgd_solver.cpp:138] Iteration 124270, lr = 1e-06
I0723 01:16:45.052263 23230 solver.cpp:243] Iteration 124280, loss = 2.72259
I0723 01:16:45.052573 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.86314 (* 1 = 1.86314 loss)
I0723 01:16:45.052692 23230 sgd_solver.cpp:138] Iteration 124280, lr = 1e-06
I0723 01:18:09.960093 23230 solver.cpp:243] Iteration 124290, loss = 2.63717
I0723 01:18:09.960443 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4383 (* 1 = 2.4383 loss)
I0723 01:18:10.770639 23230 sgd_solver.cpp:138] Iteration 124290, lr = 1e-06
I0723 01:19:34.410770 23230 solver.cpp:243] Iteration 124300, loss = 2.32443
I0723 01:19:34.411052 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61803 (* 1 = 2.61803 loss)
I0723 01:19:34.411208 23230 sgd_solver.cpp:138] Iteration 124300, lr = 1e-06
I0723 01:21:01.858127 23230 solver.cpp:243] Iteration 124310, loss = 2.46529
I0723 01:21:01.858366 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.59169 (* 1 = 2.59169 loss)
I0723 01:21:03.246948 23230 sgd_solver.cpp:138] Iteration 124310, lr = 1e-06
I0723 01:22:29.867661 23230 solver.cpp:243] Iteration 124320, loss = 2.46237
I0723 01:22:29.868422 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.5354 (* 1 = 1.5354 loss)
I0723 01:22:29.868515 23230 sgd_solver.cpp:138] Iteration 124320, lr = 1e-06
I0723 01:23:55.478358 23230 solver.cpp:243] Iteration 124330, loss = 2.45588
I0723 01:23:55.478684 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.912 (* 1 = 1.912 loss)
I0723 01:23:55.478791 23230 sgd_solver.cpp:138] Iteration 124330, lr = 1e-06
I0723 01:25:22.491655 23230 solver.cpp:243] Iteration 124340, loss = 2.55645
I0723 01:25:22.492096 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.4619 (* 1 = 3.4619 loss)
I0723 01:25:22.492156 23230 sgd_solver.cpp:138] Iteration 124340, lr = 1e-06
I0723 01:26:51.300683 23230 solver.cpp:243] Iteration 124350, loss = 2.68578
I0723 01:26:51.300925 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.99381 (* 1 = 1.99381 loss)
I0723 01:26:51.300969 23230 sgd_solver.cpp:138] Iteration 124350, lr = 1e-06
I0723 01:28:17.190881 23230 solver.cpp:243] Iteration 124360, loss = 2.53249
I0723 01:28:17.191102 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.84512 (* 1 = 3.84512 loss)
I0723 01:28:17.191149 23230 sgd_solver.cpp:138] Iteration 124360, lr = 1e-06
I0723 01:29:45.698827 23230 solver.cpp:243] Iteration 124370, loss = 2.52032
I0723 01:29:45.699054 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.45841 (* 1 = 1.45841 loss)
I0723 01:29:45.699131 23230 sgd_solver.cpp:138] Iteration 124370, lr = 1e-06
I0723 01:31:09.480172 23230 solver.cpp:243] Iteration 124380, loss = 2.56864
I0723 01:31:09.480435 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38239 (* 1 = 2.38239 loss)
I0723 01:31:09.480543 23230 sgd_solver.cpp:138] Iteration 124380, lr = 1e-06
I0723 01:32:36.117262 23230 solver.cpp:243] Iteration 124390, loss = 2.72685
I0723 01:32:36.117620 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.04497 (* 1 = 2.04497 loss)
I0723 01:32:36.478233 23230 sgd_solver.cpp:138] Iteration 124390, lr = 1e-06
I0723 01:34:02.604219 23230 solver.cpp:243] Iteration 124400, loss = 2.3566
I0723 01:34:02.604459 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.21421 (* 1 = 2.21421 loss)
I0723 01:34:02.604502 23230 sgd_solver.cpp:138] Iteration 124400, lr = 1e-06
I0723 01:35:30.706043 23230 solver.cpp:243] Iteration 124410, loss = 2.57409
I0723 01:35:30.706311 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.15725 (* 1 = 2.15725 loss)
I0723 01:35:30.706384 23230 sgd_solver.cpp:138] Iteration 124410, lr = 1e-06
I0723 01:36:59.959610 23230 solver.cpp:243] Iteration 124420, loss = 2.79086
I0723 01:36:59.959964 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27416 (* 1 = 3.27416 loss)
I0723 01:36:59.960034 23230 sgd_solver.cpp:138] Iteration 124420, lr = 1e-06
I0723 01:38:27.722630 23230 solver.cpp:243] Iteration 124430, loss = 2.52164
I0723 01:38:27.722980 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.93634 (* 1 = 3.93634 loss)
I0723 01:38:27.723109 23230 sgd_solver.cpp:138] Iteration 124430, lr = 1e-06
I0723 01:39:55.823333 23230 solver.cpp:243] Iteration 124440, loss = 2.38628
I0723 01:39:55.823593 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2319 (* 1 = 2.2319 loss)
I0723 01:39:55.823637 23230 sgd_solver.cpp:138] Iteration 124440, lr = 1e-06
I0723 01:41:21.682744 23230 solver.cpp:243] Iteration 124450, loss = 2.61244
I0723 01:41:21.683022 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.52491 (* 1 = 1.52491 loss)
I0723 01:41:21.683116 23230 sgd_solver.cpp:138] Iteration 124450, lr = 1e-06
I0723 01:42:46.136773 23230 solver.cpp:243] Iteration 124460, loss = 2.72054
I0723 01:42:46.137051 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.13309 (* 1 = 2.13309 loss)
I0723 01:42:46.137168 23230 sgd_solver.cpp:138] Iteration 124460, lr = 1e-06
I0723 01:44:13.382644 23230 solver.cpp:243] Iteration 124470, loss = 2.69583
I0723 01:44:13.383378 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.0583 (* 1 = 3.0583 loss)
I0723 01:44:13.383428 23230 sgd_solver.cpp:138] Iteration 124470, lr = 1e-06
I0723 01:45:40.497251 23230 solver.cpp:243] Iteration 124480, loss = 2.49958
I0723 01:45:40.497543 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.75121 (* 1 = 1.75121 loss)
I0723 01:45:40.497654 23230 sgd_solver.cpp:138] Iteration 124480, lr = 1e-06
I0723 01:47:07.144418 23230 solver.cpp:243] Iteration 124490, loss = 2.46571
I0723 01:47:07.144731 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.12736 (* 1 = 1.12736 loss)
I0723 01:47:07.496698 23230 sgd_solver.cpp:138] Iteration 124490, lr = 1e-06
I0723 01:48:34.043526 23230 solver.cpp:243] Iteration 124500, loss = 2.57317
I0723 01:48:34.043845 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.21497 (* 1 = 3.21497 loss)
I0723 01:48:34.043947 23230 sgd_solver.cpp:138] Iteration 124500, lr = 1e-06
I0723 01:50:01.636020 23230 solver.cpp:243] Iteration 124510, loss = 2.44124
I0723 01:50:01.636327 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.1278 (* 1 = 2.1278 loss)
I0723 01:50:01.636473 23230 sgd_solver.cpp:138] Iteration 124510, lr = 1e-06
I0723 01:51:30.036710 23230 solver.cpp:243] Iteration 124520, loss = 2.72351
I0723 01:51:30.037060 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.40278 (* 1 = 4.40278 loss)
I0723 01:51:30.873072 23230 sgd_solver.cpp:138] Iteration 124520, lr = 1e-06
I0723 01:52:59.808606 23230 solver.cpp:243] Iteration 124530, loss = 2.48697
I0723 01:52:59.808874 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.2849 (* 1 = 2.2849 loss)
I0723 01:52:59.808941 23230 sgd_solver.cpp:138] Iteration 124530, lr = 1e-06
I0723 01:54:28.204728 23230 solver.cpp:243] Iteration 124540, loss = 2.53841
I0723 01:54:28.204974 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.07378 (* 1 = 3.07378 loss)
I0723 01:54:28.205024 23230 sgd_solver.cpp:138] Iteration 124540, lr = 1e-06
I0723 01:55:54.204690 23230 solver.cpp:243] Iteration 124550, loss = 2.58218
I0723 01:55:54.204983 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.58485 (* 1 = 2.58485 loss)
I0723 01:55:54.205073 23230 sgd_solver.cpp:138] Iteration 124550, lr = 1e-06
I0723 01:57:23.339316 23230 solver.cpp:243] Iteration 124560, loss = 2.38564
I0723 01:57:23.339602 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.37933 (* 1 = 3.37933 loss)
I0723 01:57:23.339720 23230 sgd_solver.cpp:138] Iteration 124560, lr = 1e-06
I0723 01:58:51.371505 23230 solver.cpp:243] Iteration 124570, loss = 2.58182
I0723 01:58:51.372447 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.20411 (* 1 = 2.20411 loss)
I0723 01:58:51.785755 23230 sgd_solver.cpp:138] Iteration 124570, lr = 1e-06
I0723 02:00:17.499876 23230 solver.cpp:243] Iteration 124580, loss = 2.40872
I0723 02:00:17.500186 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.78272 (* 1 = 3.78272 loss)
I0723 02:00:18.270768 23230 sgd_solver.cpp:138] Iteration 124580, lr = 1e-06
I0723 02:01:44.812801 23230 solver.cpp:243] Iteration 124590, loss = 2.70643
I0723 02:01:44.813118 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.784419 (* 1 = 0.784419 loss)
I0723 02:01:45.588619 23230 sgd_solver.cpp:138] Iteration 124590, lr = 1e-06
I0723 02:03:13.383270 23230 solver.cpp:243] Iteration 124600, loss = 2.72938
I0723 02:03:13.383579 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38322 (* 1 = 2.38322 loss)
I0723 02:03:13.383646 23230 sgd_solver.cpp:138] Iteration 124600, lr = 1e-06
I0723 02:04:38.829269 23230 solver.cpp:243] Iteration 124610, loss = 2.53769
I0723 02:04:38.829596 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.81994 (* 1 = 2.81994 loss)
I0723 02:04:38.829741 23230 sgd_solver.cpp:138] Iteration 124610, lr = 1e-06
I0723 02:06:06.162798 23230 solver.cpp:243] Iteration 124620, loss = 2.62768
I0723 02:06:06.163089 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.14639 (* 1 = 2.14639 loss)
I0723 02:06:06.163215 23230 sgd_solver.cpp:138] Iteration 124620, lr = 1e-06
I0723 02:07:33.876726 23230 solver.cpp:243] Iteration 124630, loss = 2.49999
I0723 02:07:33.876962 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.90994 (* 1 = 1.90994 loss)
I0723 02:07:33.877010 23230 sgd_solver.cpp:138] Iteration 124630, lr = 1e-06
I0723 02:09:00.667867 23230 solver.cpp:243] Iteration 124640, loss = 2.56521
I0723 02:09:00.668140 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.53097 (* 1 = 2.53097 loss)
I0723 02:09:00.668186 23230 sgd_solver.cpp:138] Iteration 124640, lr = 1e-06
I0723 02:10:25.540416 23230 solver.cpp:243] Iteration 124650, loss = 2.56257
I0723 02:10:25.540633 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.33166 (* 1 = 6.33166 loss)
I0723 02:10:25.540673 23230 sgd_solver.cpp:138] Iteration 124650, lr = 1e-06
I0723 02:11:50.498754 23230 solver.cpp:243] Iteration 124660, loss = 2.31641
I0723 02:11:50.499027 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.55876 (* 1 = 3.55876 loss)
I0723 02:11:51.293602 23230 sgd_solver.cpp:138] Iteration 124660, lr = 1e-06
I0723 02:13:19.560547 23230 solver.cpp:243] Iteration 124670, loss = 2.51582
I0723 02:13:19.562100 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.44149 (* 1 = 4.44149 loss)
I0723 02:13:19.562155 23230 sgd_solver.cpp:138] Iteration 124670, lr = 1e-06
I0723 02:14:48.053511 23230 solver.cpp:243] Iteration 124680, loss = 2.42422
I0723 02:14:48.053791 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.4497 (* 1 = 1.4497 loss)
I0723 02:14:48.443857 23230 sgd_solver.cpp:138] Iteration 124680, lr = 1e-06
I0723 02:16:15.461757 23230 solver.cpp:243] Iteration 124690, loss = 2.55309
I0723 02:16:15.462079 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27421 (* 1 = 3.27421 loss)
I0723 02:16:15.462210 23230 sgd_solver.cpp:138] Iteration 124690, lr = 1e-06
I0723 02:17:41.357476 23230 solver.cpp:243] Iteration 124700, loss = 2.31184
I0723 02:17:41.357770 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.70877 (* 1 = 1.70877 loss)
I0723 02:17:41.357888 23230 sgd_solver.cpp:138] Iteration 124700, lr = 1e-06
I0723 02:19:10.652891 23230 solver.cpp:243] Iteration 124710, loss = 2.715
I0723 02:19:10.653129 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.59555 (* 1 = 1.59555 loss)
I0723 02:19:10.653169 23230 sgd_solver.cpp:138] Iteration 124710, lr = 1e-06
I0723 02:20:37.400575 23230 solver.cpp:243] Iteration 124720, loss = 2.24324
I0723 02:20:37.400825 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61171 (* 1 = 2.61171 loss)
I0723 02:20:38.151036 23230 sgd_solver.cpp:138] Iteration 124720, lr = 1e-06
I0723 02:22:05.789338 23230 solver.cpp:243] Iteration 124730, loss = 2.51139
I0723 02:22:05.789608 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.78177 (* 1 = 1.78177 loss)
I0723 02:22:06.528857 23230 sgd_solver.cpp:138] Iteration 124730, lr = 1e-06
I0723 02:23:33.378581 23230 solver.cpp:243] Iteration 124740, loss = 2.50149
I0723 02:23:33.378840 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.44532 (* 1 = 2.44532 loss)
I0723 02:23:33.378968 23230 sgd_solver.cpp:138] Iteration 124740, lr = 1e-06
I0723 02:24:57.509299 23230 solver.cpp:243] Iteration 124750, loss = 2.71799
I0723 02:24:57.509620 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.78066 (* 1 = 3.78066 loss)
I0723 02:24:57.509667 23230 sgd_solver.cpp:138] Iteration 124750, lr = 1e-06
I0723 02:26:24.638170 23230 solver.cpp:243] Iteration 124760, loss = 2.84213
I0723 02:26:24.638429 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96733 (* 1 = 2.96733 loss)
I0723 02:26:24.638468 23230 sgd_solver.cpp:138] Iteration 124760, lr = 1e-06
I0723 02:27:52.987030 23230 solver.cpp:243] Iteration 124770, loss = 2.49766
I0723 02:27:52.987363 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17882 (* 1 = 3.17882 loss)
I0723 02:27:53.953565 23230 sgd_solver.cpp:138] Iteration 124770, lr = 1e-06
I0723 02:29:19.308460 23230 solver.cpp:243] Iteration 124780, loss = 2.47279
I0723 02:29:19.308766 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.24142 (* 1 = 2.24142 loss)
I0723 02:29:19.308881 23230 sgd_solver.cpp:138] Iteration 124780, lr = 1e-06
I0723 02:30:47.819461 23230 solver.cpp:243] Iteration 124790, loss = 2.65514
I0723 02:30:47.819743 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64067 (* 1 = 1.64067 loss)
I0723 02:30:47.819850 23230 sgd_solver.cpp:138] Iteration 124790, lr = 1e-06
I0723 02:32:13.064312 23230 solver.cpp:243] Iteration 124800, loss = 2.7726
I0723 02:32:13.064543 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.07778 (* 1 = 4.07778 loss)
I0723 02:32:13.461614 23230 sgd_solver.cpp:138] Iteration 124800, lr = 1e-06
I0723 02:33:37.675612 23230 solver.cpp:243] Iteration 124810, loss = 2.63555
I0723 02:33:37.675825 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.32711 (* 1 = 2.32711 loss)
I0723 02:33:37.675866 23230 sgd_solver.cpp:138] Iteration 124810, lr = 1e-06
I0723 02:35:02.202847 23230 solver.cpp:243] Iteration 124820, loss = 2.55038
I0723 02:35:02.203136 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04285 (* 1 = 3.04285 loss)
I0723 02:35:02.203256 23230 sgd_solver.cpp:138] Iteration 124820, lr = 1e-06
I0723 02:36:31.459678 23230 solver.cpp:243] Iteration 124830, loss = 2.63813
I0723 02:36:31.460719 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.85371 (* 1 = 4.85371 loss)
I0723 02:36:32.377203 23230 sgd_solver.cpp:138] Iteration 124830, lr = 1e-06
I0723 02:38:00.579646 23230 solver.cpp:243] Iteration 124840, loss = 2.59315
I0723 02:38:00.580997 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.61992 (* 1 = 2.61992 loss)
I0723 02:38:00.581048 23230 sgd_solver.cpp:138] Iteration 124840, lr = 1e-06
I0723 02:39:31.572357 23230 solver.cpp:243] Iteration 124850, loss = 2.3025
I0723 02:39:31.572607 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.54114 (* 1 = 1.54114 loss)
I0723 02:39:31.572677 23230 sgd_solver.cpp:138] Iteration 124850, lr = 1e-06
I0723 02:40:59.363098 23230 solver.cpp:243] Iteration 124860, loss = 2.72451
I0723 02:40:59.363443 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.06311 (* 1 = 2.06311 loss)
I0723 02:40:59.363510 23230 sgd_solver.cpp:138] Iteration 124860, lr = 1e-06
I0723 02:42:26.774480 23230 solver.cpp:243] Iteration 124870, loss = 2.89594
I0723 02:42:26.774804 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.61843 (* 1 = 1.61843 loss)
I0723 02:42:26.774909 23230 sgd_solver.cpp:138] Iteration 124870, lr = 1e-06
I0723 02:43:50.226069 23230 solver.cpp:243] Iteration 124880, loss = 2.50655
I0723 02:43:50.226400 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.18457 (* 1 = 2.18457 loss)
I0723 02:43:50.226526 23230 sgd_solver.cpp:138] Iteration 124880, lr = 1e-06
I0723 02:45:16.553649 23230 solver.cpp:243] Iteration 124890, loss = 2.55558
I0723 02:45:16.553948 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.46647 (* 1 = 2.46647 loss)
I0723 02:45:16.554103 23230 sgd_solver.cpp:138] Iteration 124890, lr = 1e-06
I0723 02:46:42.522769 23230 solver.cpp:243] Iteration 124900, loss = 2.56292
I0723 02:46:42.523017 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.45422 (* 1 = 2.45422 loss)
I0723 02:46:43.279673 23230 sgd_solver.cpp:138] Iteration 124900, lr = 1e-06
I0723 02:48:12.685962 23230 solver.cpp:243] Iteration 124910, loss = 2.56787
I0723 02:48:12.686285 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.3008 (* 1 = 1.3008 loss)
I0723 02:48:13.102035 23230 sgd_solver.cpp:138] Iteration 124910, lr = 1e-06
I0723 02:49:40.745932 23230 solver.cpp:243] Iteration 124920, loss = 2.60142
I0723 02:49:40.746177 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.59816 (* 1 = 3.59816 loss)
I0723 02:49:40.746229 23230 sgd_solver.cpp:138] Iteration 124920, lr = 1e-06
I0723 02:51:08.021505 23230 solver.cpp:243] Iteration 124930, loss = 2.57952
I0723 02:51:08.021824 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.53099 (* 1 = 3.53099 loss)
I0723 02:51:08.021945 23230 sgd_solver.cpp:138] Iteration 124930, lr = 1e-06
I0723 02:52:35.395023 23230 solver.cpp:243] Iteration 124940, loss = 2.50565
I0723 02:52:35.395332 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.65601 (* 1 = 2.65601 loss)
I0723 02:52:35.395460 23230 sgd_solver.cpp:138] Iteration 124940, lr = 1e-06
I0723 02:54:01.891177 23230 solver.cpp:243] Iteration 124950, loss = 2.58864
I0723 02:54:01.891432 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.70356 (* 1 = 2.70356 loss)
I0723 02:54:02.703958 23230 sgd_solver.cpp:138] Iteration 124950, lr = 1e-06
I0723 02:55:26.932677 23230 solver.cpp:243] Iteration 124960, loss = 2.62612
I0723 02:55:26.932936 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.4269 (* 1 = 1.4269 loss)
I0723 02:55:26.932974 23230 sgd_solver.cpp:138] Iteration 124960, lr = 1e-06
I0723 02:56:54.691440 23230 solver.cpp:243] Iteration 124970, loss = 2.54624
I0723 02:56:54.691722 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.10679 (* 1 = 3.10679 loss)
I0723 02:56:54.691794 23230 sgd_solver.cpp:138] Iteration 124970, lr = 1e-06
I0723 02:58:22.265221 23230 solver.cpp:243] Iteration 124980, loss = 2.76251
I0723 02:58:22.265521 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.51357 (* 1 = 2.51357 loss)
I0723 02:58:23.009173 23230 sgd_solver.cpp:138] Iteration 124980, lr = 1e-06
I0723 02:59:48.089437 23230 solver.cpp:243] Iteration 124990, loss = 2.4392
I0723 02:59:48.089730 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.36748 (* 1 = 2.36748 loss)
I0723 02:59:48.089840 23230 sgd_solver.cpp:138] Iteration 124990, lr = 1e-06
I0723 03:01:04.043707 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_125000.caffemodel
I0723 03:01:04.872987 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_125000.solverstate
I0723 03:01:05.070623 23230 solver.cpp:433] Iteration 125000, Testing net (#0)
I0723 03:01:05.070816 23230 net.cpp:693] Ignoring source layer mbox_loss
I0723 03:01:08.379334 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.619834
I0723 03:01:15.574254 23230 solver.cpp:243] Iteration 125000, loss = 2.79554
I0723 03:01:15.574329 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17937 (* 1 = 3.17937 loss)
I0723 03:01:15.574362 23230 sgd_solver.cpp:138] Iteration 125000, lr = 1e-06
I0723 03:02:41.840896 23230 solver.cpp:243] Iteration 125010, loss = 2.47997
I0723 03:02:41.841192 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78147 (* 1 = 2.78147 loss)
I0723 03:02:41.841292 23230 sgd_solver.cpp:138] Iteration 125010, lr = 1e-06
I0723 03:04:06.304383 23230 solver.cpp:243] Iteration 125020, loss = 2.64062
I0723 03:04:06.304617 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10795 (* 1 = 2.10795 loss)
I0723 03:04:06.304659 23230 sgd_solver.cpp:138] Iteration 125020, lr = 1e-06
I0723 03:05:34.193781 23230 solver.cpp:243] Iteration 125030, loss = 2.8027
I0723 03:05:34.194119 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.76205 (* 1 = 2.76205 loss)
I0723 03:05:34.194217 23230 sgd_solver.cpp:138] Iteration 125030, lr = 1e-06
I0723 03:07:01.445713 23230 solver.cpp:243] Iteration 125040, loss = 2.82625
I0723 03:07:01.446063 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.09197 (* 1 = 4.09197 loss)
I0723 03:07:01.446116 23230 sgd_solver.cpp:138] Iteration 125040, lr = 1e-06
I0723 03:08:30.094725 23230 solver.cpp:243] Iteration 125050, loss = 2.29284
I0723 03:08:30.094970 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.17427 (* 1 = 3.17427 loss)
I0723 03:08:30.095010 23230 sgd_solver.cpp:138] Iteration 125050, lr = 1e-06
I0723 03:09:55.093340 23230 solver.cpp:243] Iteration 125060, loss = 2.40265
I0723 03:09:55.093597 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.16709 (* 1 = 2.16709 loss)
I0723 03:09:55.093636 23230 sgd_solver.cpp:138] Iteration 125060, lr = 1e-06
I0723 03:11:23.250984 23230 solver.cpp:243] Iteration 125070, loss = 2.55645
I0723 03:11:23.251338 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.8247 (* 1 = 1.8247 loss)
I0723 03:11:23.606626 23230 sgd_solver.cpp:138] Iteration 125070, lr = 1e-06
I0723 03:12:47.445698 23230 solver.cpp:243] Iteration 125080, loss = 2.47732
I0723 03:12:47.445999 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.66948 (* 1 = 1.66948 loss)
I0723 03:12:47.446128 23230 sgd_solver.cpp:138] Iteration 125080, lr = 1e-06
I0723 03:14:15.716177 23230 solver.cpp:243] Iteration 125090, loss = 2.55667
I0723 03:14:15.716517 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.09064 (* 1 = 3.09064 loss)
I0723 03:14:16.889322 23230 sgd_solver.cpp:138] Iteration 125090, lr = 1e-06
I0723 03:15:42.464422 23230 solver.cpp:243] Iteration 125100, loss = 2.65901
I0723 03:15:42.464695 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.31864 (* 1 = 2.31864 loss)
I0723 03:15:42.464828 23230 sgd_solver.cpp:138] Iteration 125100, lr = 1e-06
I0723 03:17:09.111057 23230 solver.cpp:243] Iteration 125110, loss = 2.44465
I0723 03:17:09.111301 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.1787 (* 1 = 2.1787 loss)
I0723 03:17:09.111346 23230 sgd_solver.cpp:138] Iteration 125110, lr = 1e-06
I0723 03:18:36.060086 23230 solver.cpp:243] Iteration 125120, loss = 2.42216
I0723 03:18:36.060369 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.18948 (* 1 = 1.18948 loss)
I0723 03:18:36.060473 23230 sgd_solver.cpp:138] Iteration 125120, lr = 1e-06
I0723 03:20:01.639508 23230 solver.cpp:243] Iteration 125130, loss = 2.54342
I0723 03:20:01.639813 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.23433 (* 1 = 3.23433 loss)
I0723 03:20:01.639931 23230 sgd_solver.cpp:138] Iteration 125130, lr = 1e-06
I0723 03:21:25.047256 23230 solver.cpp:243] Iteration 125140, loss = 2.54325
I0723 03:21:25.047469 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.56843 (* 1 = 3.56843 loss)
I0723 03:21:25.047513 23230 sgd_solver.cpp:138] Iteration 125140, lr = 1e-06
I0723 03:22:48.929582 23230 solver.cpp:243] Iteration 125150, loss = 2.44813
I0723 03:22:48.929869 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.64864 (* 1 = 3.64864 loss)
I0723 03:22:48.929991 23230 sgd_solver.cpp:138] Iteration 125150, lr = 1e-06
I0723 03:24:16.024974 23230 solver.cpp:243] Iteration 125160, loss = 2.79778
I0723 03:24:16.025255 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.07769 (* 1 = 3.07769 loss)
I0723 03:24:16.025375 23230 sgd_solver.cpp:138] Iteration 125160, lr = 1e-06
I0723 03:25:42.360401 23230 solver.cpp:243] Iteration 125170, loss = 2.47746
I0723 03:25:42.360687 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.81683 (* 1 = 2.81683 loss)
I0723 03:25:42.360796 23230 sgd_solver.cpp:138] Iteration 125170, lr = 1e-06
I0723 03:27:07.814926 23230 solver.cpp:243] Iteration 125180, loss = 2.8174
I0723 03:27:07.816032 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.26827 (* 1 = 3.26827 loss)
I0723 03:27:08.616721 23230 sgd_solver.cpp:138] Iteration 125180, lr = 1e-06
I0723 03:28:31.612186 23230 solver.cpp:243] Iteration 125190, loss = 2.53753
I0723 03:28:31.612434 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.43664 (* 1 = 2.43664 loss)
I0723 03:28:32.627245 23230 sgd_solver.cpp:138] Iteration 125190, lr = 1e-06
I0723 03:29:56.221149 23230 solver.cpp:243] Iteration 125200, loss = 2.56228
I0723 03:29:56.221412 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.54009 (* 1 = 6.54009 loss)
I0723 03:29:56.221457 23230 sgd_solver.cpp:138] Iteration 125200, lr = 1e-06
I0723 03:31:17.105742 23230 solver.cpp:243] Iteration 125210, loss = 2.52677
I0723 03:31:17.105969 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.48014 (* 1 = 1.48014 loss)
I0723 03:31:17.106040 23230 sgd_solver.cpp:138] Iteration 125210, lr = 1e-06
I0723 03:32:37.474232 23230 solver.cpp:243] Iteration 125220, loss = 2.37655
I0723 03:32:37.474469 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.1604 (* 1 = 1.1604 loss)
I0723 03:32:37.474514 23230 sgd_solver.cpp:138] Iteration 125220, lr = 1e-06
I0723 03:34:02.292095 23230 solver.cpp:243] Iteration 125230, loss = 2.43313
I0723 03:34:02.292356 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.29744 (* 1 = 2.29744 loss)
I0723 03:34:03.244561 23230 sgd_solver.cpp:138] Iteration 125230, lr = 1e-06
I0723 03:35:29.110492 23230 solver.cpp:243] Iteration 125240, loss = 2.37909
I0723 03:35:29.110791 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85181 (* 1 = 2.85181 loss)
I0723 03:35:29.110911 23230 sgd_solver.cpp:138] Iteration 125240, lr = 1e-06
I0723 03:36:53.980832 23230 solver.cpp:243] Iteration 125250, loss = 2.54092
I0723 03:36:53.981075 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.32563 (* 1 = 2.32563 loss)
I0723 03:36:53.981120 23230 sgd_solver.cpp:138] Iteration 125250, lr = 1e-06
I0723 03:38:17.721875 23230 solver.cpp:243] Iteration 125260, loss = 2.5709
I0723 03:38:17.722105 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82127 (* 1 = 2.82127 loss)
I0723 03:38:17.722156 23230 sgd_solver.cpp:138] Iteration 125260, lr = 1e-06
I0723 03:39:42.655323 23230 solver.cpp:243] Iteration 125270, loss = 2.40293
I0723 03:39:42.655645 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.84033 (* 1 = 1.84033 loss)
I0723 03:39:42.655755 23230 sgd_solver.cpp:138] Iteration 125270, lr = 1e-06
I0723 03:41:09.887303 23230 solver.cpp:243] Iteration 125280, loss = 2.66404
I0723 03:41:09.887684 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.09206 (* 1 = 2.09206 loss)
I0723 03:41:10.240134 23230 sgd_solver.cpp:138] Iteration 125280, lr = 1e-06
I0723 03:42:36.610925 23230 solver.cpp:243] Iteration 125290, loss = 2.58224
I0723 03:42:36.611182 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 03:42:36.611230 23230 sgd_solver.cpp:138] Iteration 125290, lr = 1e-06
I0723 03:44:04.317592 23230 solver.cpp:243] Iteration 125300, loss = 2.53567
I0723 03:44:04.317858 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17096 (* 1 = 2.17096 loss)
I0723 03:44:04.318006 23230 sgd_solver.cpp:138] Iteration 125300, lr = 1e-06
I0723 03:45:31.424298 23230 solver.cpp:243] Iteration 125310, loss = 2.38768
I0723 03:45:31.424630 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.23187 (* 1 = 4.23187 loss)
I0723 03:45:31.424715 23230 sgd_solver.cpp:138] Iteration 125310, lr = 1e-06
I0723 03:46:56.179606 23230 solver.cpp:243] Iteration 125320, loss = 2.83919
I0723 03:46:56.179926 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.74695 (* 1 = 5.74695 loss)
I0723 03:46:56.180030 23230 sgd_solver.cpp:138] Iteration 125320, lr = 1e-06
I0723 03:48:22.096712 23230 solver.cpp:243] Iteration 125330, loss = 2.2965
I0723 03:48:22.097023 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.86899 (* 1 = 4.86899 loss)
I0723 03:48:22.452363 23230 sgd_solver.cpp:138] Iteration 125330, lr = 1e-06
I0723 03:49:47.958822 23230 solver.cpp:243] Iteration 125340, loss = 2.56093
I0723 03:49:47.959128 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.27813 (* 1 = 4.27813 loss)
I0723 03:49:48.700551 23230 sgd_solver.cpp:138] Iteration 125340, lr = 1e-06
I0723 03:51:12.162959 23230 solver.cpp:243] Iteration 125350, loss = 2.7997
I0723 03:51:12.163270 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.26676 (* 1 = 1.26676 loss)
I0723 03:51:12.968672 23230 sgd_solver.cpp:138] Iteration 125350, lr = 1e-06
I0723 03:52:35.088266 23230 solver.cpp:243] Iteration 125360, loss = 2.48218
I0723 03:52:35.088497 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.09076 (* 1 = 3.09076 loss)
I0723 03:52:35.477603 23230 sgd_solver.cpp:138] Iteration 125360, lr = 1e-06
I0723 03:54:00.280597 23230 solver.cpp:243] Iteration 125370, loss = 2.47797
I0723 03:54:00.280907 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.29729 (* 1 = 2.29729 loss)
I0723 03:54:01.027086 23230 sgd_solver.cpp:138] Iteration 125370, lr = 1e-06
I0723 03:55:27.460836 23230 solver.cpp:243] Iteration 125380, loss = 2.56505
I0723 03:55:27.461163 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.06812 (* 1 = 3.06812 loss)
I0723 03:55:27.461277 23230 sgd_solver.cpp:138] Iteration 125380, lr = 1e-06
I0723 03:56:54.434064 23230 solver.cpp:243] Iteration 125390, loss = 2.40191
I0723 03:56:54.434350 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.49734 (* 1 = 1.49734 loss)
I0723 03:56:54.434463 23230 sgd_solver.cpp:138] Iteration 125390, lr = 1e-06
I0723 03:58:20.339494 23230 solver.cpp:243] Iteration 125400, loss = 2.59267
I0723 03:58:20.339722 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85886 (* 1 = 2.85886 loss)
I0723 03:58:20.339772 23230 sgd_solver.cpp:138] Iteration 125400, lr = 1e-06
I0723 03:59:47.330030 23230 solver.cpp:243] Iteration 125410, loss = 2.70971
I0723 03:59:47.330265 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.11176 (* 1 = 1.11176 loss)
I0723 03:59:47.330312 23230 sgd_solver.cpp:138] Iteration 125410, lr = 1e-06
I0723 04:01:14.524415 23230 solver.cpp:243] Iteration 125420, loss = 2.49578
I0723 04:01:14.524730 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.84788 (* 1 = 3.84788 loss)
I0723 04:01:14.524822 23230 sgd_solver.cpp:138] Iteration 125420, lr = 1e-06
I0723 04:02:41.261116 23230 solver.cpp:243] Iteration 125430, loss = 2.44717
I0723 04:02:41.261370 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.858343 (* 1 = 0.858343 loss)
I0723 04:02:41.261426 23230 sgd_solver.cpp:138] Iteration 125430, lr = 1e-06
I0723 04:04:05.895733 23230 solver.cpp:243] Iteration 125440, loss = 2.46315
I0723 04:04:05.895967 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.28048 (* 1 = 1.28048 loss)
I0723 04:04:05.896013 23230 sgd_solver.cpp:138] Iteration 125440, lr = 1e-06
I0723 04:05:31.015734 23230 solver.cpp:243] Iteration 125450, loss = 2.59469
I0723 04:05:31.016049 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73141 (* 1 = 2.73141 loss)
I0723 04:05:31.016167 23230 sgd_solver.cpp:138] Iteration 125450, lr = 1e-06
I0723 04:06:57.861344 23230 solver.cpp:243] Iteration 125460, loss = 2.70234
I0723 04:06:57.861637 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.12506 (* 1 = 4.12506 loss)
I0723 04:06:57.861763 23230 sgd_solver.cpp:138] Iteration 125460, lr = 1e-06
I0723 04:08:24.402348 23230 solver.cpp:243] Iteration 125470, loss = 2.57799
I0723 04:08:24.402653 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50526 (* 1 = 2.50526 loss)
I0723 04:08:24.402751 23230 sgd_solver.cpp:138] Iteration 125470, lr = 1e-06
I0723 04:09:51.786101 23230 solver.cpp:243] Iteration 125480, loss = 2.48466
I0723 04:09:51.786370 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.911277 (* 1 = 0.911277 loss)
I0723 04:09:51.786412 23230 sgd_solver.cpp:138] Iteration 125480, lr = 1e-06
I0723 04:11:18.036550 23230 solver.cpp:243] Iteration 125490, loss = 2.48445
I0723 04:11:18.036959 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.53501 (* 1 = 3.53501 loss)
I0723 04:11:18.386461 23230 sgd_solver.cpp:138] Iteration 125490, lr = 1e-06
I0723 04:12:43.937767 23230 solver.cpp:243] Iteration 125500, loss = 2.36127
I0723 04:12:43.938097 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78326 (* 1 = 2.78326 loss)
I0723 04:12:43.938239 23230 sgd_solver.cpp:138] Iteration 125500, lr = 1e-06
I0723 04:14:11.330984 23230 solver.cpp:243] Iteration 125510, loss = 2.37549
I0723 04:14:11.331341 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 04:14:11.331447 23230 sgd_solver.cpp:138] Iteration 125510, lr = 1e-06
I0723 04:15:37.087252 23230 solver.cpp:243] Iteration 125520, loss = 2.69716
I0723 04:15:37.087523 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57733 (* 1 = 2.57733 loss)
I0723 04:15:37.876286 23230 sgd_solver.cpp:138] Iteration 125520, lr = 1e-06
I0723 04:17:01.918241 23230 solver.cpp:243] Iteration 125530, loss = 2.57325
I0723 04:17:01.918529 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8728 (* 1 = 2.8728 loss)
I0723 04:17:01.918607 23230 sgd_solver.cpp:138] Iteration 125530, lr = 1e-06
I0723 04:18:22.477269 23230 solver.cpp:243] Iteration 125540, loss = 2.628
I0723 04:18:22.477572 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.37986 (* 1 = 2.37986 loss)
I0723 04:18:22.477668 23230 sgd_solver.cpp:138] Iteration 125540, lr = 1e-06
I0723 04:19:45.212553 23230 solver.cpp:243] Iteration 125550, loss = 2.45001
I0723 04:19:45.212827 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.34233 (* 1 = 1.34233 loss)
I0723 04:19:45.212924 23230 sgd_solver.cpp:138] Iteration 125550, lr = 1e-06
I0723 04:21:08.912101 23230 solver.cpp:243] Iteration 125560, loss = 2.45417
I0723 04:21:08.912408 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.13956 (* 1 = 3.13956 loss)
I0723 04:21:08.912511 23230 sgd_solver.cpp:138] Iteration 125560, lr = 1e-06
I0723 04:22:33.711542 23230 solver.cpp:243] Iteration 125570, loss = 2.4114
I0723 04:22:33.711789 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60876 (* 1 = 2.60876 loss)
I0723 04:22:33.711833 23230 sgd_solver.cpp:138] Iteration 125570, lr = 1e-06
I0723 04:23:59.341224 23230 solver.cpp:243] Iteration 125580, loss = 2.37499
I0723 04:23:59.341465 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.7619 (* 1 = 1.7619 loss)
I0723 04:23:59.763305 23230 sgd_solver.cpp:138] Iteration 125580, lr = 1e-06
I0723 04:25:22.061655 23230 solver.cpp:243] Iteration 125590, loss = 2.43263
I0723 04:25:22.061962 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.13518 (* 1 = 1.13518 loss)
I0723 04:25:22.062080 23230 sgd_solver.cpp:138] Iteration 125590, lr = 1e-06
I0723 04:26:51.305634 23230 solver.cpp:243] Iteration 125600, loss = 2.53001
I0723 04:26:51.305889 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50417 (* 1 = 2.50417 loss)
I0723 04:26:51.305943 23230 sgd_solver.cpp:138] Iteration 125600, lr = 1e-06
I0723 04:28:18.618607 23230 solver.cpp:243] Iteration 125610, loss = 2.65244
I0723 04:28:18.618870 23230 solver.cpp:259]     Train net output #0: mbox_loss = 6.7645 (* 1 = 6.7645 loss)
I0723 04:28:18.618921 23230 sgd_solver.cpp:138] Iteration 125610, lr = 1e-06
I0723 04:29:43.219161 23230 solver.cpp:243] Iteration 125620, loss = 2.40392
I0723 04:29:43.219374 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05069 (* 1 = 2.05069 loss)
I0723 04:29:43.219421 23230 sgd_solver.cpp:138] Iteration 125620, lr = 1e-06
I0723 04:31:09.065109 23230 solver.cpp:243] Iteration 125630, loss = 2.49539
I0723 04:31:09.065481 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.99358 (* 1 = 3.99358 loss)
I0723 04:31:09.412626 23230 sgd_solver.cpp:138] Iteration 125630, lr = 1e-06
I0723 04:32:34.790364 23230 solver.cpp:243] Iteration 125640, loss = 2.6379
I0723 04:32:34.790619 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.65956 (* 1 = 3.65956 loss)
I0723 04:32:34.790660 23230 sgd_solver.cpp:138] Iteration 125640, lr = 1e-06
I0723 04:33:58.843731 23230 solver.cpp:243] Iteration 125650, loss = 2.68275
I0723 04:33:58.843950 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.56501 (* 1 = 4.56501 loss)
I0723 04:33:58.843991 23230 sgd_solver.cpp:138] Iteration 125650, lr = 1e-06
I0723 04:35:24.255853 23230 solver.cpp:243] Iteration 125660, loss = 2.35328
I0723 04:35:24.256146 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.94823 (* 1 = 2.94823 loss)
I0723 04:35:24.608116 23230 sgd_solver.cpp:138] Iteration 125660, lr = 1e-06
I0723 04:36:50.301858 23230 solver.cpp:243] Iteration 125670, loss = 2.52077
I0723 04:36:50.302250 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.4316 (* 1 = 1.4316 loss)
I0723 04:36:50.302294 23230 sgd_solver.cpp:138] Iteration 125670, lr = 1e-06
I0723 04:38:18.748911 23230 solver.cpp:243] Iteration 125680, loss = 2.48143
I0723 04:38:18.749116 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.38603 (* 1 = 1.38603 loss)
I0723 04:38:18.749156 23230 sgd_solver.cpp:138] Iteration 125680, lr = 1e-06
I0723 04:39:44.283412 23230 solver.cpp:243] Iteration 125690, loss = 2.34932
I0723 04:39:44.283737 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.30837 (* 1 = 2.30837 loss)
I0723 04:39:44.283854 23230 sgd_solver.cpp:138] Iteration 125690, lr = 1e-06
I0723 04:41:09.630749 23230 solver.cpp:243] Iteration 125700, loss = 2.57399
I0723 04:41:09.631055 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.962502 (* 1 = 0.962502 loss)
I0723 04:41:09.631150 23230 sgd_solver.cpp:138] Iteration 125700, lr = 1e-06
I0723 04:42:35.708341 23230 solver.cpp:243] Iteration 125710, loss = 2.38053
I0723 04:42:35.708643 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.99355 (* 1 = 1.99355 loss)
I0723 04:42:35.708750 23230 sgd_solver.cpp:138] Iteration 125710, lr = 1e-06
I0723 04:44:01.315366 23230 solver.cpp:243] Iteration 125720, loss = 2.55022
I0723 04:44:01.315591 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.19861 (* 1 = 3.19861 loss)
I0723 04:44:02.614526 23230 sgd_solver.cpp:138] Iteration 125720, lr = 1e-06
I0723 04:45:26.689116 23230 solver.cpp:243] Iteration 125730, loss = 2.57903
I0723 04:45:26.689397 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.181 (* 1 = 1.181 loss)
I0723 04:45:26.689502 23230 sgd_solver.cpp:138] Iteration 125730, lr = 1e-06
I0723 04:46:49.176254 23230 solver.cpp:243] Iteration 125740, loss = 2.62641
I0723 04:46:49.176571 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 04:46:49.176679 23230 sgd_solver.cpp:138] Iteration 125740, lr = 1e-06
I0723 04:48:16.011719 23230 solver.cpp:243] Iteration 125750, loss = 2.50736
I0723 04:48:16.012010 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.35856 (* 1 = 2.35856 loss)
I0723 04:48:16.012125 23230 sgd_solver.cpp:138] Iteration 125750, lr = 1e-06
I0723 04:49:39.013936 23230 solver.cpp:243] Iteration 125760, loss = 2.40748
I0723 04:49:39.014242 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10647 (* 1 = 2.10647 loss)
I0723 04:49:39.014345 23230 sgd_solver.cpp:138] Iteration 125760, lr = 1e-06
I0723 04:51:02.606688 23230 solver.cpp:243] Iteration 125770, loss = 2.79971
I0723 04:51:02.606986 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17426 (* 1 = 2.17426 loss)
I0723 04:51:03.385727 23230 sgd_solver.cpp:138] Iteration 125770, lr = 1e-06
I0723 04:52:29.362942 23230 solver.cpp:243] Iteration 125780, loss = 2.47857
I0723 04:52:29.363219 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.07068 (* 1 = 1.07068 loss)
I0723 04:52:29.363262 23230 sgd_solver.cpp:138] Iteration 125780, lr = 1e-06
I0723 04:53:54.103811 23230 solver.cpp:243] Iteration 125790, loss = 2.67776
I0723 04:53:54.104125 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.72659 (* 1 = 2.72659 loss)
I0723 04:53:55.474529 23230 sgd_solver.cpp:138] Iteration 125790, lr = 1e-06
I0723 04:55:20.848646 23230 solver.cpp:243] Iteration 125800, loss = 2.51377
I0723 04:55:20.848875 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.31677 (* 1 = 1.31677 loss)
I0723 04:55:20.848918 23230 sgd_solver.cpp:138] Iteration 125800, lr = 1e-06
I0723 04:56:44.369182 23230 solver.cpp:243] Iteration 125810, loss = 2.59876
I0723 04:56:44.369444 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.91064 (* 1 = 2.91064 loss)
I0723 04:56:44.369537 23230 sgd_solver.cpp:138] Iteration 125810, lr = 1e-06
I0723 04:58:11.010825 23230 solver.cpp:243] Iteration 125820, loss = 2.34154
I0723 04:58:11.013360 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.71221 (* 1 = 1.71221 loss)
I0723 04:58:11.013451 23230 sgd_solver.cpp:138] Iteration 125820, lr = 1e-06
I0723 04:59:38.733779 23230 solver.cpp:243] Iteration 125830, loss = 2.62084
I0723 04:59:38.734125 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26977 (* 1 = 2.26977 loss)
I0723 04:59:38.734211 23230 sgd_solver.cpp:138] Iteration 125830, lr = 1e-06
I0723 05:01:04.611326 23230 solver.cpp:243] Iteration 125840, loss = 2.41205
I0723 05:01:04.612509 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.41544 (* 1 = 3.41544 loss)
I0723 05:01:04.612555 23230 sgd_solver.cpp:138] Iteration 125840, lr = 1e-06
I0723 05:02:30.014341 23230 solver.cpp:243] Iteration 125850, loss = 2.51196
I0723 05:02:30.014570 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 05:02:30.410187 23230 sgd_solver.cpp:138] Iteration 125850, lr = 1e-06
I0723 05:03:59.391824 23230 solver.cpp:243] Iteration 125860, loss = 2.57013
I0723 05:03:59.392084 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.1107 (* 1 = 3.1107 loss)
I0723 05:03:59.392179 23230 sgd_solver.cpp:138] Iteration 125860, lr = 1e-06
I0723 05:05:25.595346 23230 solver.cpp:243] Iteration 125870, loss = 2.48319
I0723 05:05:25.595660 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.34735 (* 1 = 1.34735 loss)
I0723 05:05:25.595759 23230 sgd_solver.cpp:138] Iteration 125870, lr = 1e-06
I0723 05:06:51.918735 23230 solver.cpp:243] Iteration 125880, loss = 2.5547
I0723 05:06:51.919019 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.18344 (* 1 = 2.18344 loss)
I0723 05:06:51.919137 23230 sgd_solver.cpp:138] Iteration 125880, lr = 1e-06
I0723 05:08:19.130153 23230 solver.cpp:243] Iteration 125890, loss = 2.59708
I0723 05:08:19.130486 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.91715 (* 1 = 3.91715 loss)
I0723 05:08:19.496099 23230 sgd_solver.cpp:138] Iteration 125890, lr = 1e-06
I0723 05:09:46.038271 23230 solver.cpp:243] Iteration 125900, loss = 2.41593
I0723 05:09:46.038552 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.17751 (* 1 = 2.17751 loss)
I0723 05:09:46.038664 23230 sgd_solver.cpp:138] Iteration 125900, lr = 1e-06
I0723 05:11:09.065821 23230 solver.cpp:243] Iteration 125910, loss = 2.307
I0723 05:11:09.066104 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.22713 (* 1 = 2.22713 loss)
I0723 05:11:09.066155 23230 sgd_solver.cpp:138] Iteration 125910, lr = 1e-06
I0723 05:12:35.004634 23230 solver.cpp:243] Iteration 125920, loss = 2.53959
I0723 05:12:35.004909 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.04154 (* 1 = 3.04154 loss)
I0723 05:12:35.004976 23230 sgd_solver.cpp:138] Iteration 125920, lr = 1e-06
I0723 05:13:59.744267 23230 solver.cpp:243] Iteration 125930, loss = 2.48158
I0723 05:13:59.744557 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.40293 (* 1 = 2.40293 loss)
I0723 05:14:00.129228 23230 sgd_solver.cpp:138] Iteration 125930, lr = 1e-06
I0723 05:15:27.744367 23230 solver.cpp:243] Iteration 125940, loss = 2.299
I0723 05:15:27.744590 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.14197 (* 1 = 2.14197 loss)
I0723 05:15:27.744634 23230 sgd_solver.cpp:138] Iteration 125940, lr = 1e-06
I0723 05:16:53.101665 23230 solver.cpp:243] Iteration 125950, loss = 2.67435
I0723 05:16:53.101951 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.267 (* 1 = 3.267 loss)
I0723 05:16:53.102044 23230 sgd_solver.cpp:138] Iteration 125950, lr = 1e-06
I0723 05:18:19.604974 23230 solver.cpp:243] Iteration 125960, loss = 2.32729
I0723 05:18:19.605198 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 05:18:19.605243 23230 sgd_solver.cpp:138] Iteration 125960, lr = 1e-06
I0723 05:19:44.776433 23230 solver.cpp:243] Iteration 125970, loss = 2.60908
I0723 05:19:44.776757 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60331 (* 1 = 2.60331 loss)
I0723 05:19:44.776818 23230 sgd_solver.cpp:138] Iteration 125970, lr = 1e-06
I0723 05:21:09.229766 23230 solver.cpp:243] Iteration 125980, loss = 2.53401
I0723 05:21:09.230015 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.96061 (* 1 = 2.96061 loss)
I0723 05:21:09.230065 23230 sgd_solver.cpp:138] Iteration 125980, lr = 1e-06
I0723 05:22:34.665889 23230 solver.cpp:243] Iteration 125990, loss = 2.5241
I0723 05:22:34.666151 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 05:22:34.666203 23230 sgd_solver.cpp:138] Iteration 125990, lr = 1e-06
I0723 05:23:54.319700 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_126000.caffemodel
I0723 05:23:55.125454 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_126000.solverstate
I0723 05:23:55.299389 23230 solver.cpp:433] Iteration 126000, Testing net (#0)
I0723 05:23:55.299685 23230 net.cpp:693] Ignoring source layer mbox_loss
I0723 05:23:58.625900 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.617164
I0723 05:24:06.412662 23230 solver.cpp:243] Iteration 126000, loss = 2.72358
I0723 05:24:06.412739 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.59097 (* 1 = 3.59097 loss)
I0723 05:24:06.412778 23230 sgd_solver.cpp:138] Iteration 126000, lr = 1e-06
I0723 05:25:31.341625 23230 solver.cpp:243] Iteration 126010, loss = 2.60322
I0723 05:25:31.341873 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.63485 (* 1 = 1.63485 loss)
I0723 05:25:31.341924 23230 sgd_solver.cpp:138] Iteration 126010, lr = 1e-06
I0723 05:26:58.517230 23230 solver.cpp:243] Iteration 126020, loss = 2.47291
I0723 05:26:58.517490 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.04042 (* 1 = 2.04042 loss)
I0723 05:26:58.517532 23230 sgd_solver.cpp:138] Iteration 126020, lr = 1e-06
I0723 05:28:23.837965 23230 solver.cpp:243] Iteration 126030, loss = 2.3899
I0723 05:28:23.838250 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.69308 (* 1 = 1.69308 loss)
I0723 05:28:25.630700 23230 sgd_solver.cpp:138] Iteration 126030, lr = 1e-06
I0723 05:29:49.189888 23230 solver.cpp:243] Iteration 126040, loss = 2.53981
I0723 05:29:49.190244 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.29564 (* 1 = 3.29564 loss)
I0723 05:29:49.957700 23230 sgd_solver.cpp:138] Iteration 126040, lr = 1e-06
I0723 05:31:14.851948 23230 solver.cpp:243] Iteration 126050, loss = 2.51667
I0723 05:31:14.852234 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.97957 (* 1 = 1.97957 loss)
I0723 05:31:14.852330 23230 sgd_solver.cpp:138] Iteration 126050, lr = 1e-06
I0723 05:32:40.533107 23230 solver.cpp:243] Iteration 126060, loss = 2.74811
I0723 05:32:40.533411 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.25474 (* 1 = 1.25474 loss)
I0723 05:32:40.533517 23230 sgd_solver.cpp:138] Iteration 126060, lr = 1e-06
I0723 05:34:07.465509 23230 solver.cpp:243] Iteration 126070, loss = 2.4936
I0723 05:34:07.465828 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.60626 (* 1 = 2.60626 loss)
I0723 05:34:07.465924 23230 sgd_solver.cpp:138] Iteration 126070, lr = 1e-06
I0723 05:35:33.650087 23230 solver.cpp:243] Iteration 126080, loss = 2.56968
I0723 05:35:33.650396 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.8845 (* 1 = 2.8845 loss)
I0723 05:35:33.650492 23230 sgd_solver.cpp:138] Iteration 126080, lr = 1e-06
I0723 05:37:01.949512 23230 solver.cpp:243] Iteration 126090, loss = 2.72067
I0723 05:37:01.949785 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32555 (* 1 = 3.32555 loss)
I0723 05:37:01.949826 23230 sgd_solver.cpp:138] Iteration 126090, lr = 1e-06
I0723 05:38:27.229351 23230 solver.cpp:243] Iteration 126100, loss = 2.76644
I0723 05:38:27.229662 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.13948 (* 1 = 2.13948 loss)
I0723 05:38:27.229764 23230 sgd_solver.cpp:138] Iteration 126100, lr = 1e-06
I0723 05:39:50.366472 23230 solver.cpp:243] Iteration 126110, loss = 2.42379
I0723 05:39:50.368207 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.00434 (* 1 = 2.00434 loss)
I0723 05:39:51.621760 23230 sgd_solver.cpp:138] Iteration 126110, lr = 1e-06
I0723 05:41:18.387104 23230 solver.cpp:243] Iteration 126120, loss = 2.5464
I0723 05:41:18.388499 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47568 (* 1 = 2.47568 loss)
I0723 05:41:18.388564 23230 sgd_solver.cpp:138] Iteration 126120, lr = 1e-06
I0723 05:42:44.431466 23230 solver.cpp:243] Iteration 126130, loss = 2.57311
I0723 05:42:44.431766 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.09847 (* 1 = 1.09847 loss)
I0723 05:42:44.431865 23230 sgd_solver.cpp:138] Iteration 126130, lr = 1e-06
I0723 05:44:12.221122 23230 solver.cpp:243] Iteration 126140, loss = 2.61292
I0723 05:44:12.221468 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.04031 (* 1 = 2.04031 loss)
I0723 05:44:12.626866 23230 sgd_solver.cpp:138] Iteration 126140, lr = 1e-06
I0723 05:45:36.813740 23230 solver.cpp:243] Iteration 126150, loss = 2.59132
I0723 05:45:36.814033 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.10079 (* 1 = 3.10079 loss)
I0723 05:45:36.814118 23230 sgd_solver.cpp:138] Iteration 126150, lr = 1e-06
I0723 05:47:04.789609 23230 solver.cpp:243] Iteration 126160, loss = 2.52181
I0723 05:47:04.789935 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.08727 (* 1 = 2.08727 loss)
I0723 05:47:05.575592 23230 sgd_solver.cpp:138] Iteration 126160, lr = 1e-06
I0723 05:48:29.801065 23230 solver.cpp:243] Iteration 126170, loss = 2.53072
I0723 05:48:29.801357 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.23886 (* 1 = 3.23886 loss)
I0723 05:48:29.801411 23230 sgd_solver.cpp:138] Iteration 126170, lr = 1e-06
I0723 05:49:57.334272 23230 solver.cpp:243] Iteration 126180, loss = 2.6801
I0723 05:49:57.334543 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.2529 (* 1 = 1.2529 loss)
I0723 05:49:57.334648 23230 sgd_solver.cpp:138] Iteration 126180, lr = 1e-06
I0723 05:51:22.747565 23230 solver.cpp:243] Iteration 126190, loss = 2.70831
I0723 05:51:22.747862 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.98834 (* 1 = 3.98834 loss)
I0723 05:51:22.747964 23230 sgd_solver.cpp:138] Iteration 126190, lr = 1e-06
I0723 05:52:46.080468 23230 solver.cpp:243] Iteration 126200, loss = 2.63427
I0723 05:52:46.080690 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.55312 (* 1 = 1.55312 loss)
I0723 05:52:46.080740 23230 sgd_solver.cpp:138] Iteration 126200, lr = 1e-06
I0723 05:54:12.909940 23230 solver.cpp:243] Iteration 126210, loss = 2.5848
I0723 05:54:12.910220 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.17962 (* 1 = 4.17962 loss)
I0723 05:54:12.910321 23230 sgd_solver.cpp:138] Iteration 126210, lr = 1e-06
I0723 05:55:37.348527 23230 solver.cpp:243] Iteration 126220, loss = 2.28322
I0723 05:55:37.348860 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 05:55:38.323523 23230 sgd_solver.cpp:138] Iteration 126220, lr = 1e-06
I0723 05:57:03.445497 23230 solver.cpp:243] Iteration 126230, loss = 2.40972
I0723 05:57:03.445756 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.86681 (* 1 = 3.86681 loss)
I0723 05:57:03.445801 23230 sgd_solver.cpp:138] Iteration 126230, lr = 1e-06
I0723 05:58:28.338927 23230 solver.cpp:243] Iteration 126240, loss = 2.73281
I0723 05:58:28.339751 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.99875 (* 1 = 2.99875 loss)
I0723 05:58:28.339802 23230 sgd_solver.cpp:138] Iteration 126240, lr = 1e-06
I0723 05:59:56.525848 23230 solver.cpp:243] Iteration 126250, loss = 2.57161
I0723 05:59:56.526129 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.03552 (* 1 = 4.03552 loss)
I0723 05:59:56.526226 23230 sgd_solver.cpp:138] Iteration 126250, lr = 1e-06
I0723 06:01:22.353219 23230 solver.cpp:243] Iteration 126260, loss = 2.40619
I0723 06:01:22.353564 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.27289 (* 1 = 3.27289 loss)
I0723 06:01:22.716159 23230 sgd_solver.cpp:138] Iteration 126260, lr = 1e-06
I0723 06:02:50.204294 23230 solver.cpp:243] Iteration 126270, loss = 2.68176
I0723 06:02:50.204524 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.74276 (* 1 = 2.74276 loss)
I0723 06:02:50.598309 23230 sgd_solver.cpp:138] Iteration 126270, lr = 1e-06
I0723 06:04:17.756446 23230 solver.cpp:243] Iteration 126280, loss = 2.39618
I0723 06:04:17.756748 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.64213 (* 1 = 2.64213 loss)
I0723 06:04:17.756853 23230 sgd_solver.cpp:138] Iteration 126280, lr = 1e-06
I0723 06:05:42.309094 23230 solver.cpp:243] Iteration 126290, loss = 2.56849
I0723 06:05:42.309322 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.11759 (* 1 = 3.11759 loss)
I0723 06:05:42.309363 23230 sgd_solver.cpp:138] Iteration 126290, lr = 1e-06
I0723 06:07:05.798286 23230 solver.cpp:243] Iteration 126300, loss = 2.67228
I0723 06:07:05.798624 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.91417 (* 1 = 4.91417 loss)
I0723 06:07:05.798730 23230 sgd_solver.cpp:138] Iteration 126300, lr = 1e-06
I0723 06:08:32.051954 23230 solver.cpp:243] Iteration 126310, loss = 2.52247
I0723 06:08:32.052264 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.26428 (* 1 = 2.26428 loss)
I0723 06:08:32.052367 23230 sgd_solver.cpp:138] Iteration 126310, lr = 1e-06
I0723 06:09:59.211657 23230 solver.cpp:243] Iteration 126320, loss = 2.63505
I0723 06:09:59.211968 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.51304 (* 1 = 2.51304 loss)
I0723 06:09:59.212075 23230 sgd_solver.cpp:138] Iteration 126320, lr = 1e-06
I0723 06:11:25.638445 23230 solver.cpp:243] Iteration 126330, loss = 2.5605
I0723 06:11:25.638782 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.57706 (* 1 = 4.57706 loss)
I0723 06:11:25.638888 23230 sgd_solver.cpp:138] Iteration 126330, lr = 1e-06
I0723 06:12:49.355494 23230 solver.cpp:243] Iteration 126340, loss = 2.62779
I0723 06:12:49.355721 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.77285 (* 1 = 2.77285 loss)
I0723 06:12:49.355765 23230 sgd_solver.cpp:138] Iteration 126340, lr = 1e-06
I0723 06:14:12.513181 23230 solver.cpp:243] Iteration 126350, loss = 2.55119
I0723 06:14:12.513500 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.47412 (* 1 = 2.47412 loss)
I0723 06:14:12.864938 23230 sgd_solver.cpp:138] Iteration 126350, lr = 1e-06
I0723 06:15:37.262621 23230 solver.cpp:243] Iteration 126360, loss = 2.46949
I0723 06:15:37.262936 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.14761 (* 1 = 1.14761 loss)
I0723 06:15:37.263039 23230 sgd_solver.cpp:138] Iteration 126360, lr = 1e-06
I0723 06:17:02.721143 23230 solver.cpp:243] Iteration 126370, loss = 2.58331
I0723 06:17:02.721367 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.25834 (* 1 = 2.25834 loss)
I0723 06:17:03.116247 23230 sgd_solver.cpp:138] Iteration 126370, lr = 1e-06
I0723 06:18:30.494251 23230 solver.cpp:243] Iteration 126380, loss = 2.47211
I0723 06:18:30.494514 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64407 (* 1 = 1.64407 loss)
I0723 06:18:30.494582 23230 sgd_solver.cpp:138] Iteration 126380, lr = 1e-06
I0723 06:19:57.058955 23230 solver.cpp:243] Iteration 126390, loss = 2.61543
I0723 06:19:57.059240 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.06368 (* 1 = 2.06368 loss)
I0723 06:19:57.059324 23230 sgd_solver.cpp:138] Iteration 126390, lr = 1e-06
I0723 06:21:24.134791 23230 solver.cpp:243] Iteration 126400, loss = 2.51777
I0723 06:21:24.135110 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32933 (* 1 = 1.32933 loss)
I0723 06:21:24.135216 23230 sgd_solver.cpp:138] Iteration 126400, lr = 1e-06
I0723 06:22:52.523380 23230 solver.cpp:243] Iteration 126410, loss = 2.45436
I0723 06:22:52.523687 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.59119 (* 1 = 2.59119 loss)
I0723 06:22:52.523814 23230 sgd_solver.cpp:138] Iteration 126410, lr = 1e-06
I0723 06:24:18.529382 23230 solver.cpp:243] Iteration 126420, loss = 2.59915
I0723 06:24:18.529706 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80661 (* 1 = 2.80661 loss)
I0723 06:24:18.909857 23230 sgd_solver.cpp:138] Iteration 126420, lr = 1e-06
I0723 06:25:45.627349 23230 solver.cpp:243] Iteration 126430, loss = 2.4883
I0723 06:25:45.627617 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.24792 (* 1 = 1.24792 loss)
I0723 06:25:45.627660 23230 sgd_solver.cpp:138] Iteration 126430, lr = 1e-06
I0723 06:27:08.537369 23230 solver.cpp:243] Iteration 126440, loss = 2.42334
I0723 06:27:08.537643 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.5156 (* 1 = 3.5156 loss)
I0723 06:27:09.214534 23230 sgd_solver.cpp:138] Iteration 126440, lr = 1e-06
I0723 06:28:35.294957 23230 solver.cpp:243] Iteration 126450, loss = 2.44978
I0723 06:28:35.295215 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32286 (* 1 = 1.32286 loss)
I0723 06:28:35.295258 23230 sgd_solver.cpp:138] Iteration 126450, lr = 1e-06
I0723 06:29:59.592655 23230 solver.cpp:243] Iteration 126460, loss = 2.48966
I0723 06:29:59.592877 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.03151 (* 1 = 1.03151 loss)
I0723 06:29:59.954071 23230 sgd_solver.cpp:138] Iteration 126460, lr = 1e-06
I0723 06:31:22.195798 23230 solver.cpp:243] Iteration 126470, loss = 2.39148
I0723 06:31:22.196058 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.83491 (* 1 = 1.83491 loss)
I0723 06:31:22.196171 23230 sgd_solver.cpp:138] Iteration 126470, lr = 1e-06
I0723 06:32:48.383219 23230 solver.cpp:243] Iteration 126480, loss = 2.45477
I0723 06:32:48.383455 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.43455 (* 1 = 3.43455 loss)
I0723 06:32:48.383497 23230 sgd_solver.cpp:138] Iteration 126480, lr = 1e-06
I0723 06:34:15.307687 23230 solver.cpp:243] Iteration 126490, loss = 2.57884
I0723 06:34:15.307943 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.29277 (* 1 = 2.29277 loss)
I0723 06:34:15.307982 23230 sgd_solver.cpp:138] Iteration 126490, lr = 1e-06
I0723 06:35:42.953433 23230 solver.cpp:243] Iteration 126500, loss = 2.3799
I0723 06:35:42.953737 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.64419 (* 1 = 1.64419 loss)
I0723 06:35:43.717041 23230 sgd_solver.cpp:138] Iteration 126500, lr = 1e-06
I0723 06:37:08.436257 23230 solver.cpp:243] Iteration 126510, loss = 2.60208
I0723 06:37:08.436506 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.64643 (* 1 = 2.64643 loss)
I0723 06:37:08.436556 23230 sgd_solver.cpp:138] Iteration 126510, lr = 1e-06
I0723 06:38:37.503497 23230 solver.cpp:243] Iteration 126520, loss = 2.46422
I0723 06:38:37.504817 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.5894 (* 1 = 2.5894 loss)
I0723 06:38:37.504920 23230 sgd_solver.cpp:138] Iteration 126520, lr = 1e-06
I0723 06:40:04.018322 23230 solver.cpp:243] Iteration 126530, loss = 2.66963
I0723 06:40:04.018561 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.73327 (* 1 = 2.73327 loss)
I0723 06:40:04.372234 23230 sgd_solver.cpp:138] Iteration 126530, lr = 1e-06
I0723 06:41:30.462512 23230 solver.cpp:243] Iteration 126540, loss = 2.56804
I0723 06:41:30.462730 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.98282 (* 1 = 3.98282 loss)
I0723 06:41:30.462779 23230 sgd_solver.cpp:138] Iteration 126540, lr = 1e-06
I0723 06:42:57.464568 23230 solver.cpp:243] Iteration 126550, loss = 2.43313
I0723 06:42:57.464853 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.1084 (* 1 = 1.1084 loss)
I0723 06:42:57.464947 23230 sgd_solver.cpp:138] Iteration 126550, lr = 1e-06
I0723 06:44:21.303325 23230 solver.cpp:243] Iteration 126560, loss = 2.60927
I0723 06:44:21.303570 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69942 (* 1 = 2.69942 loss)
I0723 06:44:21.303617 23230 sgd_solver.cpp:138] Iteration 126560, lr = 1e-06
I0723 06:45:46.110842 23230 solver.cpp:243] Iteration 126570, loss = 2.47932
I0723 06:45:46.111172 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9181 (* 1 = 1.9181 loss)
I0723 06:45:46.111225 23230 sgd_solver.cpp:138] Iteration 126570, lr = 1e-06
I0723 06:47:08.943153 23230 solver.cpp:243] Iteration 126580, loss = 2.56551
I0723 06:47:08.944365 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.43119 (* 1 = 2.43119 loss)
I0723 06:47:10.078796 23230 sgd_solver.cpp:138] Iteration 126580, lr = 1e-06
I0723 06:48:37.084426 23230 solver.cpp:243] Iteration 126590, loss = 2.65044
I0723 06:48:37.084751 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.45955 (* 1 = 2.45955 loss)
I0723 06:48:37.084846 23230 sgd_solver.cpp:138] Iteration 126590, lr = 1e-06
I0723 06:50:03.992466 23230 solver.cpp:243] Iteration 126600, loss = 2.46849
I0723 06:50:03.992715 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.36175 (* 1 = 4.36175 loss)
I0723 06:50:03.992754 23230 sgd_solver.cpp:138] Iteration 126600, lr = 1e-06
I0723 06:51:28.997273 23230 solver.cpp:243] Iteration 126610, loss = 2.60512
I0723 06:51:28.997579 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.34694 (* 1 = 3.34694 loss)
I0723 06:51:28.997711 23230 sgd_solver.cpp:138] Iteration 126610, lr = 1e-06
I0723 06:52:53.084233 23230 solver.cpp:243] Iteration 126620, loss = 2.56414
I0723 06:52:53.084534 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.06084 (* 1 = 3.06084 loss)
I0723 06:52:53.450018 23230 sgd_solver.cpp:138] Iteration 126620, lr = 1e-06
I0723 06:54:18.576817 23230 solver.cpp:243] Iteration 126630, loss = 2.50833
I0723 06:54:18.577045 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.57022 (* 1 = 2.57022 loss)
I0723 06:54:18.577100 23230 sgd_solver.cpp:138] Iteration 126630, lr = 1e-06
I0723 06:55:40.667666 23230 solver.cpp:243] Iteration 126640, loss = 2.71828
I0723 06:55:40.667976 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.90288 (* 1 = 1.90288 loss)
I0723 06:55:41.060026 23230 sgd_solver.cpp:138] Iteration 126640, lr = 1e-06
I0723 06:57:02.791659 23230 solver.cpp:243] Iteration 126650, loss = 2.29488
I0723 06:57:02.791884 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.800769 (* 1 = 0.800769 loss)
I0723 06:57:03.176463 23230 sgd_solver.cpp:138] Iteration 126650, lr = 1e-06
I0723 06:58:28.635843 23230 solver.cpp:243] Iteration 126660, loss = 2.44329
I0723 06:58:28.636167 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.4881 (* 1 = 3.4881 loss)
I0723 06:58:28.636268 23230 sgd_solver.cpp:138] Iteration 126660, lr = 1e-06
I0723 06:59:54.823828 23230 solver.cpp:243] Iteration 126670, loss = 2.49532
I0723 06:59:54.824115 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.55222 (* 1 = 1.55222 loss)
I0723 06:59:54.824234 23230 sgd_solver.cpp:138] Iteration 126670, lr = 1e-06
I0723 07:01:22.111932 23230 solver.cpp:243] Iteration 126680, loss = 2.3753
I0723 07:01:22.112195 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.54916 (* 1 = 3.54916 loss)
I0723 07:01:22.112238 23230 sgd_solver.cpp:138] Iteration 126680, lr = 1e-06
I0723 07:02:50.695802 23230 solver.cpp:243] Iteration 126690, loss = 2.58324
I0723 07:02:50.696110 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.872223 (* 1 = 0.872223 loss)
I0723 07:02:50.696218 23230 sgd_solver.cpp:138] Iteration 126690, lr = 1e-06
I0723 07:04:16.564703 23230 solver.cpp:243] Iteration 126700, loss = 2.68561
I0723 07:04:16.564944 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50024 (* 1 = 2.50024 loss)
I0723 07:04:16.565006 23230 sgd_solver.cpp:138] Iteration 126700, lr = 1e-06
I0723 07:05:43.955375 23230 solver.cpp:243] Iteration 126710, loss = 2.51104
I0723 07:05:43.955629 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 07:05:43.955677 23230 sgd_solver.cpp:138] Iteration 126710, lr = 1e-06
I0723 07:07:10.005518 23230 solver.cpp:243] Iteration 126720, loss = 2.51177
I0723 07:07:10.005811 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.13676 (* 1 = 2.13676 loss)
I0723 07:07:10.005861 23230 sgd_solver.cpp:138] Iteration 126720, lr = 1e-06
I0723 07:08:36.720759 23230 solver.cpp:243] Iteration 126730, loss = 2.48272
I0723 07:08:36.721088 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93755 (* 1 = 2.93755 loss)
I0723 07:08:37.079648 23230 sgd_solver.cpp:138] Iteration 126730, lr = 1e-06
I0723 07:10:02.529064 23230 solver.cpp:243] Iteration 126740, loss = 2.331
I0723 07:10:02.529312 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.38139 (* 1 = 2.38139 loss)
I0723 07:10:02.529357 23230 sgd_solver.cpp:138] Iteration 126740, lr = 1e-06
I0723 07:11:28.227964 23230 solver.cpp:243] Iteration 126750, loss = 2.57906
I0723 07:11:28.228194 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.74601 (* 1 = 1.74601 loss)
I0723 07:11:28.596614 23230 sgd_solver.cpp:138] Iteration 126750, lr = 1e-06
I0723 07:12:51.826669 23230 solver.cpp:243] Iteration 126760, loss = 2.51056
I0723 07:12:51.826963 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.25375 (* 1 = 2.25375 loss)
I0723 07:12:51.827065 23230 sgd_solver.cpp:138] Iteration 126760, lr = 1e-06
I0723 07:14:19.592569 23230 solver.cpp:243] Iteration 126770, loss = 2.65793
I0723 07:14:19.592852 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.7457 (* 1 = 3.7457 loss)
I0723 07:14:19.979403 23230 sgd_solver.cpp:138] Iteration 126770, lr = 1e-06
I0723 07:15:47.561604 23230 solver.cpp:243] Iteration 126780, loss = 2.44342
I0723 07:15:47.561897 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.93829 (* 1 = 1.93829 loss)
I0723 07:15:47.562005 23230 sgd_solver.cpp:138] Iteration 126780, lr = 1e-06
I0723 07:17:11.951663 23230 solver.cpp:243] Iteration 126790, loss = 2.623
I0723 07:17:11.951943 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.0168 (* 1 = 3.0168 loss)
I0723 07:17:11.952070 23230 sgd_solver.cpp:138] Iteration 126790, lr = 1e-06
I0723 07:18:38.972913 23230 solver.cpp:243] Iteration 126800, loss = 2.68836
I0723 07:18:38.973177 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.05793 (* 1 = 2.05793 loss)
I0723 07:18:38.973228 23230 sgd_solver.cpp:138] Iteration 126800, lr = 1e-06
I0723 07:20:04.211917 23230 solver.cpp:243] Iteration 126810, loss = 2.49393
I0723 07:20:04.212296 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.32273 (* 1 = 3.32273 loss)
I0723 07:20:04.212383 23230 sgd_solver.cpp:138] Iteration 126810, lr = 1e-06
I0723 07:21:32.131618 23230 solver.cpp:243] Iteration 126820, loss = 2.59571
I0723 07:21:32.131850 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.948869 (* 1 = 0.948869 loss)
I0723 07:21:32.131891 23230 sgd_solver.cpp:138] Iteration 126820, lr = 1e-06
I0723 07:22:58.375174 23230 solver.cpp:243] Iteration 126830, loss = 2.55505
I0723 07:22:58.375454 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.78476 (* 1 = 1.78476 loss)
I0723 07:22:58.375530 23230 sgd_solver.cpp:138] Iteration 126830, lr = 1e-06
I0723 07:24:26.683874 23230 solver.cpp:243] Iteration 126840, loss = 2.6695
I0723 07:24:26.684113 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.58506 (* 1 = 2.58506 loss)
I0723 07:24:27.040158 23230 sgd_solver.cpp:138] Iteration 126840, lr = 1e-06
I0723 07:25:54.168017 23230 solver.cpp:243] Iteration 126850, loss = 2.80905
I0723 07:25:54.168278 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.50526 (* 1 = 2.50526 loss)
I0723 07:25:54.168318 23230 sgd_solver.cpp:138] Iteration 126850, lr = 1e-06
I0723 07:27:20.723162 23230 solver.cpp:243] Iteration 126860, loss = 2.59448
I0723 07:27:20.723455 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9391 (* 1 = 1.9391 loss)
I0723 07:27:20.723557 23230 sgd_solver.cpp:138] Iteration 126860, lr = 1e-06
I0723 07:28:47.490185 23230 solver.cpp:243] Iteration 126870, loss = 2.37093
I0723 07:28:47.490460 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.87462 (* 1 = 1.87462 loss)
I0723 07:28:47.490562 23230 sgd_solver.cpp:138] Iteration 126870, lr = 1e-06
I0723 07:30:13.840590 23230 solver.cpp:243] Iteration 126880, loss = 2.5293
I0723 07:30:13.840823 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93171 (* 1 = 2.93171 loss)
I0723 07:30:13.840873 23230 sgd_solver.cpp:138] Iteration 126880, lr = 1e-06
I0723 07:31:42.021958 23230 solver.cpp:243] Iteration 126890, loss = 2.85039
I0723 07:31:42.022245 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.01704 (* 1 = 3.01704 loss)
I0723 07:31:42.022292 23230 sgd_solver.cpp:138] Iteration 126890, lr = 1e-06
I0723 07:33:10.905695 23230 solver.cpp:243] Iteration 126900, loss = 2.69778
I0723 07:33:10.905964 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.69375 (* 1 = 3.69375 loss)
I0723 07:33:10.906095 23230 sgd_solver.cpp:138] Iteration 126900, lr = 1e-06
I0723 07:34:36.173913 23230 solver.cpp:243] Iteration 126910, loss = 2.59245
I0723 07:34:36.174176 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.32396 (* 1 = 1.32396 loss)
I0723 07:34:36.174228 23230 sgd_solver.cpp:138] Iteration 126910, lr = 1e-06
I0723 07:35:59.936774 23230 solver.cpp:243] Iteration 126920, loss = 2.62127
I0723 07:35:59.937034 23230 solver.cpp:259]     Train net output #0: mbox_loss = 4.5098 (* 1 = 4.5098 loss)
I0723 07:36:00.320253 23230 sgd_solver.cpp:138] Iteration 126920, lr = 1e-06
I0723 07:37:21.894737 23230 solver.cpp:243] Iteration 126930, loss = 2.59066
I0723 07:37:21.895035 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 07:37:21.895155 23230 sgd_solver.cpp:138] Iteration 126930, lr = 1e-06
I0723 07:38:46.933840 23230 solver.cpp:243] Iteration 126940, loss = 2.54606
I0723 07:38:46.934152 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.51728 (* 1 = 2.51728 loss)
I0723 07:38:46.934267 23230 sgd_solver.cpp:138] Iteration 126940, lr = 1e-06
I0723 07:40:14.027300 23230 solver.cpp:243] Iteration 126950, loss = 2.50727
I0723 07:40:14.027571 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.78295 (* 1 = 2.78295 loss)
I0723 07:40:14.027673 23230 sgd_solver.cpp:138] Iteration 126950, lr = 1e-06
I0723 07:41:38.401873 23230 solver.cpp:243] Iteration 126960, loss = 2.72436
I0723 07:41:38.402106 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.93139 (* 1 = 3.93139 loss)
I0723 07:41:38.402154 23230 sgd_solver.cpp:138] Iteration 126960, lr = 1e-06
I0723 07:43:03.798722 23230 solver.cpp:243] Iteration 126970, loss = 2.50791
I0723 07:43:03.799001 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93804 (* 1 = 2.93804 loss)
I0723 07:43:03.799082 23230 sgd_solver.cpp:138] Iteration 126970, lr = 1e-06
I0723 07:44:28.014993 23230 solver.cpp:243] Iteration 126980, loss = 2.7993
I0723 07:44:28.015239 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.16574 (* 1 = 2.16574 loss)
I0723 07:44:28.015281 23230 sgd_solver.cpp:138] Iteration 126980, lr = 1e-06
I0723 07:45:53.495033 23230 solver.cpp:243] Iteration 126990, loss = 2.66736
I0723 07:45:53.495352 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0.973257 (* 1 = 0.973257 loss)
I0723 07:45:54.178218 23230 sgd_solver.cpp:138] Iteration 126990, lr = 1e-06
I0723 07:47:11.470474 23230 solver.cpp:596] Snapshotting to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_127000.caffemodel
I0723 07:47:12.312712 23230 sgd_solver.cpp:307] Snapshotting solver state to binary proto file models/VGGNet/VOC0712/SSD_1024x1024/VGG_VOC0712_SSD_1024x1024_iter_127000.solverstate
I0723 07:47:12.515161 23230 solver.cpp:433] Iteration 127000, Testing net (#0)
I0723 07:47:12.515666 23230 net.cpp:693] Ignoring source layer mbox_loss
I0723 07:47:15.838891 23230 solver.cpp:546]     Test net output #0: detection_eval = 0.616853
I0723 07:47:23.598070 23230 solver.cpp:243] Iteration 127000, loss = 2.51137
I0723 07:47:23.598186 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.90748 (* 1 = 1.90748 loss)
I0723 07:47:24.396745 23230 sgd_solver.cpp:138] Iteration 127000, lr = 1e-06
I0723 07:48:43.389969 23230 solver.cpp:243] Iteration 127010, loss = 2.59981
I0723 07:48:43.390290 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.80531 (* 1 = 2.80531 loss)
I0723 07:48:43.390400 23230 sgd_solver.cpp:138] Iteration 127010, lr = 1e-06
I0723 07:50:08.900916 23230 solver.cpp:243] Iteration 127020, loss = 2.31716
I0723 07:50:08.901185 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4472 (* 1 = 2.4472 loss)
I0723 07:50:08.901233 23230 sgd_solver.cpp:138] Iteration 127020, lr = 1e-06
I0723 07:51:36.975059 23230 solver.cpp:243] Iteration 127030, loss = 2.6846
I0723 07:51:36.975354 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.5104 (* 1 = 1.5104 loss)
I0723 07:51:36.975467 23230 sgd_solver.cpp:138] Iteration 127030, lr = 1e-06
I0723 07:53:02.063956 23230 solver.cpp:243] Iteration 127040, loss = 2.46575
I0723 07:53:02.064241 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.86043 (* 1 = 1.86043 loss)
I0723 07:53:02.417587 23230 sgd_solver.cpp:138] Iteration 127040, lr = 1e-06
I0723 07:54:27.671291 23230 solver.cpp:243] Iteration 127050, loss = 2.61761
I0723 07:54:27.671545 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.44279 (* 1 = 2.44279 loss)
I0723 07:54:27.671584 23230 sgd_solver.cpp:138] Iteration 127050, lr = 1e-06
I0723 07:55:54.069118 23230 solver.cpp:243] Iteration 127060, loss = 2.39039
I0723 07:55:54.069396 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.34306 (* 1 = 1.34306 loss)
I0723 07:55:54.069455 23230 sgd_solver.cpp:138] Iteration 127060, lr = 1e-06
I0723 07:57:19.878670 23230 solver.cpp:243] Iteration 127070, loss = 2.59126
I0723 07:57:19.878944 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.4197 (* 1 = 2.4197 loss)
I0723 07:57:20.239523 23230 sgd_solver.cpp:138] Iteration 127070, lr = 1e-06
I0723 07:58:46.107394 23230 solver.cpp:243] Iteration 127080, loss = 2.46521
I0723 07:58:46.107691 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.93329 (* 1 = 2.93329 loss)
I0723 07:58:46.107785 23230 sgd_solver.cpp:138] Iteration 127080, lr = 1e-06
I0723 08:00:13.428532 23230 solver.cpp:243] Iteration 127090, loss = 2.58183
I0723 08:00:13.428889 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.36256 (* 1 = 1.36256 loss)
I0723 08:00:13.428994 23230 sgd_solver.cpp:138] Iteration 127090, lr = 1e-06
I0723 08:01:42.017123 23230 solver.cpp:243] Iteration 127100, loss = 2.37477
I0723 08:01:42.017359 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.79347 (* 1 = 1.79347 loss)
I0723 08:01:42.374550 23230 sgd_solver.cpp:138] Iteration 127100, lr = 1e-06
I0723 08:03:08.640841 23230 solver.cpp:243] Iteration 127110, loss = 2.58296
I0723 08:03:08.641109 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.82425 (* 1 = 2.82425 loss)
I0723 08:03:08.641167 23230 sgd_solver.cpp:138] Iteration 127110, lr = 1e-06
I0723 08:04:30.360477 23230 solver.cpp:243] Iteration 127120, loss = 2.39387
I0723 08:04:30.360747 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.46516 (* 1 = 1.46516 loss)
I0723 08:04:30.360816 23230 sgd_solver.cpp:138] Iteration 127120, lr = 1e-06
I0723 08:05:53.370473 23230 solver.cpp:243] Iteration 127130, loss = 2.48678
I0723 08:05:53.370772 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.96706 (* 1 = 1.96706 loss)
I0723 08:05:53.370837 23230 sgd_solver.cpp:138] Iteration 127130, lr = 1e-06
I0723 08:07:16.907774 23230 solver.cpp:243] Iteration 127140, loss = 2.25756
I0723 08:07:16.908056 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.10497 (* 1 = 2.10497 loss)
I0723 08:07:16.908114 23230 sgd_solver.cpp:138] Iteration 127140, lr = 1e-06
I0723 08:08:43.655268 23230 solver.cpp:243] Iteration 127150, loss = 2.66893
I0723 08:08:43.655584 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.9564 (* 1 = 1.9564 loss)
I0723 08:08:43.655678 23230 sgd_solver.cpp:138] Iteration 127150, lr = 1e-06
I0723 08:10:10.278759 23230 solver.cpp:243] Iteration 127160, loss = 2.57916
I0723 08:10:10.279050 23230 solver.cpp:259]     Train net output #0: mbox_loss = 0 (* 1 = 0 loss)
I0723 08:10:11.115365 23230 sgd_solver.cpp:138] Iteration 127160, lr = 1e-06
I0723 08:11:37.283352 23230 solver.cpp:243] Iteration 127170, loss = 2.62314
I0723 08:11:37.283676 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.92395 (* 1 = 3.92395 loss)
I0723 08:11:37.283720 23230 sgd_solver.cpp:138] Iteration 127170, lr = 1e-06
I0723 08:13:01.000830 23230 solver.cpp:243] Iteration 127180, loss = 2.41631
I0723 08:13:01.001087 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.82783 (* 1 = 1.82783 loss)
I0723 08:13:01.736595 23230 sgd_solver.cpp:138] Iteration 127180, lr = 1e-06
I0723 08:14:26.411502 23230 solver.cpp:243] Iteration 127190, loss = 2.76336
I0723 08:14:26.411803 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.74149 (* 1 = 3.74149 loss)
I0723 08:14:26.411907 23230 sgd_solver.cpp:138] Iteration 127190, lr = 1e-06
I0723 08:15:51.941823 23230 solver.cpp:243] Iteration 127200, loss = 2.48904
I0723 08:15:51.942090 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.5309 (* 1 = 1.5309 loss)
I0723 08:15:51.942142 23230 sgd_solver.cpp:138] Iteration 127200, lr = 1e-06
I0723 08:17:20.723366 23230 solver.cpp:243] Iteration 127210, loss = 2.69519
I0723 08:17:20.723647 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.14024 (* 1 = 3.14024 loss)
I0723 08:17:20.723762 23230 sgd_solver.cpp:138] Iteration 127210, lr = 1e-06
I0723 08:18:48.078893 23230 solver.cpp:243] Iteration 127220, loss = 2.63819
I0723 08:18:48.079159 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.23491 (* 1 = 2.23491 loss)
I0723 08:18:48.079231 23230 sgd_solver.cpp:138] Iteration 127220, lr = 1e-06
I0723 08:20:14.230553 23230 solver.cpp:243] Iteration 127230, loss = 2.6408
I0723 08:20:14.230846 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.69376 (* 1 = 2.69376 loss)
I0723 08:20:14.588856 23230 sgd_solver.cpp:138] Iteration 127230, lr = 1e-06
I0723 08:21:40.684612 23230 solver.cpp:243] Iteration 127240, loss = 2.33583
I0723 08:21:40.684933 23230 solver.cpp:259]     Train net output #0: mbox_loss = 5.72688 (* 1 = 5.72688 loss)
I0723 08:21:40.685034 23230 sgd_solver.cpp:138] Iteration 127240, lr = 1e-06
I0723 08:23:07.763156 23230 solver.cpp:243] Iteration 127250, loss = 2.45848
I0723 08:23:07.763397 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.85347 (* 1 = 2.85347 loss)
I0723 08:23:07.763447 23230 sgd_solver.cpp:138] Iteration 127250, lr = 1e-06
I0723 08:24:33.998028 23230 solver.cpp:243] Iteration 127260, loss = 2.3519
I0723 08:24:33.998318 23230 solver.cpp:259]     Train net output #0: mbox_loss = 3.24256 (* 1 = 3.24256 loss)
I0723 08:24:33.998373 23230 sgd_solver.cpp:138] Iteration 127260, lr = 1e-06
I0723 08:26:00.054749 23230 solver.cpp:243] Iteration 127270, loss = 2.68928
I0723 08:26:00.055052 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.58927 (* 1 = 1.58927 loss)
I0723 08:26:00.055162 23230 sgd_solver.cpp:138] Iteration 127270, lr = 1e-06
I0723 08:27:27.315961 23230 solver.cpp:243] Iteration 127280, loss = 2.59621
I0723 08:27:27.316220 23230 solver.cpp:259]     Train net output #0: mbox_loss = 1.38483 (* 1 = 1.38483 loss)
I0723 08:27:27.316267 23230 sgd_solver.cpp:138] Iteration 127280, lr = 1e-06
I0723 08:28:54.724882 23230 solver.cpp:243] Iteration 127290, loss = 2.51724
I0723 08:28:54.725191 23230 solver.cpp:259]     Train net output #0: mbox_loss = 2.41477 (* 1 = 2.41477 loss)
I0723 08:28:54.725288 23230 sgd_solver.cpp:138] Iteration 127290, lr = 1e-06
